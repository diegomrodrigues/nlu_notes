## Treinamento de Large Language Models com Datasets Textuais Massivos

### Introdução

Este capítulo foca no processo de treinamento de Large Language Models (LLMs), explorando como esses modelos são alimentados por datasets textuais massivos, geralmente obtidos através da extração de dados da web (*web scraping*), e frequentemente complementados por dados curados e outras fontes. Este capítulo complementa a discussão sobre corpora de treinamento dos capítulos anteriores [^26], detalhando o processo de como esses dados são utilizados no treinamento dos modelos. Como vimos anteriormente, a qualidade e a diversidade dos dados são cruciais para o desenvolvimento de LLMs robustos e generalizáveis [^26].

### Conceitos Fundamentais

LLMs, conforme introduzido nos capítulos anteriores, são treinados utilizando grandes volumes de dados textuais. O processo de treinamento envolve a apresentação desses dados ao modelo para que ele aprenda os padrões e nuances da linguagem [^26]. Os datasets utilizados são frequentemente uma mistura de textos da web, e dados curados, cuidadosamente selecionados.

#### Extração de Dados da Web (*Web Scraping*)

A extração de dados da web, ou *web scraping*, é o processo de coletar automaticamente informações de páginas da web. Este método é fundamental para criar os vastos datasets necessários para treinar LLMs:
* **Crawlers:** Os *crawlers* são programas automatizados que percorrem a web seguindo links e armazenando o conteúdo das páginas. Eles são o coração do *web scraping*.
    > 💡 **Exemplo Numérico:** Um *crawler* típico pode explorar milhões de páginas da web por dia, seguindo links e armazenando o conteúdo HTML de cada página. Se cada *crawler* explorar 1 milhão de páginas por dia e um projeto de *web scraping* usar 100 *crawlers*, teremos um volume de 100 milhões de páginas por dia. Essa é a escala da qual precisamos para treinar modelos de linguagem.
**Proposição 1:** *A escolha da arquitetura e configuração do *crawler* impacta diretamente a eficiência da coleta de dados, a diversidade das fontes e a qualidade dos dados obtidos.*
    **Prova da Proposição 1:**
    I. A arquitetura de um *crawler* (e.g., *breadth-first* vs. *depth-first*) influencia quais páginas são exploradas primeiro e, portanto, a ordem e a diversidade da coleta.
    II. A configuração do *crawler* (e.g., limites de requisições por minuto, número de *threads* simultâneas) afeta a velocidade da coleta e o volume de dados obtidos por unidade de tempo.
    III. Uma configuração inadequada pode levar à coleta de dados enviesados (e.g., focando em certos tipos de sites) ou a sobrecarga dos servidores visitados (o que pode causar bloqueio do *crawler*).
    IV. A escolha da arquitetura e configuração deve ser feita cuidadosamente para garantir a eficiência e qualidade da coleta, maximizando a diversidade e minimizando vieses.
    Portanto, a arquitetura e a configuração do *crawler* impactam a eficiência, diversidade e qualidade dos dados coletados. ■
*   **Formato de Dados:** Os dados são geralmente armazenados em formatos como HTML, que precisam ser processados para extrair o texto relevante.
    > 💡 **Exemplo Numérico:** Uma página da web típica pode conter 10KB de código HTML e apenas 2KB de texto útil. O processamento é necessário para extrair esses 2KB de texto relevante, removendo *tags* HTML e outros elementos não textuais. Por exemplo, em uma coleta de 100 milhões de páginas web, teremos 1000 TB de HTML, dos quais apenas 200TB são texto útil.
*   **Desafios do *Web Scraping*:** O processo de extração de dados da web apresenta desafios, como:
    *   **Conteúdo Dinâmico:** Muitas páginas da web geram conteúdo dinamicamente, o que dificulta a extração usando *crawlers* tradicionais.
    *   **Bloqueio:** Websites podem bloquear *crawlers* para evitar sobrecarga em seus servidores ou proteger seu conteúdo.
    *   **Formatação Inconsistente:** Páginas da web têm formatação inconsistente, o que torna difícil a extração de texto relevante.
    **Lema 1.1:** *A variabilidade na formatação e no conteúdo das páginas da web exige técnicas de extração robustas e adaptáveis para garantir a qualidade dos dados coletados para o treinamento de LLMs.*
        **Prova do Lema 1.1:**
        I. Páginas da web são projetadas com uma variedade de formatos, usando diferentes *tags* HTML, estilos CSS e elementos JavaScript.
        II. Essa variabilidade dificulta a criação de *crawlers* que extraiam o texto útil de forma consistente.
        III. Técnicas de extração robustas (e.g., usando *parsers* HTML e modelos de *machine learning* para identificar blocos de texto) são necessárias para lidar com diferentes formatos e garantir a qualidade dos dados.
        IV. A falta de adaptabilidade do extrator pode resultar na coleta de texto com ruído ou na perda de informações relevantes para o treinamento do LLM.
    Portanto, a variabilidade nas páginas da web exige técnicas de extração robustas e adaptáveis para garantir a qualidade dos dados. ■
    **Lema 1.2:** *O uso de *headless browsers* e outras técnicas de renderização de JavaScript pode auxiliar a extração de conteúdo de páginas da web dinâmicas, mas isso aumenta os custos computacionais e a complexidade do processo de *scraping*.*
        **Prova do Lema 1.2:**
        I. Páginas com conteúdo dinâmico utilizam JavaScript para gerar ou alterar seu conteúdo.
        II. *Crawlers* tradicionais, que apenas analisam o HTML, podem não conseguir extrair o conteúdo gerado dinamicamente.
        III. *Headless browsers*, que simulam a ação de um navegador web real, conseguem renderizar JavaScript e, portanto, extrair o conteúdo dinâmico.
        IV. No entanto, *headless browsers* são mais pesados computacionalmente, o que torna o processo mais lento e caro.
        V. O uso de técnicas de renderização de JavaScript adiciona complexidade ao processo de *scraping*, exigindo um maior investimento em infraestrutura e desenvolvimento.
    Portanto, a extração de conteúdo dinâmico usando *headless browsers* tem maior custo computacional e complexidade. ■
    **Lema 1.3:** *A implementação de técnicas de re-tentativa (retry) e gerenciamento de proxies é crucial para lidar com o bloqueio de crawlers e garantir a continuidade da coleta de dados.*
    **Prova do Lema 1.3:**
        I. Websites podem implementar medidas de bloqueio para impedir o acesso de crawlers, seja por detecção de padrões de requisição ou por endereços IP específicos.
        II. Técnicas de re-tentativa, que permitem que o crawler tente acessar novamente uma página após um período de tempo, podem resolver problemas temporários de bloqueio.
        III. O uso de proxies permite que o crawler altere seu endereço IP de origem, dificultando a identificação e bloqueio por parte dos websites.
        IV. A combinação de re-tentativas e gerenciamento de proxies garante maior resiliência do crawler e a continuidade da coleta de dados, mesmo diante de mecanismos de bloqueio.
    Portanto, re-tentativas e gerenciamento de proxies são cruciais para garantir a continuidade da coleta. ■

#### Dados Curados e Outras Fontes

Além dos dados extraídos da web, os LLMs também são treinados com outros conjuntos de dados mais curados e controlados, como:

*   **Datasets Públicos:** Datasets como Wikipedia, Common Crawl (após filtragem), livros (e.g., *Project Gutenberg*), e outros conjuntos de dados abertos oferecem conteúdo de alta qualidade para o treinamento.
    > 💡 **Exemplo Numérico:** A Wikipedia em inglês possui mais de 6 milhões de artigos, com um total de mais de 10 bilhões de *tokens*. Um dataset de livros pode ter cerca de 50.000 livros, totalizando 25 bilhões de tokens. Esses dados são utilizados em diversos projetos de LLMs.
**Teorema 1.1:** *A combinação de dados da web com datasets curados resulta em um *corpus* de treinamento que equilibra quantidade e qualidade, contribuindo para uma melhor capacidade de generalização do LLM.*
        **Prova do Teorema 1.1:**
        I. Dados da web são volumosos, mas podem conter muito ruído e vieses.
        II. Datasets curados, como livros e Wikipedia, são menos ruidosos e mais bem estruturados, mas podem ser limitados em volume e diversidade.
        III. Ao combinar dados da web e datasets curados, é possível aproveitar o volume e diversidade da web e a qualidade e estrutura dos dados curados.
        IV. Essa combinação leva a um treinamento mais eficaz e a modelos com melhor capacidade de generalização, que são capazes de lidar com uma ampla gama de tarefas e dados.
    Portanto, a combinação de dados da web com datasets curados melhora a capacidade de generalização do LLM. ■
*   **Dados Específicos de Tarefa:** Datasets criados especificamente para tarefas como tradução automática, summarização de texto, question answering (Q&A), análise de sentimentos, entre outros. Estes dados geralmente são pareados ou contém um *label* que indica o tipo de texto.
    > 💡 **Exemplo Numérico:** Um dataset para tradução automática pode ter milhões de pares de frases em diferentes idiomas (e.g., inglês-espanhol, inglês-francês, etc.). Um dataset de Q&A pode incluir milhões de pares de perguntas e respostas. Esses dados são utilizados para treinar modelos que resolvem tarefas específicas com alta precisão. Por exemplo, um dataset de tradução pode conter 1 milhão de pares de frases, totalizando 20 milhões de tokens (10 milhões em cada idioma).
*   **Dados Sintéticos:** Algumas vezes, dados sintéticos (e.g., texto gerado por outros modelos ou regras) são usados para aumentar ou balancear datasets ou para criar exemplos de casos específicos.
    > 💡 **Exemplo Numérico:** Para aumentar um dataset de texto tóxico, podemos usar um gerador de texto para criar mais exemplos de *hate speech*, e incluir esses dados no treino. Essa técnica pode dobrar o tamanho dos datasets específicos. Um dataset inicial de 500 mil exemplos pode ser expandido para 1 milhão com a adição de dados sintéticos.
  **Proposição 2:** *O uso de dados sintéticos no treinamento de LLMs pode complementar ou aumentar os datasets existentes, melhorando o desempenho em tarefas específicas, mas requer monitoramento para evitar a introdução de artefatos e vieses.*
    **Prova da Proposição 2:**
        I. Dados sintéticos podem ser gerados para preencher lacunas ou aumentar a diversidade em datasets existentes, permitindo uma aprendizagem mais abrangente.
        II. A geração de exemplos sintéticos para casos específicos (e.g., texto tóxico, perguntas e respostas raras) pode melhorar o desempenho do LLM em tarefas que requerem lidar com esses casos.
        III. No entanto, se os dados sintéticos não forem bem gerados, eles podem introduzir artefatos e vieses que podem afetar negativamente a qualidade do treinamento.
        IV. O monitoramento contínuo dos dados sintéticos é necessário para garantir que eles não introduzam problemas no treinamento e que o modelo aprenda padrões corretos e úteis.
    Portanto, o uso de dados sintéticos pode ser útil, mas requer monitoramento para evitar a introdução de artefatos e vieses. ■
*   **Código de Programação:** Datasets de código de programação em diversas linguagens são usados para treinar LLMs que podem gerar e entender código.
       > 💡 **Exemplo Numérico:** Um dataset de código pode conter milhões de arquivos de código em várias linguagens como Python, Java, C++, etc. Um exemplo seria ter 5 milhões de arquivos Python, 3 milhões de Java, e 2 milhões de C++, totalizando 10 milhões de arquivos no dataset.
**Teorema 1.2:** *A combinação de texto e código no *corpus* de treinamento expande as capacidades dos LLMs, permitindo que eles lidem com tarefas de geração, compreensão e tradução de código, além de tarefas de linguagem natural.*
        **Prova do Teorema 1.2:**
            I. Datasets de código oferecem ao LLM exposição à sintaxe, estrutura e lógica da programação.
            II. Essa exposição permite que o modelo aprenda a gerar código, a entender a semântica do código e a traduzir entre diferentes linguagens de programação.
            III. Ao combinar dados de texto com dados de código, o LLM torna-se um modelo mais versátil, capaz de lidar tanto com tarefas de linguagem natural quanto tarefas de programação.
            IV. Essa capacidade de lidar com texto e código é essencial para modelos que precisam interagir com desenvolvedores, auxiliar na programação e automatizar tarefas de software.
    Portanto, a combinação de texto e código no treinamento melhora a versatilidade do LLM. ■

#### Processamento de Dados

Antes de serem usados para treinar LLMs, os dados precisam ser processados para remover ruídos, padronizar a formatação e aumentar a qualidade dos dados. Essas etapas incluem:

* **Limpeza:** Remoção de *spam*, *HTML*, código *JavaScript*, caracteres inválidos e outros elementos não textuais.
    > 💡 **Exemplo Numérico:** Em uma etapa de limpeza, cerca de 10% dos dados coletados da web podem ser removidos devido à presença de *spam* e conteúdo inválido, incluindo código, *HTML* e caracteres não textuais. Se um dataset inicial tem 1000 TB, a limpeza removerá 100 TB de lixo, restando 900 TB de dados úteis para as próximas etapas.
* **Deduplicação:** Identificação e remoção de textos duplicados ou muito similares.
    > 💡 **Exemplo Numérico:** Uma etapa de deduplicação pode remover 5% do restante do dataset após a limpeza. Se temos 900TB após a limpeza, a deduplicação removerá 45 TB, deixando 855 TB de dados únicos.
*   **Tokenização:** O texto é convertido em *tokens* (palavras ou partes de palavras) que são a unidade de entrada para o modelo.
    > 💡 **Exemplo Numérico:** Uma frase como “O gato preto pulou a cerca.” pode ser tokenizada como: ["O", "gato", "preto", "pulou", "a", "cerca", "."]. O tokenizer BPE é comumente usado, quebra palavras em subpartes como "pul" "ou" e gera representações mais compactas para o vocabulário.
    > ```python
    > import nltk
    > from nltk.tokenize import word_tokenize
    > nltk.download('punkt')
    >
    > text = "O gato preto pulou a cerca."
    > tokens = word_tokenize(text)
    > print(tokens) # Output: ['O', 'gato', 'preto', 'pulou', 'a', 'cerca', '.']
    > ```
*   **Padronização:** Padronização do formato do texto (e.g., *encoding*, caracteres, quebras de linha).
    > 💡 **Exemplo Numérico:** Um texto com diferentes quebras de linha e caracteres especiais pode ser padronizado para UTF-8 e para ter quebras de linha consistentes, tornando o dataset mais uniforme.
    > ```python
    > import unicodedata
    >
    > text_with_inconsistencies = "Texto com\r\nquebras de linha\ne caracteres\xa0especiais."
    > # Normalize unicode
    > normalized_text = unicodedata.normalize('NFKD', text_with_inconsistencies)
    > # Replace new lines
    > normalized_text = normalized_text.replace('\r\n', '\n').replace('\xa0', ' ')
    > print(normalized_text) # Output: Texto com\nquebras de linha\ne caracteres especiais.
    > ```
*   **Filtragem:** Remoção de texto ofensivo, dados enviesados e conteúdo de baixa qualidade.
    > 💡 **Exemplo Numérico:** A filtragem pode identificar e remover 2% dos textos remanescentes por conter conteúdo tóxico, reduzindo ainda mais o tamanho do *dataset*, mas aumentando a sua qualidade. Se tivermos 855TB após a deduplicação, a filtragem pode remover 17TB de conteúdo tóxico, restando 838TB para treino.
    **Teorema 1.3:** *A aplicação de técnicas de filtragem robustas é crucial para a remoção de conteúdo tóxico e enviesado, prevenindo que o LLM aprenda comportamentos indesejados ou perpetue vieses sociais.*
     **Prova do Teorema 1.3:**
        I. Datasets da web podem conter conteúdo tóxico, como discurso de ódio, discriminação e violência, o que, se não filtrado, pode levar o modelo a reproduzir esses comportamentos.
        II. A falta de filtragem adequada pode fazer com que o LLM perpetue vieses sociais presentes nos dados, tornando-o inadequado para interações em diversas comunidades.
        III. Técnicas robustas de filtragem, que utilizam modelos de machine learning e outras ferramentas de análise, são necessárias para identificar e remover conteúdo tóxico e enviesado.
        IV. A filtragem garante que o modelo seja treinado em um ambiente mais seguro e ético, reduzindo a possibilidade de reprodução de conteúdo problemático.
    Portanto, a filtragem robusta garante um LLM seguro e justo. ■

    **Teorema 1.4:** *O uso de diferentes *tokenizers* pode levar a diferentes representações do mesmo texto, afetando a performance do LLM em downstream tasks. A escolha do tokenizer deve ser feita com base nas características do texto e da tarefa.*
     **Prova do Teorema 1.4:**
        I. *Tokenizers* diferentes podem quebrar o texto em unidades de formas distintas (palavras, subpalavras ou caracteres), gerando diferentes representações para o mesmo texto.
        II. A escolha do tokenizer influencia o tamanho do vocabulário, a representação de palavras raras e a capacidade do modelo de lidar com diferentes tipos de texto.
        III. Um *tokenizer* que divide palavras em subpalavras pode ser mais eficiente em lidar com palavras raras ou com diferentes formas de uma mesma palavra, enquanto um *tokenizer* que quebra em palavras pode ser mais simples e eficiente para textos com vocabulário comum.
        IV. O desempenho do LLM em tarefas específicas está ligado à representação gerada pelo *tokenizer*, sendo crucial escolher o mais adequado para a tarefa e o tipo de texto.
    Portanto, a escolha do *tokenizer* impacta a performance do LLM. ■
    **Teorema 1.5:** *A padronização dos dados de entrada, como a codificação e o formato de quebras de linha, melhora a eficiência do processamento e o desempenho do LLM, evitando problemas causados por inconsistências nos dados.*
     **Prova do Teorema 1.5:**
        I. Inconsistências na codificação (e.g., UTF-8, ISO-8859-1) e no formato das quebras de linha (e.g., \n, \r\n) podem levar a erros no processamento de dados e a diferentes representações do mesmo texto pelo modelo.
        II. A padronização dos dados garante que todos os textos sejam processados uniformemente, evitando que o modelo aprenda padrões errôneos e melhorando a eficiência do treinamento.
        III. Ao utilizar uma codificação e um formato de quebras de linha consistentes, é possível garantir uma melhor qualidade do corpus de treinamento.
        IV. A padronização simplifica o fluxo de trabalho, permitindo que os modelos sejam treinados e implementados de forma mais eficiente.
    Portanto, a padronização dos dados melhora a eficiência do processamento. ■
   **Proposição 2.1:** *A ordem das etapas de processamento e filtragem dos dados pode influenciar o resultado final, sendo necessário avaliar e ajustar cada etapa para garantir a qualidade ótima do *corpus* de treinamento.*
    **Prova da Proposição 2.1:**
        I. A aplicação de deduplicação antes da limpeza, por exemplo, pode remover dados importantes que seriam limpos em uma etapa posterior, causando perda de informações valiosas.
        II. O uso de diferentes *tokenizers* pode levar a diferentes representações dos mesmos textos, impactando a maneira como o modelo aprende e generaliza.
        III. A escolha da ordem e dos parâmetros de cada etapa de processamento deve ser feita cuidadosamente e de forma específica para o tipo de modelo e tarefa.
        IV. O ajuste e avaliação contínuos das etapas são necessários para otimizar a qualidade do corpus e garantir que ele atenda aos requisitos do LLM.
    Portanto, a ordem das etapas de processamento e filtragem pode influenciar o resultado final. ■

### Conclusão

O treinamento de LLMs requer datasets textuais massivos, obtidos principalmente através de *web scraping*, complementados por datasets públicos, dados específicos de tarefas e, algumas vezes, dados sintéticos. O processamento desses dados é tão crítico quanto a arquitetura do modelo, com etapas de limpeza, deduplicação, tokenização, padronização e filtragem, que impactam diretamente na qualidade final dos dados e, por consequência, no desempenho dos modelos. Como temos visto desde os capítulos iniciais, a qualidade dos dados e o seu tratamento são centrais para o sucesso de qualquer modelo de *machine learning*, especialmente para modelos de linguagem. Nos próximos capítulos, veremos como utilizar esses dados no treinamento e otimização de LLMs.

### Referências
[^26]: Jurafsky, Daniel e James H. Martin. *Speech and Language Processing*. Draft de 3 de Fevereiro de 2024. Capítulo 10.
<!-- END -->
