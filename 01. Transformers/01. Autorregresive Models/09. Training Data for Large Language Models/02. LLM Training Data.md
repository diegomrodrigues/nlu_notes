## Corpora de Treinamento para Large Language Models

### Introdu√ß√£o
Este cap√≠tulo aprofunda a discuss√£o sobre os **corpora de treinamento** utilizados em Large Language Models (LLMs), expandindo os conceitos apresentados no cap√≠tulo anterior [^26]. Abordaremos em detalhe a import√¢ncia da utiliza√ß√£o de dados da web, *crawled* e curados, incluindo o Common Crawl, C4, Wikip√©dia e livros, enfatizando como esses corpora s√£o cruciais para o desenvolvimento de modelos robustos. Como vimos anteriormente, a qualidade e diversidade desses corpora s√£o determinantes para o desempenho e generaliza√ß√£o dos modelos [^26].

### Conceitos Fundamentais
Conforme introduzido no cap√≠tulo anterior, LLMs s√£o treinados com grandes volumes de dados textuais [^26]. A base desses dados vem de diversas fontes e estilos, o que permite que o modelo aprenda padr√µes lingu√≠sticos complexos. A sele√ß√£o e prepara√ß√£o desses dados s√£o etapas cr√≠ticas para o sucesso do modelo.

#### Fontes de Dados Web

A web √© uma das principais fontes de dados para o treinamento de LLMs, devido √† sua vasta quantidade de informa√ß√µes e diversidade de conte√∫do. As principais fontes incluem:

*   **Common Crawl:** Este √© um grande *corpus* de texto da web, obtido por meio de *crawling* automatizado [^26]. Cont√©m bilh√µes de p√°ginas, oferecendo uma ampla representa√ß√£o da diversidade textual na internet. No entanto, tamb√©m inclui ru√≠do e requer filtragem cuidadosa.
    > üí° **Exemplo Num√©rico:** O Common Crawl pode ter snapshots trimestrais com mais de 50 bilh√µes de p√°ginas web, incluindo textos em v√°rias l√≠nguas e estilos, totalizando mais de 100 trilh√µes de tokens. Suponha que ap√≥s o crawling de um novo snapshot do Common Crawl, foram identificados 55 bilh√µes de p√°ginas, totalizando 110 trilh√µes de tokens. Se um LLM fosse treinado com esses dados diretamente, ele poderia sofrer com o ru√≠do e a inconsist√™ncia desses dados.
    **Proposi√ß√£o 1:** *A natureza n√£o-curada do Common Crawl implica que a sua qualidade varia significativamente entre diferentes fontes, exigindo t√©cnicas robustas de filtragem para garantir a utilidade para o treinamento de LLMs.*

*   **C4 (Colossal Clean Crawled Corpus):** Uma vers√£o limpa e filtrada do Common Crawl, o C4 √© um corpus de 156 bilh√µes de *tokens* em ingl√™s [^26]. Ele √© processado para remover textos duplicados, conte√∫do n√£o textual (como c√≥digo) e palavras ofensivas, tornando-o mais adequado para o treinamento de LLMs [^26].
    > üí° **Exemplo Num√©rico:** O C4, ap√≥s a limpeza, possui aproximadamente 150 bilh√µes de tokens de alta qualidade. Esse corpus foca em texto em ingl√™s e remove elementos irrelevantes, melhorando a qualidade dos dados para o treino. Por exemplo, imagine que um snapshot inicial do Common Crawl com 200 bilh√µes de tokens seja a base. Ap√≥s a limpeza e filtragem para o C4, 50 bilh√µes de tokens foram removidos por serem duplicados, c√≥digo ou conte√∫do t√≥xico. Os 150 bilh√µes restantes formam o dataset limpo.
    **Lema 1.1:** *A remo√ß√£o de duplicatas no C4, embora reduza o tamanho do corpus, melhora a efici√™ncia do treinamento ao diminuir o vi√©s de repeti√ß√£o, um problema comum em dados da web.*
    **Prova do Lema 1.1:**
    I. A remo√ß√£o de duplicatas diminui a quantidade de repeti√ß√µes exatas de frases ou par√°grafos.
    II. A repeti√ß√£o excessiva de um mesmo texto pode levar um modelo de aprendizado de m√°quina a dar mais peso a essas inst√¢ncias repetidas.
    III. Ao reduzir repeti√ß√µes, evitamos um vi√©s direcionado para conte√∫do repetido, ajudando o modelo a generalizar a partir de inst√¢ncias diversas.
    IV. Assim, a redu√ß√£o no tamanho do corpus devido √† remo√ß√£o de duplicatas √© compensada por uma melhor efici√™ncia no treinamento devido √† redu√ß√£o do vi√©s.
    Portanto, a remo√ß√£o de duplicatas melhora a efici√™ncia do treinamento, diminuindo o vi√©s de repeti√ß√£o. ‚ñ†
*   **Outras Fontes da Web:** Al√©m do Common Crawl e do C4, modelos tamb√©m utilizam dados de outros *crawlers*, reposit√≥rios de dados web espec√≠ficos, e APIs de busca, proporcionando ainda mais variedade nos dados de treino.
    **Teorema 1.1:** *A combina√ß√£o de m√∫ltiplos crawlers e reposit√≥rios da web pode aumentar a diversidade do corpus, resultando em modelos com melhor capacidade de generaliza√ß√£o, desde que devidamente filtrados e balanceados para evitar vieses.*
    **Prova do Teorema 1.1:**
    I. Dados de diferentes *crawlers* e reposit√≥rios web capturam uma gama mais ampla de estilos de escrita, t√≥picos e pontos de vista.
    II. A maior diversidade nos dados de treinamento exp√µe o modelo a uma gama mais ampla de padr√µes e nuances lingu√≠sticas.
    III. Modelos treinados com maior diversidade tendem a generalizar melhor para dados que n√£o estavam presentes no treinamento.
    IV. No entanto, para garantir essa generaliza√ß√£o, √© crucial filtrar e balancear os dados para evitar que certos *crawlers* ou fontes dominem o corpus e introduzam vieses.
    Portanto, a combina√ß√£o de m√∫ltiplos *crawlers* e reposit√≥rios web aumenta a diversidade e melhora a capacidade de generaliza√ß√£o, quando filtrada e balanceada corretamente. ‚ñ†

#### Fontes de Dados Curados

Al√©m dos dados *crawled* da web, existem outras fontes de dados cuidadosamente selecionados para o treinamento de LLMs, que podem complementar o que √© aprendido com texto da web. Estes incluem:

*   **Wikip√©dia:** A Wikip√©dia √© uma enciclop√©dia online colaborativa com um grande volume de texto sobre diversos t√≥picos [^26]. √â utilizada como fonte de dados para conhecimento geral, com artigos abrangendo uma ampla variedade de dom√≠nios.
     > üí° **Exemplo Num√©rico:** A Wikip√©dia em ingl√™s cont√©m cerca de 6.7 milh√µes de artigos, totalizando cerca de 10 bilh√µes de tokens. A natureza colaborativa da Wikip√©dia permite uma cobertura ampla e diversificada de t√≥picos. Em um cen√°rio de treinamento, o dataset da Wikip√©dia poderia ser dividido em se√ß√µes tem√°ticas, como ci√™ncia, hist√≥ria e arte, e usado para treinar o modelo a entender essas categorias de informa√ß√£o.
   **Lema 2.1:** *A estrutura enciclop√©dica da Wikip√©dia a torna uma fonte de conhecimento factual de alta qualidade, ideal para o treinamento de LLMs que requerem precis√£o e abrang√™ncia, mas a sua estrutura mais formal pode n√£o ser representativa de todos os estilos de linguagem.*

*   **Livros:** Datasets de livros oferecem grandes volumes de texto em v√°rios estilos de escrita [^26], sendo uma fonte importante para modelar o uso correto da linguagem e a estrutura narrativa. A literatura oferece contextos mais longos e complexos do que √© tipicamente encontrado na web.
     > üí° **Exemplo Num√©rico:** Um conjunto de dados de livros pode incluir 50.000 livros, com um total de 25 bilh√µes de tokens. O conte√∫do de livros fornece ao LLM uma vis√£o mais aprofundada da linguagem e dos padr√µes narrativos. Por exemplo, livros como "Dom Quixote" podem ser usados para expor o modelo a narrativas complexas e diferentes estilos de escrita.
    **Teorema 2.1:** *A inclus√£o de livros no corpus de treinamento contribui para a capacidade do LLM de gerar textos mais longos e coerentes, al√©m de aprender nuances de estilo e tom, devido √† sua estrutura narrativa mais extensa.*
    **Prova do Teorema 2.1:**
    I. Livros geralmente cont√™m narrativas extensas e coerentes, com temas e personagens desenvolvidos ao longo de m√∫ltiplas p√°ginas.
    II. Essa exposi√ß√£o a textos longos e complexos permite que o LLM aprenda como manter a coer√™ncia em grandes trechos textuais.
    III. A diversidade de estilos liter√°rios nos livros permite que o LLM aprenda nuances e tons diferentes de escrita.
    IV. Em compara√ß√£o com fragmentos de texto da web, livros oferecem uma estrutura narrativa mais rica e extensa, favorecendo a aprendizagem da gera√ß√£o de textos mais coesos.
    Portanto, a inclus√£o de livros contribui para que o LLM aprenda a gerar textos longos e coerentes com nuances de estilo e tom. ‚ñ†
*   **Dados Espec√≠ficos para Tarefas:** Para tarefas como tradu√ß√£o autom√°tica, summariza√ß√£o e question answering, datasets espec√≠ficos s√£o criados, incluindo pares de texto-tradu√ß√£o, artigos-resumo, e pares de perguntas e respostas [^26].
    > üí° **Exemplo Num√©rico:** Um dataset para tradu√ß√£o autom√°tica pode incluir 10 milh√µes de pares de frases em ingl√™s e franc√™s, como: ("Hello, how are you?", "Bonjour, comment allez-vous?"). Para summariza√ß√£o, pode haver 500 mil artigos com seus resumos correspondentes. Para question answering, podemos usar 2 milh√µes de pares de perguntas e respostas relacionados a diversos t√≥picos.

*   **C√≥digo de Programa√ß√£o:** Para treinar modelos capazes de entender e gerar c√≥digo, √© crucial incluir reposit√≥rios de c√≥digo em v√°rias linguagens, como Python, Java e C++ [^26].
      > üí° **Exemplo Num√©rico:** Um corpus de c√≥digo pode ter 10 milh√µes de arquivos em diversas linguagens, totalizando cerca de 10 bilh√µes de tokens. O uso de c√≥digo real, com diferentes estilos, ajuda o LLM a lidar com diferentes sintaxes e desafios de programa√ß√£o. Por exemplo, um conjunto de dados pode incluir 4 milh√µes de arquivos Python, 3 milh√µes de arquivos Java e 3 milh√µes de arquivos C++.
    **Corol√°rio 1:** *A diversidade de linguagens de programa√ß√£o no corpus de treinamento permite que o LLM aprenda padr√µes gerais de programa√ß√£o, tornando-o mais adapt√°vel a diferentes contextos de desenvolvimento.*
    **Prova do Corol√°rio 1:**
    I. Cada linguagem de programa√ß√£o (e.g., Python, Java, C++) tem sua pr√≥pria sintaxe e estilo, mas existem padr√µes comuns de programa√ß√£o (e.g., estruturas de controle, fun√ß√µes, vari√°veis).
    II. Ao ser exposto a diversas linguagens, o LLM aprende n√£o apenas a sintaxe espec√≠fica de cada uma, mas tamb√©m os conceitos gerais de programa√ß√£o que s√£o comuns entre elas.
    III. Essa compreens√£o dos padr√µes gerais de programa√ß√£o permite que o LLM seja mais adapt√°vel, conseguindo aplicar seus conhecimentos a novas situa√ß√µes de programa√ß√£o, mesmo com linguagens n√£o vistas durante o treinamento.
    Portanto, a diversidade de linguagens de programa√ß√£o no corpus de treinamento permite que o LLM aprenda padr√µes gerais de programa√ß√£o, aumentando sua adaptabilidade. ‚ñ†
*   **Outros Dados Curados:** Outras fontes de dados curados podem incluir publica√ß√µes acad√™micas, artigos cient√≠ficos, e dados de redes sociais, desde que cuidadosamente filtrados e processados.
  **Proposi√ß√£o 2:** *A inclus√£o de dados de redes sociais, apesar do potencial para alta variabilidade e informalidade, pode enriquecer a capacidade do LLM de entender e gerar textos em contextos mais informais e coloquiais, se cuidadosamente selecionados e filtrados para remover dados indesejados.*
    **Prova da Proposi√ß√£o 2:**
    I. Dados de redes sociais refletem a linguagem em seu uso cotidiano, muitas vezes apresentando uma natureza mais informal e variada.
    II. Essa informalidade pode enriquecer o LLM com estilos de linguagem que n√£o s√£o encontrados em fontes mais formais como livros e enciclop√©dias.
    III. No entanto, dados de redes sociais podem conter ru√≠do, g√≠rias, abrevia√ß√µes e informa√ß√µes irrelevantes.
    IV. A filtragem cuidadosa √© necess√°ria para remover dados indesejados e preservar a diversidade √∫til, como padr√µes de conversa√ß√£o e express√µes idiom√°ticas.
    Portanto, a inclus√£o de dados de redes sociais pode enriquecer a capacidade do LLM de entender e gerar textos informais, desde que estes sejam cuidadosamente selecionados e filtrados. ‚ñ†

####  Processamento e Filtragem de Dados
A prepara√ß√£o dos corpora de treinamento envolve etapas de processamento e filtragem para remover conte√∫do ruidoso ou indesejado. As principais opera√ß√µes incluem:

*   **Deduplica√ß√£o:** Remo√ß√£o de textos duplicados para reduzir a influ√™ncia excessiva de certas frases [^26]. Este processo assegura que o modelo n√£o seja enviesado por repeti√ß√£o.
    > üí° **Exemplo Num√©rico:** A deduplica√ß√£o de um conjunto de dados web de 100 bilh√µes de tokens pode reduzir o tamanho do dataset em 5%, enquanto mant√™m a sua diversidade. Se um dataset original tem 100 bilh√µes de tokens e a deduplica√ß√£o remove 5 bilh√µes de tokens duplicados, o dataset resultante ter√° 95 bilh√µes de tokens.
    **Lema 3.1:** *A deduplica√ß√£o, embora reduza a quantidade total de dados, pode aumentar significativamente a efici√™ncia do treinamento, pois evita que o modelo sobreajuste a padr√µes repetitivos, permitindo uma melhor generaliza√ß√£o.*
    **Prova do Lema 3.1:**
    I. Textos duplicados podem gerar um vi√©s no modelo, fazendo com que ele atribua peso excessivo a esses padr√µes repetitivos.
    II. A remo√ß√£o de duplicatas impede que o modelo se concentre em dados repetidos, permitindo que aprenda a partir da diversidade de informa√ß√µes presentes no corpus.
    III. Modelos treinados sem duplicatas tendem a generalizar melhor para dados n√£o vistos, pois s√£o menos propensos ao sobreajuste de padr√µes repetidos.
    IV. Aumento da efici√™ncia no treinamento √© alcan√ßado porque o modelo n√£o precisa processar repeti√ß√µes in√∫teis, permitindo que ele foque na variedade dos dados.
    Portanto, a deduplica√ß√£o aumenta a efici√™ncia do treinamento, prevenindo o sobreajuste e favorecendo a generaliza√ß√£o. ‚ñ†

*   **Filtragem de Conte√∫do N√£o Textual:** Remo√ß√£o de c√≥digo, *HTML*, *JavaScript* e outros conte√∫dos n√£o textuais, mantendo apenas texto puro [^26].
    > üí° **Exemplo Num√©rico:** A filtragem de um dataset web remove cerca de 10% de c√≥digos e outros elementos n√£o textuais, resultando em um corpus mais limpo. Se um dataset inicial tem 50 bilh√µes de tokens e a filtragem remove 5 bilh√µes de tokens de c√≥digo e HTML, o dataset resultante ter√° 45 bilh√µes de tokens de texto puro.
    **Teorema 3.1:** *A filtragem de conte√∫do n√£o textual, embora crucial, deve ser implementada cuidadosamente para evitar a remo√ß√£o acidental de informa√ß√µes relevantes, como exemplos de c√≥digo ou texto embutido em tags HTML.*
    **Prova do Teorema 3.1:**
    I. Conte√∫do n√£o textual como c√≥digo, *HTML* e *JavaScript* n√£o s√£o adequados para o treinamento de modelos de linguagem focados em texto.
    II. A remo√ß√£o desse conte√∫do torna o corpus mais adequado para o treinamento de modelos de linguagem natural.
    III. No entanto, algumas vezes conte√∫do textual relevante pode estar embutido em tags *HTML* ou arquivos de c√≥digo.
    IV. Uma filtragem muito agressiva pode remover acidentalmente esses dados, reduzindo a qualidade geral do corpus.
    V. Portanto, √© crucial aplicar um m√©todo de filtragem cuidadoso e balanceado, a fim de preservar informa√ß√µes relevantes e remover o conte√∫do n√£o textual.
    Assim, a filtragem de conte√∫do n√£o textual √© crucial, mas deve ser feita com cautela para evitar a remo√ß√£o acidental de informa√ß√µes relevantes. ‚ñ†
*   **Remo√ß√£o de Conte√∫do T√≥xico e Ofensivo:** Filtragem de *hate speech*, linguagem abusiva e outros conte√∫dos t√≥xicos [^28], garantindo que o modelo seja treinado em um ambiente mais seguro e √©tico. Este passo √© fundamental para evitar comportamentos indesejados do modelo.
      > üí° **Exemplo Num√©rico:** Um modelo de detec√ß√£o de conte√∫do t√≥xico pode remover cerca de 3% do dataset considerado t√≥xico ou ofensivo, melhorando a qualidade e seguran√ßa do corpus. Se um dataset de 100 bilh√µes de tokens tem 3 bilh√µes considerados t√≥xicos, a filtragem remove esses 3 bilh√µes, deixando 97 bilh√µes de tokens para treinamento.
      **Lema 3.2:** *A filtragem de conte√∫do t√≥xico, embora essencial para a √©tica e seguran√ßa, pode inadvertidamente introduzir vieses, dado que a defini√ß√£o de toxicidade √© subjetiva e dependente do contexto. Assim, esse passo requer uma abordagem cuidadosa e monitoramento cont√≠nuo.*
      **Prova do Lema 3.2:**
    I. A remo√ß√£o de conte√∫do t√≥xico √© fundamental para prevenir que o LLM aprenda comportamentos nocivos ou reproduza discursos de √≥dio.
    II. No entanto, a defini√ß√£o de "conte√∫do t√≥xico" pode ser subjetiva, variando dependendo do contexto, cultura e at√© mesmo da interpreta√ß√£o do filtro utilizado.
    III. Um filtro de toxicidade pode, inadvertidamente, remover textos perfeitamente normais em certos contextos ou introduzir vieses ao classificar textos como t√≥xicos de forma inconsistente.
    IV. √â importante realizar monitoramento constante e ajustes nos filtros, para garantir que o processo seja equilibrado e justo, minimizando a introdu√ß√£o de novos vieses.
    Portanto, a filtragem de conte√∫do t√≥xico √© essencial, mas pode introduzir vieses, exigindo uma abordagem cuidadosa e monitoramento cont√≠nuo. ‚ñ†

*   **Filtragem por Idioma:** Identifica√ß√£o e separa√ß√£o de textos nos idiomas desejados, garantindo um balan√ßo entre diferentes l√≠nguas, especialmente em modelos multil√≠ngues.
       > üí° **Exemplo Num√©rico:** Um dataset multil√≠ngue pode ser filtrado para remover textos em idiomas menos relevantes, resultando em uma distribui√ß√£o equilibrada de idiomas, como por exemplo 30% para cada idioma. Se um dataset inicial tinha 50% ingl√™s, 30% franc√™s e 20% espanhol, ap√≥s a filtragem, pode ter uma distribui√ß√£o de 33.3% para cada um dos tr√™s idiomas.
    **Corol√°rio 2:** *Em modelos multil√≠ngues, a filtragem por idioma √© essencial para garantir que cada idioma seja adequadamente representado no corpus, evitando vieses que poderiam favorecer l√≠nguas predominantes.*
    **Prova do Corol√°rio 2:**
    I. Em modelos multil√≠ngues, o corpus de treinamento deve conter exemplos em cada um dos idiomas que o modelo ir√° suportar.
    II. Sem filtragem por idioma, um corpus multil√≠ngue pode ter uma distribui√ß√£o desequilibrada, favorecendo um idioma ou um conjunto de idiomas em detrimento de outros.
    III. A representa√ß√£o desequilibrada pode levar o LLM a ter um desempenho inferior em idiomas sub-representados, resultando em um vi√©s.
    IV. Uma filtragem por idioma garante que cada idioma seja adequadamente representado, melhorando o desempenho do modelo em todos os idiomas suportados e reduzindo vieses.
    Portanto, em modelos multil√≠ngues, a filtragem por idioma √© essencial para garantir representa√ß√£o equilibrada de todos os idiomas, evitando vieses. ‚ñ†

*   **Outras Filtragens:** Outras formas de filtragem incluem corre√ß√£o ortogr√°fica e gramatical, remo√ß√£o de *spam* e outras formas de conte√∫do de baixa qualidade.
    **Proposi√ß√£o 3:** *A aplica√ß√£o combinada de diversas filtragens, enquanto melhora a qualidade geral do corpus, pode potencialmente remover informa√ß√µes √∫teis ou aumentar o vi√©s se aplicada de forma n√£o balanceada. Portanto, cada etapa de filtragem deve ser avaliada e ajustada cuidadosamente.*
    **Prova da Proposi√ß√£o 3:**
    I. A aplica√ß√£o de m√∫ltiplas filtragens remove ru√≠dos e conte√∫do indesejado do corpus, melhorando a qualidade dos dados.
    II. Contudo, cada filtragem, se feita de forma muito agressiva, pode remover informa√ß√µes que poderiam ser √∫teis.
    III. Por exemplo, a corre√ß√£o ortogr√°fica excessiva pode remover informalidades e g√≠rias que s√£o importantes em certos contextos.
    IV. Al√©m disso, se uma filtragem for aplicada de maneira desbalanceada, ela pode introduzir vieses no corpus, afetando o desempenho do modelo.
    V. Portanto, a aplica√ß√£o de cada etapa de filtragem deve ser cuidadosamente avaliada e ajustada para garantir um bom equil√≠brio entre qualidade e representatividade dos dados.
    Assim, embora m√∫ltiplas filtragens melhorem a qualidade do corpus, elas podem causar remo√ß√£o de informa√ß√µes √∫teis ou aumentar vieses se aplicadas de forma n√£o balanceada. ‚ñ†

### Conclus√£o
Os LLMs s√£o treinados em grandes quantidades de dados da web e corpora curados, combinando textos brutos, dados de perguntas e respostas, tradu√ß√µes e c√≥digo de programa√ß√£o [^26]. O processo de prepara√ß√£o desses dados √© t√£o cr√≠tico quanto a arquitetura do modelo, com a qualidade, diversidade e filtragem desempenhando um papel crucial no desempenho do modelo. Como destacado nos cap√≠tulos anteriores e referenciado ao longo deste cap√≠tulo, a forma como esses modelos s√£o treinados e os dados que consomem s√£o fatores determinantes na sua capacidade e limita√ß√µes. O entendimento da composi√ß√£o dos corpora de treinamento √© essencial para o desenvolvimento e uso √©tico e eficaz de LLMs. A qualidade e a diversidade dos dados de treinamento est√£o diretamente ligadas √† capacidade de generaliza√ß√£o dos modelos, e, portanto, s√£o prioridades para as pr√≥ximas gera√ß√µes de Large Language Models.
### Refer√™ncias
[^26]: Jurafsky, Daniel e James H. Martin. *Speech and Language Processing*. Draft de 3 de Fevereiro de 2024. Cap√≠tulo 10.
[^28]: Jurafsky, Daniel e James H. Martin. *Speech and Language Processing*. Draft de 3 de Fevereiro de 2024. Cap√≠tulo 10.
<!-- END -->
