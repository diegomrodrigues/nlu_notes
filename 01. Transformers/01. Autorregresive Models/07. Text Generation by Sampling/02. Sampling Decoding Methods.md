## Amostragem em Modelos de Linguagem: T√©cnicas Avan√ßadas para Gera√ß√£o de Texto
### Introdu√ß√£o
Dando continuidade √† nossa explora√ß√£o dos **Large Language Models (LLMs)** e sua capacidade de gerar texto, este cap√≠tulo se concentrar√° nas t√©cnicas de **amostragem** como um mecanismo chave para o processo de decodifica√ß√£o [^1]. Anteriormente, estabelecemos que a decodifica√ß√£o, em modelos autoregressivos, envolve a escolha iterativa da pr√≥xima palavra, baseada em seu contexto e nas probabilidades atribu√≠das pelo modelo [^2]. No entanto, a mera sele√ß√£o da palavra mais prov√°vel (decodifica√ß√£o *greedy*) pode resultar em textos repetitivos e pouco criativos. A amostragem, portanto, torna-se essencial para introduzir a diversidade e explorar op√ß√µes menos √≥bvias [^2]. Neste cap√≠tulo, mergulharemos nas nuances da amostragem como um m√©todo de decodifica√ß√£o, focando em como diferentes t√©cnicas podem equilibrar a qualidade e diversidade do texto gerado. Complementando os conceitos introduzidos anteriormente, exploraremos a amostragem como uma t√©cnica sofisticada para obten√ß√£o de sequ√™ncias de texto mais ricas e interessantes.

### M√©todos de Amostragem: Uma An√°lise Detalhada
Como mencionado anteriormente, a **amostragem** √© um processo fundamental na gera√ß√£o de texto, onde as palavras s√£o selecionadas aleatoriamente com base em sua probabilidade, o que, em contraste com o processo *greedy*, introduz um elemento de aleatoriedade e variedade no texto gerado [^1, 2]. No entanto, m√©todos de amostragem ing√™nuos, como a amostragem aleat√≥ria pura, podem gerar resultados n√£o ideais, o que exige t√©cnicas de amostragem mais sofisticadas. Em continuidade ao nosso estudo, vamos detalhar cada um desses m√©todos e suas caracter√≠sticas.

#### Amostragem Aleat√≥ria: Um Ponto de Partida
A forma mais b√°sica de amostragem √© a **amostragem aleat√≥ria**, na qual as palavras s√£o selecionadas diretamente da distribui√ß√£o de probabilidade do modelo [^1]. Isso significa que, em cada passo de gera√ß√£o, uma palavra √© selecionada de acordo com a probabilidade que o modelo atribui a ela para aquele contexto [^1, 2]. Embora esse m√©todo introduza um elemento de aleatoriedade, ele n√£o impede que palavras improv√°veis sejam selecionadas, pois, por mais baixas que sejam as probabilidades da cauda da distribui√ß√£o, sempre haver√° uma chance n√£o nula de que uma dessas palavras seja selecionada, o que resulta em textos muitas vezes incoerentes [^1, 2].

>  **Observa√ß√£o 2:** A amostragem aleat√≥ria pura √© um m√©todo simples e f√°cil de implementar, mas sua suscetibilidade √† gera√ß√£o de palavras improv√°veis a torna inadequada para a maioria das aplica√ß√µes de gera√ß√£o de texto.

**Lema 2:** A amostragem aleat√≥ria pode levar √† gera√ß√£o de sequ√™ncias de texto com baixa qualidade devido a ocorr√™ncias inesperadas de palavras improv√°veis da cauda da distribui√ß√£o.
*Prova*:
I. Seja $P(w)$ a distribui√ß√£o de probabilidade sobre o vocabul√°rio $V$.
II. A amostragem aleat√≥ria seleciona a palavra $w$ com probabilidade $P(w)$, independentemente de seu valor.
III. Sejam $C = \{w \in V \, | \, P(w) < \epsilon\}$ as palavras improv√°veis na cauda da distribui√ß√£o para um pequeno $\epsilon > 0$.
IV. Embora cada palavra $w \in C$ tenha probabilidade baixa, o n√∫mero de tais palavras pode ser grande.
V. A probabilidade agregada $\sum_{w \in C} P(w)$ pode ser significativa, mesmo que cada termo seja pequeno.
VI. Em muitas etapas de amostragem, a sele√ß√£o de ao menos uma palavra $w \in C$ √© muito prov√°vel, resultando em uma sequ√™ncia de texto com baixa qualidade devido a ocorr√™ncias inesperadas.
Portanto, a amostragem aleat√≥ria pode resultar em textos de baixa qualidade devido √† sele√ß√£o frequente de palavras de baixa probabilidade. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que um modelo de linguagem, ap√≥s processar a frase "O gato est√°", atribua as seguintes probabilidades para a pr√≥xima palavra: P("correndo") = 0.6, P("dormindo") = 0.3, P("zanzando") = 0.05, e P("absurdo") = 0.05, juntamente com v√°rias outras palavras com probabilidades muito pequenas. Usando amostragem aleat√≥ria, todas as palavras tem uma chance de serem escolhidas, incluindo "absurdo", apesar de sua baixa probabilidade. Uma poss√≠vel sequ√™ncia gerada pode ser: "O gato est√° absurdo e depois correndo". Esta frase demonstra como a amostragem aleat√≥ria pode gerar sequ√™ncias sem sentido ou incoerentes.

#### Amostragem Top-k: Truncando a Distribui√ß√£o
Para mitigar os problemas da amostragem aleat√≥ria, a **amostragem top-k** trunca a distribui√ß√£o de probabilidade, considerando apenas as k palavras mais prov√°veis [^1, 2]. As probabilidades das k palavras restantes s√£o ent√£o renormalizadas para que somem 1, e uma palavra √© selecionada a partir dessa nova distribui√ß√£o [^1]. A vantagem desse m√©todo √© que ele impede a sele√ß√£o de palavras de baixa probabilidade, mantendo um certo n√≠vel de aleatoriedade e diversidade [^2]. O par√¢metro k √© um hiperpar√¢metro que precisa ser ajustado para cada aplica√ß√£o.

**Observa√ß√£o 3:** A amostragem top-k oferece um melhor equil√≠brio entre qualidade e diversidade do que a amostragem aleat√≥ria pura. O valor ideal de k depende do dom√≠nio e da tarefa de gera√ß√£o.

> üí° **Exemplo Num√©rico:** Se o modelo tiver as seguintes probabilidades de palavra: P(A) = 0.4, P(B) = 0.3, P(C) = 0.15, P(D) = 0.1, P(E) = 0.05 e k=3, ent√£o apenas as palavras A, B e C s√£o consideradas. As probabilidades s√£o renormalizadas: P'(A) = 0.4/(0.4+0.3+0.15) = 0.47, P'(B) = 0.3/(0.4+0.3+0.15) = 0.35 e P'(C) = 0.15/(0.4+0.3+0.15) = 0.18. A escolha da pr√≥xima palavra √© feita dessa nova distribui√ß√£o.
>
> ```mermaid
> graph LR
>     A[P(A) = 0.4] -->|Selecionado| Renormaliza√ß√£o
>     B[P(B) = 0.3] -->|Selecionado| Renormaliza√ß√£o
>     C[P(C) = 0.15] -->|Selecionado| Renormaliza√ß√£o
>     D[P(D) = 0.1] -->|Descartado|
>     E[P(E) = 0.05] -->|Descartado|
>     Renormaliza√ß√£o --> A1[P'(A) = 0.47]
>     Renormaliza√ß√£o --> B1[P'(B) = 0.35]
>     Renormaliza√ß√£o --> C1[P'(C) = 0.18]
>     A1 -->|Amostra| PalavraSelecionada
>     B1 -->|Amostra| PalavraSelecionada
>     C1 -->|Amostra| PalavraSelecionada
>     PalavraSelecionada --> Fim
> ```
> Aqui, k=3, e a amostragem s√≥ considera as 3 palavras mais prov√°veis. As probabilidades originais s√£o descartadas e as probabilidades de A, B, e C s√£o renormalizadas para um novo espa√ßo de amostragem.

#### Amostragem por N√∫cleo (Top-p): Ajustando-se √† Distribui√ß√£o
A **amostragem por n√∫cleo** ou **top-p** (tamb√©m conhecida como amostragem de probabilidade cumulativa) seleciona o menor conjunto de palavras cujas probabilidades somadas excedem um limiar p [^1, 2]. Isso difere da amostragem top-k, onde um n√∫mero fixo de palavras √© selecionado, independentemente de suas probabilidades [^1, 2].  Ao adaptar-se √† distribui√ß√£o das probabilidades, a amostragem top-p √© mais flex√≠vel e geralmente leva a resultados melhores. O valor p √© um hiperpar√¢metro que tamb√©m precisa ser ajustado dependendo da tarefa [^2].

**Caixa de destaque:**

>  *A amostragem top-p adapta-se √† distribui√ß√£o das probabilidades, oferecendo uma maneira flex√≠vel de controlar o balan√ßo entre qualidade e diversidade.*

> üí° **Exemplo Num√©rico:**  Se o modelo atribuir as seguintes probabilidades: P(A) = 0.4, P(B) = 0.3, P(C) = 0.15, P(D) = 0.1, P(E) = 0.05, e o limiar p for 0.8, a amostragem top-p selecionar√° A, B e C, pois P(A) + P(B) + P(C) = 0.85 >= 0.8 e P(A) + P(B) = 0.7 < 0.8. As probabilidades s√£o ent√£o renormalizadas e o modelo amostra a pr√≥xima palavra.
>
> Considere o seguinte:
> 1. Probabilidades originais: P(A)=0.4, P(B)=0.3, P(C)=0.15, P(D)=0.1, P(E)=0.05
> 2. Limiar p = 0.8
> 3. Calculamos as probabilidades cumulativas:
>    - P(A) = 0.4
>    - P(A) + P(B) = 0.7
>    - P(A) + P(B) + P(C) = 0.85
> 4. O menor conjunto que excede p=0.8 √© {A, B, C}
> 5. Renormalizamos as probabilidades P'(A) = 0.4/0.85 ‚âà 0.47, P'(B) = 0.3/0.85 ‚âà 0.35, P'(C) = 0.15/0.85 ‚âà 0.18
> 6. Amostramos a pr√≥xima palavra de {A,B,C} usando essas novas probabilidades.

**Proposi√ß√£o 2:** A amostragem top-p adapta-se melhor a diferentes distribui√ß√µes de probabilidade do que a amostragem top-k.
*Prova*:
I. Seja $P(w_i)$ a probabilidade da i-√©sima palavra no vocabul√°rio, ordenadas de forma que $P(w_1) \geq P(w_2) \geq \ldots$.
II. Na amostragem top-k, as primeiras $k$ palavras s√£o selecionadas independentemente de seus valores.
III. Na amostragem top-p, o menor conjunto $S$ √© selecionado tal que $\sum_{w_i \in S} P(w_i) \geq p$.
IV. Se a distribui√ß√£o for muito concentrada em algumas palavras, a amostragem top-k pode selecionar muitas palavras de baixa probabilidade, enquanto a amostragem top-p adaptar√° o tamanho do conjunto $S$, diminuindo a diversidade.
V. Se a distribui√ß√£o for mais uniforme, a amostragem top-k pode n√£o selecionar palavras suficientes, diminuindo a diversidade, enquanto a amostragem top-p adaptar√° o tamanho do conjunto $S$, aumentando a diversidade.
VI. A amostragem top-p ajusta o n√∫mero de palavras selecionadas de forma a garantir que as probabilidades dessas palavras excedam $p$, o que leva a uma melhor adapta√ß√£o √† distribui√ß√£o.
Portanto, a amostragem top-p se adapta melhor a diferentes formas de distribui√ß√£o do que a amostragem top-k. ‚ñ†

**Teorema 2.1** A amostragem top-p pode ser vista como uma generaliza√ß√£o da amostragem top-k em determinados casos.

*Prova*:
I. Seja $P(w_i)$ a probabilidade da i-√©sima palavra no vocabul√°rio, ordenadas de forma que $P(w_1) \geq P(w_2) \geq \ldots$.
II. Na amostragem top-k, selecionamos as k primeiras palavras.
III. Na amostragem top-p, selecionamos o menor conjunto S tal que $\sum_{w_i \in S} P(w_i) \geq p$.
IV. Considere um caso onde as probabilidades $P(w_i)$ s√£o tais que $\sum_{i=1}^{k} P(w_i) = p$.
V. Neste cen√°rio espec√≠fico, a amostragem top-p tamb√©m selecionar√° as k primeiras palavras.
VI. Se $k$ for escolhido de forma que $\sum_{i=1}^{k-1} P(w_i) < p \leq \sum_{i=1}^{k} P(w_i)$, ent√£o tanto top-k quanto top-p selecionam as k primeiras palavras.

Portanto, em casos particulares onde a soma das k maiores probabilidades √© igual a p, a amostragem top-p se comporta de maneira id√™ntica √† amostragem top-k, podendo assim ser considerada uma generaliza√ß√£o. ‚ñ†

#### Amostragem por Temperatura: Remodelando a Distribui√ß√£o
A **amostragem por temperatura** modifica a distribui√ß√£o de probabilidade, em vez de trunc√°-la [^1]. Ela introduz um par√¢metro de temperatura $\tau$ que divide os *logits* antes de passar pelo *softmax*, permitindo controlar o grau de aleatoriedade [^1, 2]. Uma temperatura baixa ($\tau < 1$) concentra a probabilidade nas palavras mais prov√°veis, enquanto uma temperatura alta ($\tau > 1$) suaviza a distribui√ß√£o, aumentando a aleatoriedade da amostragem [^1, 2]. A amostragem por temperatura √© uma maneira eficaz de equilibrar a coer√™ncia e a diversidade de textos gerados.

**Observa√ß√£o 4:** A amostragem por temperatura permite um controle cont√≠nuo sobre a nitidez da distribui√ß√£o de probabilidade, oferecendo flexibilidade na gera√ß√£o de textos de diferentes estilos.

$$y = \text{softmax}(u/\tau)$$ [^2]

> üí° **Exemplo Num√©rico:**  Considere um modelo com logits u = [2, 1, 0]. Com temperatura $\tau = 1$, as probabilidades s√£o P(A) ‚âà 0.67, P(B) ‚âà 0.24 e P(C) ‚âà 0.09. Com $\tau = 0.5$, os logits s√£o u/0.5 = [4, 2, 0], e P'(A) ‚âà 0.88, P'(B) ‚âà 0.12, P'(C) ‚âà 0.01. Com $\tau = 2$, os logits s√£o u/2 = [1, 0.5, 0], e P''(A) ‚âà 0.48, P''(B) ‚âà 0.3, P''(C) ‚âà 0.22. Valores menores de œÑ aumentam o foco em palavras de alta probabilidade, e valores maiores tornam as probabilidades mais uniformes.
>
> Podemos visualizar a influ√™ncia da temperatura no gr√°fico abaixo:
> ```mermaid
>  graph LR
>      A[Logits: 2, 1, 0] --> B(softmax com œÑ = 1)
>      A --> C(softmax com œÑ = 0.5)
>      A --> D(softmax com œÑ = 2)
>      B --> E[P(A)=0.67, P(B)=0.24, P(C)=0.09]
>      C --> F[P'(A)=0.88, P'(B)=0.12, P'(C)=0.01]
>      D --> G[P''(A)=0.48, P''(B)=0.3, P''(C)=0.22]
> ```
> Este diagrama mostra como a temperatura afeta a distribui√ß√£o de probabilidade. Uma temperatura mais baixa concentra a probabilidade nas palavras mais prov√°veis (A), enquanto uma temperatura mais alta suaviza a distribui√ß√£o.

**Lema 2.1:** A amostragem por temperatura oferece uma forma cont√≠nua de controlar o trade-off entre explora√ß√£o (diversidade) e explota√ß√£o (qualidade) do modelo.
*Prova*:
I. A distribui√ß√£o de probabilidade modificada pela temperatura √© dada por $P_\tau(w_i) = \frac{e^{u_i / \tau}}{\sum_{j} e^{u_j / \tau}}$.
II. Quando $\tau \rightarrow 0$, os valores $u_i / \tau$ tendem a valores muito grandes, e a distribui√ß√£o se torna mais concentrada nas palavras de maior logit, resultando em gera√ß√£o com foco em qualidade e menor diversidade.
III. Quando $\tau \rightarrow \infty$, os valores $u_i / \tau$ tendem a zero, e a distribui√ß√£o se torna mais uniforme, aumentando a diversidade e a aleatoriedade na gera√ß√£o, mas diminuindo a qualidade.
IV. Valores de $\tau$ entre 0 e $\infty$ oferecem um espectro de possibilidades, permitindo ajustar a distribui√ß√£o para encontrar um equil√≠brio adequado entre qualidade e diversidade dependendo do caso.
Portanto, a amostragem por temperatura oferece um mecanismo cont√≠nuo para controlar o trade-off entre explora√ß√£o e explota√ß√£o na gera√ß√£o de texto. ‚ñ†

**Lema 2.2:** A amostragem por temperatura pode ser combinada com outras t√©cnicas de amostragem para obter um controle ainda maior sobre o processo de gera√ß√£o.

*Prova*:
I. A amostragem por temperatura modifica a distribui√ß√£o original de probabilidade do modelo $P(w)$ para uma distribui√ß√£o $P_\tau(w)$.
II. M√©todos como top-k e top-p realizam uma sele√ß√£o de um subconjunto do vocabul√°rio a partir de uma distribui√ß√£o.
III. Se aplicarmos a amostragem por temperatura primeiro e em seguida aplicarmos a amostragem top-k ou top-p, vamos estar selecionando um subconjunto da distribui√ß√£o modificada por temperatura.
IV. Essa combina√ß√£o nos permite modelar a nitidez da distribui√ß√£o com a temperatura e ao mesmo tempo controlar a diversidade com k ou p.
V. Essa combina√ß√£o de t√©cnicas permite maior flexibilidade na gera√ß√£o de texto.

Portanto, a amostragem por temperatura pode ser combinada com outras t√©cnicas de amostragem para um controle mais sofisticado do processo de gera√ß√£o. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo com os logits `u = [3, 2, 1, 0, -1]`. Primeiro, aplicamos uma temperatura $\tau=0.7$. Os novos logits s√£o `u_tau = u / tau = [4.28, 2.85, 1.42, 0, -1.42]`. Em seguida, aplicamos a fun√ß√£o softmax para obter as probabilidades:
> `P_tau = softmax(u_tau) = [0.53, 0.26, 0.13, 0.05, 0.02]`.
> Agora, para combinar com top-k com k=3, selecionar√≠amos as 3 maiores probabilidades e renormalizar√≠amos: `P_topk = [0.53/(0.53+0.26+0.13), 0.26/(0.53+0.26+0.13), 0.13/(0.53+0.26+0.13)] = [0.59, 0.29, 0.14]`. A pr√≥xima palavra seria selecionada a partir desta nova distribui√ß√£o. Essa combina√ß√£o nos permite utilizar a temperatura para ajustar a distribui√ß√£o antes de aplicar um filtro com top-k.

### Conclus√£o
Neste cap√≠tulo, exploramos em detalhes a **amostragem** como um mecanismo crucial para a gera√ß√£o de texto em modelos de linguagem. Analisamos como diferentes m√©todos de amostragem, como a aleat√≥ria, top-k, top-p e por temperatura, afetam a qualidade e a diversidade do texto gerado [^1, 2]. Cada m√©todo tem suas pr√≥prias vantagens e desvantagens, e a escolha do m√©todo adequado depende da aplica√ß√£o e dos resultados desejados. A compreens√£o dessas t√©cnicas √© fundamental para qualquer um que trabalhe com modelos de linguagem e busque gerar texto de alta qualidade. Os m√©todos apresentados aqui podem ser usados como base para a cria√ß√£o de m√©todos de amostragem mais sofisticados e adaptados a aplica√ß√µes espec√≠ficas.

### Refer√™ncias
[^1]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ¬© 2023. All rights reserved. Draft of February 3, 2024.
[^2]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ¬© 2023. All rights reserved. Draft of February 3, 2024.
<!-- END -->
