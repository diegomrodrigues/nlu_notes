## Otimiza√ß√£o da Previs√£o da Pr√≥xima Palavra com Cross-Entropy Loss

### Introdu√ß√£o
Em continuidade ao t√≥pico anterior sobre auto-supervis√£o no treinamento de LLMs [^25], este cap√≠tulo aprofunda o conceito da fun√ß√£o de perda **cross-entropy** e como ela √© utilizada para otimizar a capacidade de um modelo de prever a pr√≥xima palavra em uma sequ√™ncia de texto. Como discutimos, a auto-supervis√£o permite que modelos como os transformers aprendam sem r√≥tulos manuais, utilizando a sequ√™ncia natural das palavras como sinal de supervis√£o. O objetivo desta se√ß√£o √© detalhar o uso da fun√ß√£o de perda cross-entropy para guiar este processo de aprendizado, e consolidar o conhecimento adquirido sobre o processo de treinamento.

### A Fun√ß√£o de Perda Cross-Entropy em Detalhe

A fun√ß√£o de perda **cross-entropy** √© essencial no treinamento de modelos de linguagem, pois ela quantifica a diferen√ßa entre a distribui√ß√£o de probabilidade que o modelo prev√™ para a pr√≥xima palavra e a distribui√ß√£o real dessa palavra, que no nosso caso √© um vetor *one-hot* [^25]. Esta diferen√ßa, medida pela perda, orienta a atualiza√ß√£o dos pesos do modelo, atrav√©s do algoritmo de backpropagation, para que as previs√µes futuras sejam mais acuradas. Como vimos anteriormente, a perda cross-entropy para modelagem de linguagem √© expressa como:

$$ L_{CE} (\hat{y}_t, y_t) = - \log \hat{y}_t[w_{t+1}]$$

onde $\hat{y}_t$ √© a distribui√ß√£o de probabilidade prevista pelo modelo para o pr√≥ximo token no tempo *t*, e $y_t$ √© o vetor *one-hot* que representa o pr√≥ximo token correto $w_{t+1}$. O treinamento busca minimizar esta fun√ß√£o de perda.

#### Minimizando a Perda Cross-Entropy
O objetivo do treinamento √© minimizar a diferen√ßa entre a distribui√ß√£o prevista pelo modelo e a distribui√ß√£o real, atrav√©s da minimiza√ß√£o da perda cross-entropy. Isto √© alcan√ßado ajustando os pesos do modelo por meio de **backpropagation** [^25] e **descida de gradiente** [^27].  O backpropagation calcula o gradiente da fun√ß√£o de perda em rela√ß√£o aos pesos do modelo, e a descida de gradiente usa esse gradiente para ajustar os pesos na dire√ß√£o que reduz a perda.

**Teorema 2:** A minimiza√ß√£o da perda cross-entropy √© equivalente a maximizar a probabilidade logar√≠tmica da palavra correta, dada a sequ√™ncia de palavras anteriores.

*Prova:*
I. A perda cross-entropy para um modelo de linguagem √© dada por:
   $$ L_{CE}(\hat{y}_t, y_t) = - \log(\hat{y}_t[w_{t+1}])$$
II. Minimizar a perda cross-entropy significa encontrar os pesos do modelo que minimizam o valor de $L_{CE}$.
III. Como o logaritmo √© uma fun√ß√£o monot√¥nica crescente, minimizar o negativo do logaritmo √© equivalente a maximizar o argumento do logaritmo.
IV. Portanto, minimizar $- \log(\hat{y}_t[w_{t+1}])$ √© equivalente a maximizar $\log(\hat{y}_t[w_{t+1}])$.
V. Maximizar $\log(\hat{y}_t[w_{t+1}])$ corresponde a maximizar a probabilidade logar√≠tmica que o modelo atribui a palavra correta $w_{t+1}$ no instante $t$, dada a sequ√™ncia anterior $w_{<t}$.
VI. Logo, minimizar a perda cross-entropy √© equivalente a maximizar a probabilidade logar√≠tmica da pr√≥xima palavra correta, dada a sequ√™ncia de palavras anterior.
‚ñ†

> üí° **Exemplo Num√©rico:**
> Suponha que, durante o treinamento, o modelo est√° analisando a frase "O c√£o ladra". O modelo deve prever a pr√≥xima palavra. Digamos que o vocabul√°rio do modelo seja { "o", "c√£o", "ladra", "." }. Num dado instante *t*, o modelo processou "O c√£o ladra" e deve prever o token ".". Inicialmente, o modelo pode gerar as seguintes probabilidades para o pr√≥ximo token:
>
> $\hat{y}_t$ =  [P("o")=0.05, P("c√£o")=0.10, P("ladra")=0.05, P(".")=0.80]
>
> O vetor *one-hot* $y_t$ para o token "." seria:
>
> $y_t$ = [0, 0, 0, 1]
>
> Aplicando a f√≥rmula da cross-entropy:
>
> $L_{CE} = - \log(\hat{y}_t[w_{t+1}]) = - \log(0.80) \approx 0.223$
>
>  Se o modelo tivesse uma previs√£o pior, como:
>
> $\hat{y}_t$ =  [P("o")=0.25, P("c√£o")=0.25, P("ladra")=0.25, P(".")=0.25]
>
>  A perda seria:
>
> $L_{CE} = - \log(0.25) \approx 1.386$
>
>  A perda maior indica que o modelo est√° menos confiante na previs√£o correta, e os pesos do modelo ser√£o ajustados para aumentar a probabilidade de "." em contextos similares. Ap√≥s v√°rias itera√ß√µes de treinamento, espera-se que a probabilidade associada ao token correto aumente, e a perda diminua.
>
> Ao longo do treinamento, a probabilidade de prever o token correto " . " aumentar√°, levando a uma perda menor.

O treinamento visa minimizar a perda cruzada calculada em cada etapa, de forma a que o modelo se torne mais preciso a prever o token seguinte numa sequ√™ncia de texto.

**Teorema 2.1:** A perda cross-entropy √© uma medida convexa em rela√ß√£o √†s probabilidades preditas pelo modelo, garantindo a exist√™ncia de um m√≠nimo global durante o treinamento.

*Prova:*
I. A perda cross-entropy √© dada por $L_{CE}(\hat{y}_t, y_t) = - \log(\hat{y}_t[w_{t+1}])$.
II. A fun√ß√£o logaritmo √© uma fun√ß√£o c√¥ncava. Assim, $-\log(x)$ √© uma fun√ß√£o convexa.
III. Considerando que a probabilidade predita $\hat{y}_t[w_{t+1}]$ √© um valor entre 0 e 1, e a fun√ß√£o $-\log(x)$ √© convexa neste intervalo, a perda cross-entropy √© uma fun√ß√£o convexa em rela√ß√£o √†s probabilidades preditas pelo modelo.
IV. Fun√ß√µes convexas garantem que qualquer m√≠nimo local encontrado √© tamb√©m um m√≠nimo global, o que facilita a converg√™ncia do treinamento.
‚ñ†

#### Impacto da Distribui√ß√£o de Probabilidade Prevista

A distribui√ß√£o de probabilidade prevista $\hat{y}_t$ desempenha um papel crucial na determina√ß√£o da perda cross-entropy. Se o modelo prev√™ corretamente a pr√≥xima palavra, a probabilidade correspondente em $\hat{y}_t$ ser√° alta, resultando em uma perda baixa. Por outro lado, se o modelo prever incorretamente, a probabilidade da palavra correta ser√° baixa, levando a uma perda alta. Este mecanismo de feedback assegura que o modelo seja constantemente ajustado para prever as palavras seguintes com maior precis√£o.

##### O Papel dos Pesos do Modelo
Os pesos do modelo s√£o ajustados durante o treinamento para que a probabilidade atribu√≠da √† palavra correta seja aumentada e as probabilidades atribu√≠das √†s palavras incorretas sejam diminu√≠das. Esse ajuste √© feito por meio do algoritmo de backpropagation e otimizadores, que guiam os ajustes dos pesos para reduzir o erro de previs√£o do modelo [^27]. Este processo resulta num modelo que aprendeu a prever a palavra mais prov√°vel, dado o contexto de uma sequ√™ncia textual.

**Lema 2.1:**  A derivada da perda cross-entropy em rela√ß√£o √†s probabilidades preditas, $\frac{\partial L_{CE}}{\partial \hat{y}_t[w_{t+1}]}$, √© igual a $-\frac{1}{\hat{y}_t[w_{t+1}]}$.

*Prova:*
I. Temos $L_{CE}(\hat{y}_t, y_t) = - \log(\hat{y}_t[w_{t+1}])$.
II. Aplicando a regra da cadeia para derivar em rela√ß√£o a $\hat{y}_t[w_{t+1}]$, obtemos:
   $$ \frac{\partial L_{CE}}{\partial \hat{y}_t[w_{t+1}]} = -\frac{1}{\hat{y}_t[w_{t+1}]} $$
III. Esta derivada √© usada no algoritmo de backpropagation para calcular os gradientes e ajustar os pesos do modelo.
‚ñ†

#### A Perda Cross-Entropy em Contexto Multiclasse

Note que, em modelos de linguagem, a perda cross-entropy √© aplicada em um contexto multiclasse, j√° que estamos prevendo a probabilidade de cada palavra do vocabul√°rio. O vocabul√°rio pode conter milhares ou mesmo dezenas de milhares de palavras. Para um vocabul√°rio de tamanho $|V|$, o modelo gera uma distribui√ß√£o de probabilidade sobre cada palavra, e a perda cross-entropy avalia a diferen√ßa entre esta distribui√ß√£o e a distribui√ß√£o correta *one-hot* da pr√≥xima palavra.

**Observa√ß√£o:** Em termos pr√°ticos, a implementa√ß√£o da cross-entropy com um vetor *one-hot* √© computacionalmente eficiente. Em vez de calcular o produto interno entre o vetor *one-hot* e as probabilidades preditas, s√≥ √© necess√°rio recuperar a probabilidade da palavra correta do vetor de probabilidades. Isso simplifica o c√°lculo da perda e acelera o processo de treinamento.

### Teacher Forcing e a Computa√ß√£o da Perda
Como discutido anteriormente, usamos **teacher forcing** durante o treinamento [^25]. Essa t√©cnica garante que o modelo receba a sequ√™ncia correta de tokens como entrada para cada previs√£o, em vez de utilizar suas pr√≥prias previs√µes incorretas. Isso impede a propaga√ß√£o de erros ao longo da sequ√™ncia e acelera a converg√™ncia do treinamento. Em cada etapa, a perda √© calculada com base na previs√£o do modelo em rela√ß√£o √† pr√≥xima palavra correta, garantindo que o modelo sempre aprenda com o contexto correto. A perda √© calculada usando a probabilidade atribu√≠da pelo modelo √† palavra correta no contexto dado e os pesos do modelo s√£o ajustados de acordo.

> üí° **Exemplo Num√©rico:**
> Para a frase "O sol brilha forte", o modelo, durante o treinamento com *teacher forcing*, recebe "O" para prever "sol", depois recebe "O sol" para prever "brilha", e assim por diante. Suponha que o vocabul√°rio seja { "o", "sol", "brilha", "forte", "." }. Num dado passo, quando o modelo j√° processou "O sol" e deve prever "brilha", o modelo pode ter as seguintes previs√µes iniciais:
>
>  $\hat{y}_t$ = [P("o")=0.1, P("sol")=0.2, P("brilha")=0.3, P("forte")=0.2, P(".")=0.2]
>
> O vetor *one-hot* correspondente a "brilha" seria:
>
> $y_t$ = [0, 0, 1, 0, 0]
>
> A perda seria ent√£o:
>
> $L_{CE} = - \log(0.3) \approx 1.204$
>
> Se o modelo previsse incorretamente a palavra "forte" com uma probabilidade de 0.6, e "brilha" com 0.1:
>
> $\hat{y}_t$ = [P("o")=0.05, P("sol")=0.05, P("brilha")=0.1, P("forte")=0.6, P(".")=0.2]
>
> A perda seria:
>
> $L_{CE} = - \log(0.1) \approx 2.303$
>
> Esta perda maior indica que o modelo fez uma previs√£o ruim. Contudo, com *teacher forcing*, o modelo n√£o receber√° a sua previs√£o incorreta ("forte") como entrada no passo seguinte. Em vez disso, receber√° o contexto correto "O sol brilha" para prever a palavra seguinte "forte", evitando que este erro se propague. Este mecanismo ajuda o modelo a aprender mais r√°pido e de forma mais est√°vel.
>
> ```mermaid
> graph LR
>     A[Sequ√™ncia de Texto: O sol brilha forte] --> B(Teacher Forcing)
>     B --> C[O -> Prev√™ 'sol']
>     C --> D[O sol -> Prev√™ 'brilha']
>     D --> E[O sol brilha -> Prev√™ 'forte']
>     E --> F[O sol brilha forte -> Prev√™ '.']
>      style C fill:#ccf,stroke:#333,stroke-width:2px
>      style D fill:#ccf,stroke:#333,stroke-width:2px
>      style E fill:#ccf,stroke:#333,stroke-width:2px
>      style F fill:#ccf,stroke:#333,stroke-width:2px
> ```

### Conclus√£o
A fun√ß√£o de perda cross-entropy √© um componente fundamental no treinamento de LLMs. Ela fornece um mecanismo preciso para quantificar o erro de predi√ß√£o do modelo, guiando o processo de treinamento. A minimiza√ß√£o da perda cross-entropy, juntamente com *teacher forcing* e processamento paralelo, permite que modelos de linguagem grandes aprendam a prever sequ√™ncias de texto com not√°vel precis√£o. Este processo √© central para as capacidades de gera√ß√£o de texto que fazem dos LLMs t√£o √∫teis em v√°rias aplica√ß√µes de processamento de linguagem natural.

### Refer√™ncias
[^25]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ¬© 2023. All rights reserved. Draft of February 3, 2024.
[^27]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ¬© 2023. All rights reserved. Draft of February 3, 2024.
<!-- END -->
