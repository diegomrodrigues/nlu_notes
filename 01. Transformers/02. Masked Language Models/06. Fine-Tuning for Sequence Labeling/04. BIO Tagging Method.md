## Fine-Tuning para Sequence Labeling: Uma AnÃ¡lise Detalhada

### IntroduÃ§Ã£o
Este capÃ­tulo explora o ajuste fino (fine-tuning) de modelos de linguagem prÃ©-treinados para tarefas de **sequence labeling**, com foco em como os parÃ¢metros do modelo e um classificador sÃ£o otimizados para prever rÃ³tulos para cada token de uma sequÃªncia. Como vimos anteriormente [^1, 2, 3], o **fine-tuning** Ã© uma tÃ©cnica essencial para adaptar modelos de linguagem a tarefas especÃ­ficas, aproveitando o conhecimento adquirido durante o prÃ©-treinamento. A seÃ§Ã£o atual detalha como essa adaptaÃ§Ã£o Ã© realizada para problemas em que cada token em uma sequÃªncia de texto precisa ser rotulado, o que difere das tarefas de classificaÃ§Ã£o que se focam em classificar a sequÃªncia como um todo [^1, 2, 3]. Este capÃ­tulo irÃ¡ aprofundar o conceito de **sequence labeling** e como modelos de linguagem como BERT sÃ£o adaptados via fine-tuning para esta tarefa. Em particular, discutiremos a arquitetura e as tÃ©cnicas usadas para realizar esta tarefa, incluindo o uso de camadas *feedforward* e *Conditional Random Fields (CRF)*, expandindo sobre o que foi apresentado em seÃ§Ãµes anteriores [^1, 2, 3]. Em especial, exploraremos o uso de **BIO tagging** como um mÃ©todo para modelar o NER (Named Entity Recognition) como uma tarefa de **sequence labeling**, definindo o inÃ­cio, o interior ou a parte de fora de uma entidade nomeada.

### Conceitos Fundamentais

Em **sequence labeling**, o objetivo Ã© atribuir um rÃ³tulo a cada token em uma sequÃªncia de entrada [^1, 2, 3]. Diferentemente da **sequence classification**, onde um Ãºnico rÃ³tulo Ã© atribuÃ­do a toda a sequÃªncia, aqui cada token dentro da sequÃªncia requer uma classificaÃ§Ã£o. Esta abordagem Ã© fundamental para uma variedade de tarefas de processamento de linguagem natural, como o reconhecimento de entidades nomeadas (NER) [^1, 2, 3], *part-of-speech tagging* ou extraÃ§Ã£o de informaÃ§Ã£o. O ajuste fino para **sequence labeling** envolve uma arquitetura onde um modelo prÃ©-treinado de *transformer* Ã© combinado com um classificador de *feedforward* [^1, 2, 3]. Em essÃªncia, o problema de **sequence labeling**, utiliza uma arquitetura similar ao fine-tuning [^1, 2, 3], onde as saÃ­das do transformador sÃ£o levadas para um classificador, ou um CRF, para prever a sequÃªncia de rÃ³tulos.

Para realizar o ajuste fino, passamos o vetor de saÃ­da final do modelo prÃ©-treinado para cada token de entrada para um classificador que produz uma distribuiÃ§Ã£o softmax sobre o conjunto de rÃ³tulos possÃ­veis [^1, 2, 3]. Este classificador aprende uma matriz de pesos $W_k$ de tamanho $[d \times k]$, onde $d$ Ã© a dimensionalidade do modelo e $k$ Ã© o nÃºmero de rÃ³tulos possÃ­veis. A distribuiÃ§Ã£o de probabilidades sobre os rÃ³tulos Ã© entÃ£o usada para computar a perda durante o treinamento. A saÃ­da de cada token, apÃ³s passar pela camada *feedforward*, Ã© usada para determinar o rÃ³tulo apropriado para o token especÃ­fico na sequÃªncia.

A expressÃ£o matemÃ¡tica para o **sequence labeling** com uma Ãºnica camada *feedforward* pode ser descrita da seguinte forma [^1, 2, 3]:
$$
y_i = \text{softmax}(h_i W_k)
$$
$$
t_i = \text{argmax}(y_i)
$$
onde $y_i$ Ã© um vetor de probabilidades sobre os rÃ³tulos para o token $i$, $h_i$ Ã© o vetor de saÃ­da do modelo *transformer* para o token $i$, $W_k$ sÃ£o os pesos da camada *feedforward*, e $t_i$ Ã© o rÃ³tulo previsto (o *argmax* do vetor $y_i$).

> ğŸ’¡ **Exemplo NumÃ©rico:** Suponha que temos um modelo *transformer* com dimensionalidade $d=768$ e estamos trabalhando com uma tarefa de NER com $k=5$ rÃ³tulos (B-PER, I-PER, B-ORG, I-ORG, O). O vetor de saÃ­da $h_i$ do *transformer* para um token especÃ­fico tem dimensÃ£o 768. A matriz de pesos $W_k$ terÃ¡ dimensÃ£o [768 x 5]. Vamos supor um vetor de saÃ­da hipotÃ©tico $h_i$ e uma matriz de pesos $W_k$:
>
> ```python
> import numpy as np
>
> # Vetor de saÃ­da do transformer (exemplo)
> h_i = np.random.rand(768)
>
> # Matriz de pesos da camada feedforward (exemplo)
> W_k = np.random.rand(768, 5)
>
> # Calculo da saida da camada feedforward
> z_i = np.dot(h_i, W_k)
>
> # AplicaÃ§Ã£o do softmax para obter as probabilidades
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> y_i = softmax(z_i)
>
> # Calculo do rÃ³tulo previsto
> t_i = np.argmax(y_i)
>
> print("SaÃ­da do transformer (h_i):", h_i[:5])
> print("Pesos da camada feedforward (W_k):", W_k[:2,:2])
> print("SaÃ­da antes do softmax (z_i):", z_i[:5])
> print("Probabilidades (y_i):", y_i)
> print("RÃ³tulo previsto (t_i):", t_i)
> ```
> A saÃ­da ``y_i`` Ã© um vetor de 5 elementos, onde cada elemento representa a probabilidade de um dos 5 rÃ³tulos para o token. O rÃ³tulo predito ``t_i`` corresponde ao Ã­ndice do elemento com a maior probabilidade. Por exemplo, se ``t_i`` for 2, isso significa que o modelo estÃ¡ prevendo o terceiro rÃ³tulo da lista (Ã­ndice 2) para o token atual.

**ObservaÃ§Ã£o 1:** A escolha da funÃ§Ã£o *softmax* garante que as saÃ­das $y_i$ sejam vÃ¡lidas distribuiÃ§Ãµes de probabilidade, ou seja, todos os valores sÃ£o nÃ£o-negativos e somam 1. Isso Ã© crucial para o uso da entropia cruzada como funÃ§Ã£o de perda, jÃ¡ que esta funÃ§Ã£o opera sobre distribuiÃ§Ãµes de probabilidade.

**ObservaÃ§Ã£o 1.1:** Uma alternativa para a funÃ§Ã£o softmax seria utilizar a funÃ§Ã£o sigmÃ³ide em cenÃ¡rios onde os rÃ³tulos nÃ£o sÃ£o mutuamente exclusivos (e.g. um mesmo token poder ter mÃºltiplos rÃ³tulos). Neste caso, a saÃ­da $y_i$ seria um vetor de probabilidades independentes, e a funÃ§Ã£o de perda poderia ser a *binary cross entropy* para cada rÃ³tulo individualmente.

A funÃ§Ã£o de perda usada no treinamento Ã© tipicamente a entropia cruzada, que mede a diferenÃ§a entre a distribuiÃ§Ã£o prevista e a distribuiÃ§Ã£o real dos rÃ³tulos [^1, 2, 3]. O objetivo do treinamento Ã© ajustar os pesos $W_k$ para minimizar esta perda. A adaptaÃ§Ã£o pode envolver a atualizaÃ§Ã£o nÃ£o apenas dos pesos do classificador, mas tambÃ©m, em alguns casos, os pesos das camadas do *transformer*, embora isso seja menos comum [^1, 2, 3].

> ğŸ’¡ **Exemplo NumÃ©rico:** Vamos supor que para um determinado token, o rÃ³tulo verdadeiro seja o rÃ³tulo 1 (por exemplo, I-PER). O vetor de probabilidade previsto pelo nosso modelo Ã© ``y_i = [0.1, 0.6, 0.1, 0.1, 0.1]``. A distribuiÃ§Ã£o one-hot do rÃ³tulo verdadeiro seria ``[0, 1, 0, 0, 0]``.
> A entropia cruzada Ã© calculada como:
> $$ L = - \sum_{j=1}^{k}  p_j \log(q_j) $$
>  onde $p_j$ Ã© a probabilidade do rÃ³tulo verdadeiro e $q_j$ Ã© a probabilidade prevista.
>
> ```python
> import numpy as np
>
> # Probabilidades previstas (exemplo)
> y_i = np.array([0.1, 0.6, 0.1, 0.1, 0.1])
>
> # RÃ³tulo verdadeiro (one-hot encoding)
> true_label = np.array([0, 1, 0, 0, 0])
>
> # CÃ¡lculo da entropia cruzada
> cross_entropy_loss = -np.sum(true_label * np.log(y_i))
>
> print("Probabilidades previstas:", y_i)
> print("RÃ³tulo verdadeiro (one-hot):", true_label)
> print("Entropia cruzada:", cross_entropy_loss)
> ```
> Este valor da perda Ã© usado para ajustar os pesos do modelo e do classificador atravÃ©s da retropropagaÃ§Ã£o. O objetivo Ã© que, apÃ³s o treinamento, o modelo preveja distribuiÃ§Ãµes de probabilidade mais prÃ³ximas da verdade, e consequentemente, minimize essa perda.

### Detalhes do Processo de Fine-Tuning

1.  **PrÃ©-processamento:** A sequÃªncia de entrada Ã© tokenizada usando um tokenizador de subpalavras, como *WordPiece* ou *SentencePiece* [^1, 2, 3].
2.  **Passagem pelo Modelo:** A sequÃªncia de tokens Ã© passada pelo modelo *transformer* bidirecional [^1, 2, 3], produzindo um vetor de saÃ­da para cada token.
3.  **ClassificaÃ§Ã£o:** Cada vetor de saÃ­da Ã© passado por uma camada *feedforward* seguida por uma funÃ§Ã£o *softmax*. O resultado Ã© uma distribuiÃ§Ã£o de probabilidades sobre os rÃ³tulos possÃ­veis para cada token.
4.  **CÃ¡lculo da Perda:** Usamos a funÃ§Ã£o de perda de entropia cruzada para comparar a distribuiÃ§Ã£o de probabilidades prevista com o rÃ³tulo verdadeiro de cada token.
5.  **RetropropagaÃ§Ã£o:** Os gradientes da perda sÃ£o calculados e usados para atualizar os pesos do classificador $W_k$ e, opcionalmente, os pesos do *transformer*.
6.  **RepetiÃ§Ã£o:** Repetimos os passos 2 a 5 em um conjunto de dados de treinamento rotulado atÃ© que o modelo convirja.

**Lema 1:** O processo de retropropagaÃ§Ã£o (passo 5) usa a regra da cadeia para calcular os gradientes da funÃ§Ã£o de perda em relaÃ§Ã£o aos pesos da rede. Isso permite atualizar iterativamente os pesos para minimizar a perda. Formalmente, seja $L$ a funÃ§Ã£o de perda, o gradiente de $L$ em relaÃ§Ã£o a um peso $w$ Ã© dado por $\frac{\partial L}{\partial w} = \frac{\partial L}{\partial y_i} \frac{\partial y_i}{\partial w}$.

**Prova do Lema 1:**
Para provar o lema 1, vamos demonstrar como a regra da cadeia Ã© aplicada para calcular o gradiente da funÃ§Ã£o de perda $L$ em relaÃ§Ã£o a um peso $w$.

I. Seja $L$ a funÃ§Ã£o de perda que depende de $y_i$, e $y_i$ depende dos pesos $w$ da rede. Queremos encontrar $\frac{\partial L}{\partial w}$.

II. Pela regra da cadeia, o gradiente de $L$ em relaÃ§Ã£o a $w$ pode ser expresso como:
    $$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial y_i} \cdot \frac{\partial y_i}{\partial w}$$
   Este passo quebra o problema em dois termos: como a perda $L$ muda em relaÃ§Ã£o Ã  saÃ­da do classificador $y_i$, e como a saÃ­da $y_i$ muda em relaÃ§Ã£o aos pesos $w$.

III. O termo $\frac{\partial L}{\partial y_i}$ representa o gradiente da funÃ§Ã£o de perda em relaÃ§Ã£o Ã  saÃ­da do classificador, e este depende da funÃ§Ã£o de perda especifica que esta sendo usada. Por exemplo, se a funÃ§Ã£o de perda Ã© a entropia cruzada, podemos calcular este termo usando as derivadas da entropia cruzada em relaÃ§Ã£o a $y_i$.

IV. O termo $\frac{\partial y_i}{\partial w}$ representa o gradiente da saÃ­da do classificador em relaÃ§Ã£o aos pesos $w$. Este termo depende da estrutura da camada de classificador, que, neste caso, Ã© uma camada *feedforward* seguida por um *softmax*. O cÃ¡lculo desse gradiente Ã© feito aplicando a regra da cadeia novamente, no entanto, o resultado final Ã© que o gradiente depende dos valores dos pesos e dos valores de ativaÃ§Ã£o da camada de entrada. Especificamente, se $y_i = \text{softmax}(h_i W_k)$ e $z_i = h_i W_k$, entÃ£o $\frac{\partial y_i}{\partial w} = \frac{\partial y_i}{\partial z_i} \frac{\partial z_i}{\partial w}$.

V. Portanto, ao multiplicar esses dois termos, obtemos o gradiente da funÃ§Ã£o de perda em relaÃ§Ã£o aos pesos $w$, $\frac{\partial L}{\partial w}$, que Ã© entÃ£o usado no processo de retropropagaÃ§Ã£o para atualizar iterativamente os pesos e minimizar a perda. $\blacksquare$

### NER como um Exemplo de Sequence Labeling
Para ilustrar o **sequence labeling** em prÃ¡tica, usamos o exemplo do reconhecimento de entidades nomeadas (NER). NER envolve a identificaÃ§Ã£o de *spans* de texto que representam nomes prÃ³prios e a classificaÃ§Ã£o desses *spans* em categorias como pessoas (PER), organizaÃ§Ãµes (ORG), locais (LOC), ou entidades geogrÃ¡ficas-polÃ­ticas (GPE) [^1, 2, 3]. No exemplo da seÃ§Ã£o anterior, "Jane Villanueva" e "United Airlines Holding" foram identificadas como entidades nomeadas, com "Jane Villanueva" sendo classificada como uma pessoa e "United Airlines Holding" como uma organizaÃ§Ã£o [^1, 2, 3].

Para modelar NER usando **sequence labeling**, usamos *BIO tagging* [^1, 2, 3]. O *BIO tagging* atribui um rÃ³tulo a cada token que indica se o token comeÃ§a uma entidade (B), estÃ¡ dentro de uma entidade (I) ou nÃ£o faz parte de nenhuma entidade (O). Este sistema de rotulagem nos permite capturar a extensÃ£o e o tipo de cada entidade na sequÃªncia. Usando o *BIO tagging* com modelos como o BERT, podemos aplicar o *fine-tuning* para otimizar os parÃ¢metros para prever as tags BIO corretas para cada token.

> ğŸ’¡ **Exemplo NumÃ©rico:** Consideremos a frase "Apple anunciou um novo iPhone em Cupertino". Usando o *BIO tagging* para NER, terÃ­amos as seguintes etiquetas:
>
> | Token     | RÃ³tulo |
> |-----------|--------|
> | Apple     | B-ORG  |
> | anunciou  | O      |
> | um        | O      |
> | novo      | O      |
> | iPhone    | B-PROD |
> | em        | O      |
> | Cupertino | B-LOC  |
>
>  Aqui, "Apple" Ã© o inÃ­cio (B) de uma organizaÃ§Ã£o (ORG), "iPhone" Ã© o inÃ­cio de um produto (PROD), e "Cupertino" Ã© o inÃ­cio de uma localizaÃ§Ã£o (LOC). As outras palavras sÃ£o rotuladas como O (fora de qualquer entidade nomeada). Este tipo de rotulaÃ§Ã£o Ã© essencial para o treinamento de modelos de **sequence labeling** para NER. Em essÃªncia, o *BIO tagging* transforma um problema de detecÃ§Ã£o de *spans* em um problema de rotulaÃ§Ã£o de tokens, tornando possÃ­vel o uso de modelos de *sequence labeling* para NER.

### ConsideraÃ§Ãµes Importantes

- **Alinhamento de Tokens e RÃ³tulos:** O tokenizador de subpalavras pode resultar em tokens que nÃ£o correspondem diretamente Ã s palavras. Em tarefas de NER, onde as anotaÃ§Ãµes sÃ£o geralmente feitas em palavras, um dos desafios Ã© lidar com esse desalinhamento [^1, 2, 3]. Para o treinamento, podemos simplesmente atribuir o rÃ³tulo da palavra a todos os sub-tokens derivados da mesma. Para a decodificaÃ§Ã£o, uma abordagem comum Ã© usar o rÃ³tulo do primeiro subtoken para representar a palavra.

- **CRF:** Podemos passar os rÃ³tulos da camada *softmax* para uma camada *Conditional Random Field* (CRF), que pode modelar transiÃ§Ãµes entre rÃ³tulos [^1, 2, 3]. A camada CRF Ã© especialmente Ãºtil em problemas como NER, onde as transiÃ§Ãµes de rÃ³tulo tem dependÃªncias.

**Teorema 1:** A utilizaÃ§Ã£o de um CRF apÃ³s a camada softmax em tarefas de **sequence labeling** como NER, pode levar a uma melhoria no desempenho, em especial em cenÃ¡rios com forte dependÃªncia contextual entre rÃ³tulos. Isso ocorre porque o CRF modela explicitamente a probabilidade de uma sequÃªncia de rÃ³tulos, e nÃ£o apenas a probabilidade de um rÃ³tulo individual, como faz uma camada *softmax* isolada.

**Prova do Teorema 1:**

Para provar o teorema 1, vamos demonstrar porque o uso de um CRF apÃ³s o softmax em **sequence labeling** pode levar a uma melhoria no desempenho, especialmente quando hÃ¡ dependÃªncias contextuais entre os rÃ³tulos.

I. Em um modelo de **sequence labeling** com uma camada *softmax* isolada, a probabilidade de um rÃ³tulo para um token Ã© calculada independentemente de outros tokens na sequÃªncia. Isso ignora as dependÃªncias contextuais entre rÃ³tulos adjacentes.

II. Um modelo CRF, por outro lado, modela a probabilidade de toda a sequÃªncia de rÃ³tulos, levando em consideraÃ§Ã£o as transiÃ§Ãµes entre rÃ³tulos adjacentes. Formalmente, a probabilidade de uma sequÃªncia de rÃ³tulos $y = [y_1, y_2, \ldots, y_n]$ dado uma sequÃªncia de entrada $x$ Ã© modelada como:
    $$P(y|x) = \frac{1}{Z(x)} \exp(\sum_{i=1}^{n} A_{y_{i-1}, y_i} + \sum_{i=1}^{n} P(y_i|x))$$
     onde $A_{y_{i-1}, y_i}$ representa os *scores* de transiÃ§Ã£o entre os rÃ³tulos $y_{i-1}$ e $y_i$, $P(y_i|x)$ sÃ£o os *scores* obtidos da camada *softmax* para o rÃ³tulo $y_i$ e $Z(x)$ Ã© um fator de normalizaÃ§Ã£o que garante que a distribuiÃ§Ã£o $P(y|x)$ seja uma distribuiÃ§Ã£o de probabilidade vÃ¡lida.

III. Ao modelar transiÃ§Ãµes de rÃ³tulos usando os *scores* $A_{y_{i-1}, y_i}$, o CRF consegue capturar as dependÃªncias contextuais que sÃ£o comuns em tarefas como NER. Por exemplo, Ã© muito mais provÃ¡vel que um rÃ³tulo 'I-PER' (inside person) siga um rÃ³tulo 'B-PER' (begin person) do que um rÃ³tulo 'O' (outside). O CRF atribui scores de transiÃ§Ã£o mais altos para sequÃªncias que seguem regras como essa, e penaliza sequÃªncias improvÃ¡veis.

IV. Portanto, o CRF modela a probabilidade conjunta de uma sequÃªncia de rÃ³tulos, em vez de rÃ³tulos independentes. A consideraÃ§Ã£o da probabilidade da sequÃªncia completa permite que o CRF faÃ§a previsÃµes mais coerentes e precisas.

V. Em resumo, ao modelar as dependÃªncias entre rÃ³tulos, o CRF pode melhorar a precisÃ£o das previsÃµes, especialmente em cenÃ¡rios onde as dependÃªncias contextuais entre os rÃ³tulos sÃ£o fortes. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:** Suponha que o modelo *softmax* preveja as seguintes probabilidades para a sequÃªncia de rÃ³tulos "B-PER", "I-PER", "O":
>  - Para o primeiro token: $P(\text{B-PER}) = 0.8$, $P(\text{I-PER}) = 0.1$, $P(\text{O}) = 0.1$.
> - Para o segundo token: $P(\text{B-PER}) = 0.2$, $P(\text{I-PER}) = 0.7$, $P(\text{O}) = 0.1$.
> - Para o terceiro token: $P(\text{B-PER}) = 0.1$, $P(\text{I-PER}) = 0.2$, $P(\text{O}) = 0.7$.
>
>  Um CRF pode modelar transiÃ§Ãµes mais provÃ¡veis, como a transiÃ§Ã£o de B-PER para I-PER, e penalizar transiÃ§Ãµes improvÃ¡veis como B-PER para O. Os pesos de transiÃ§Ã£o podem ser expressos como uma matriz, onde cada elemento $A_{ij}$ representa a pontuaÃ§Ã£o da transiÃ§Ã£o do rÃ³tulo $i$ para o rÃ³tulo $j$.
>
> ```python
> import numpy as np
>
> # Probabilidades de saida do softmax (exemplo)
> softmax_probs = np.array([
>    [0.8, 0.1, 0.1], # B-PER, I-PER, O para o primeiro token
>    [0.2, 0.7, 0.1], # B-PER, I-PER, O para o segundo token
>    [0.1, 0.2, 0.7]  # B-PER, I-PER, O para o terceiro token
> ])
>
> # Matriz de transiÃ§Ã£o CRF (exemplo)
> transition_scores = np.array([
>    [0.5, 1.0, -2.0], # B-PER para B-PER, I-PER, O
>    [-1.0, 0.8, -0.5],# I-PER para B-PER, I-PER, O
>    [-0.5, -1.0, 0.9] # O para B-PER, I-PER, O
> ])
>
> def calculate_sequence_score(softmax_probs, transition_scores, labels):
>  score = 0
>  for i, label_idx in enumerate(labels):
>      score += np.log(softmax_probs[i][label_idx])
>      if i > 0:
>        score += transition_scores[labels[i-1]][label_idx]
>  return score
>
> labels1 = [0,1,2] # Sequencia B-PER, I-PER, O
> labels2 = [0,0,2] # Sequencia B-PER, B-PER, O
>
> score1 = calculate_sequence_score(softmax_probs, transition_scores, labels1)
> score2 = calculate_sequence_score(softmax_probs, transition_scores, labels2)
> print(f"PontuaÃ§Ã£o da sequÃªncia B-PER, I-PER, O: {score1:.2f}")
> print(f"PontuaÃ§Ã£o da sequÃªncia B-PER, B-PER, O: {score2:.2f}")
> ```
>
> No exemplo, a pontuaÃ§Ã£o da sequÃªncia correta (B-PER, I-PER, O) Ã© maior do que a da sequÃªncia incorreta (B-PER, B-PER, O), mostrando como o CRF ajuda a modelar as dependÃªncias e transiÃ§Ãµes de rÃ³tulos.

- **MÃ©tricas de AvaliaÃ§Ã£o:** Os modelos de **sequence labeling** sÃ£o avaliados usando mÃ©tricas como precisÃ£o, *recall*, e *F1-score*, que medem a eficÃ¡cia do modelo na previsÃ£o de rÃ³tulos [^1, 2, 3]. Essas mÃ©tricas sÃ£o calculadas tanto no nÃ­vel do token quanto no nÃ­vel da entidade.

**CorolÃ¡rio 1.1:** Ao avaliar modelos de NER, Ã© importante reportar mÃ©tricas tanto no nÃ­vel do token quanto no nÃ­vel da entidade. As mÃ©tricas em nÃ­vel de token fornecem uma visÃ£o da capacidade do modelo em rotular corretamente cada token individualmente, enquanto as mÃ©tricas em nÃ­vel da entidade refletem a precisÃ£o do modelo na detecÃ§Ã£o e classificaÃ§Ã£o de entidades completas.

**Prova do CorolÃ¡rio 1.1:**

Para demonstrar a importÃ¢ncia de reportar mÃ©tricas de avaliaÃ§Ã£o tanto no nÃ­vel do token quanto no nÃ­vel da entidade para tarefas de NER, vamos analisar as diferenÃ§as e complementaridades dessas medidas:

I.  **MÃ©tricas no nÃ­vel do token**: Essas mÃ©tricas (precisÃ£o, *recall* e *F1-score*) sÃ£o calculadas considerando cada token individualmente. Elas avaliam se cada token foi rotulado corretamente ou nÃ£o.

    *   A *precisÃ£o* no nÃ­vel do token mede a proporÃ§Ã£o de tokens rotulados corretamente em relaÃ§Ã£o a todos os tokens que o modelo rotulou como parte de alguma entidade.
    *   O *recall* no nÃ­vel do token mede a proporÃ§Ã£o de tokens rotulados corretamente em relaÃ§Ã£o a todos os tokens que *realmente* fazem parte de alguma entidade.
    *   O *F1-score* no nÃ­vel do token Ã© a mÃ©dia harmÃ´nica entre precisÃ£o e *recall*, fornecendo uma mÃ©trica balanceada.

II. **MÃ©tricas no nÃ­vel da entidade**: Essas mÃ©tricas sÃ£o calculadas considerando as entidades como um todo. Uma entidade Ã© considerada corretamente identificada apenas se seu *span* completo foi detectado corretamente e todos os rÃ³tulos de tokens dentro do *span* estiverem corretos.

    *   A *precisÃ£o* no nÃ­vel da entidade mede a proporÃ§Ã£o de entidades corretamente identificadas em relaÃ§Ã£o ao total de entidades que o modelo detectou.
    *   O *recall* no nÃ­vel da entidade mede a proporÃ§Ã£o de entidades corretamente identificadas em relaÃ§Ã£o ao total de entidades presentes no conjunto de dados.
    *   O *F1-score* no nÃ­vel da entidade Ã© a mÃ©dia harmÃ´nica entre precisÃ£o e *recall* no nÃ­vel da entidade.

III. **Complementaridade:** As mÃ©tricas no nÃ­vel do token avaliam o desempenho em termos de cada rÃ³tulo de token individual, enquanto as mÃ©tricas no nÃ­vel da entidade avaliam o desempenho em termos da identificaÃ§Ã£o correta de *spans* e tipos de entidades.

    *   Por exemplo, um modelo pode ter uma alta precisÃ£o no nÃ­vel do token, mas ter um baixo *recall* no nÃ­vel da entidade se ele frequentemente rotular entidades incorretamente, por exemplo, rotulando apenas alguns dos tokens que compÃµem a entidade corretamente, ou fazendo uma mÃ¡ delimitaÃ§Ã£o dos *spans* da entidade.
    *   Em contrapartida, um modelo pode ter um alto *recall* no nÃ­vel da entidade, mas baixa precisÃ£o no nÃ­vel do token se ele muitas vezes errar na rotulaÃ§Ã£o dos tokens dentro das entidades, ou rotulando entidades que nÃ£o existem.

IV. **ConclusÃ£o:** Ao reportar ambas as mÃ©tricas, avaliamos o desempenho do modelo de maneira abrangente. MÃ©trica de nÃ­vel do token nos informa a capacidade do modelo de rotular cada token corretamente, enquanto a mÃ©trica de nÃ­vel da entidade nos informa se o modelo Ã© capaz de identificar corretamente entidades completas. Portanto, Ã© crucial reportar ambas as mÃ©tricas para ter uma avaliaÃ§Ã£o completa da capacidade do modelo em tarefas de NER. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:** Vamos supor que nosso modelo tenha as seguintes previsÃµes para uma frase (com entidades em negrito) : "A **Apple** lanÃ§ou o novo **iPhone** em **Cupertino**".
>
>  **RÃ³tulos verdadeiros:**
>
>   - A: O
>   - Apple: B-ORG
>   - lanÃ§ou: O
>   - o: O
>   - novo: O
>   - iPhone: B-PROD
>   - em: O
>   - Cupertino: B-LOC
>
> **RÃ³tulos previstos:**
>
>  - A: O
>   - Apple: B-ORG
>   - lanÃ§ou: O
>   - o: O
>   - novo: O
>   - iPhone: I-PROD  *(erro)*
>   - em: O
>   - Cupertino: B-LOC
>
> **AnÃ¡lise:**
>
> *   **NÃ­vel do Token:**
>     *   **PrecisÃ£o:** 7/8 = 0.875 (7 rÃ³tulos corretos de 8 previstos como entidade)
>     *   **Recall:** 7/8 = 0.875 (7 rÃ³tulos corretos de 8 rÃ³tulos reais como entidade)
>     *  **F1-Score:** 2 * (0.875*0.875) / (0.875 + 0.875) = 0.875
> *   **NÃ­vel da Entidade:**
>     *   **PrecisÃ£o:** 2/2 = 1.0 (2 entidades detectadas corretamente de 2 detectadas)
>     *   **Recall:** 2/3 = 0.67 (2 entidades detectadas corretamente de 3 entidades reais)
>     *   **F1-Score:** 2 * (1.0 * 0.67) / (1.0 + 0.67) = 0.80
>
>  Note que, apesar do bom desempenho no nÃ­vel do token, o *recall* no nÃ­vel da entidade Ã© mais baixo porque o modelo errou ao rotular o token "iPhone" como "I-PROD" em vez de "B-PROD", o que resultou em uma entidade incorreta. Este exemplo ilustra a importÃ¢ncia de reportar mÃ©tricas em ambos os nÃ­veis.

**ProposiÃ§Ã£o 1:** A escolha da arquitetura para o classificador em **sequence labeling** (e.g., uso de uma simples camada feedforward ou um CRF) pode impactar no desempenho do modelo de maneira considerÃ¡vel, dependendo da tarefa e das dependÃªncias entre rÃ³tulos. Tarefas com fortes dependÃªncias contextuais podem se beneficiar mais do uso de um CRF, enquanto tarefas com dependÃªncias mais fracas podem ter um bom desempenho com uma camada feedforward simples.

**Prova da ProposiÃ§Ã£o 1:**

Para demonstrar a influÃªncia da arquitetura do classificador no desempenho do modelo de **sequence labeling**, vamos discutir como diferentes escolhas de arquitetura impactam o modelo em tarefas distintas:

I. **Camada Feedforward Simples:** A camada feedforward (seguida pelo *softmax*) opera independentemente em cada token, ou seja, a previsÃ£o do rÃ³tulo de um token nÃ£o depende da previsÃ£o dos rÃ³tulos adjacentes. Matematicamente, isso pode ser representado por $y_i = \text{softmax}(h_i W_k)$, onde a probabilidade de um rÃ³tulo para o token $i$ depende apenas do vetor de entrada $h_i$ e dos pesos $W_k$ da camada *feedforward*.

     *  **Vantagens:** Simples e computacionalmente eficiente. Funciona bem em tarefas onde as dependÃªncias entre rÃ³tulos sÃ£o fracas ou inexistentes (ex: classificaÃ§Ã£o de sentimento por token, quando o contexto Ã© pequeno).
     * **Desvantagens:** NÃ£o captura dependÃªncias sequenciais entre rÃ³tulos.  Pode apresentar dificuldades em cenÃ¡rios onde a probabilidade de um rÃ³tulo depende de rÃ³tulos precedentes ou subsequentes.

II. **Conditional Random Field (CRF):** O CRF, por sua vez, modela a probabilidade de uma sequÃªncia de rÃ³tulos, levando em consideraÃ§Ã£o as transiÃ§Ãµes entre eles. Isso permite que o modelo aprenda dependÃªncias sequenciais entre os rÃ³tulos. Formalmente, um CRF modela a probabilidade de uma sequÃªncia de rÃ³tulos $y$ dada uma sequÃªncia de entrada $x$ como:
    $$P(y|x) = \frac{1}{Z(x)} \exp(\sum_{i=1}^{n} A_{y_{i-1}, y_i} + \sum_{i=1}^{n} P(y_i|x))$$
    onde o termo $A_{y_{i-1}, y_i}$ modela as dependÃªncias de transiÃ§Ã£o entre os rÃ³tulos, e $P(y_i|x)$ Ã© a saÃ­da da camada *softmax* para o token $i$.

    *  **Vantagens:** Modelagem de dependÃªncias entre rÃ³tulos, levando a previsÃµes mais consistentes. Ãštil para tarefas como NER ou part-of-speech tagging onde a ordem dos rÃ³tulos Ã© importante.
    *  **Desvantagens:** Computacionalmente mais custoso que uma camada *feedforward* simples. Requer um treinamento mais cuidadoso e pode ser mais difÃ­cil de otimizar.

III. **Impacto nas Tarefas:**

    *   **NER:** No NER, por exemplo, um token com rÃ³tulo 'I-PER' geralmente precede ou segue um rÃ³tulo 'B-PER'. Um modelo *feedforward* simples nÃ£o captura essa dependÃªncia, enquanto um CRF faz isso de forma natural, atribuindo *scores* de transiÃ§Ã£o mais altos para sequÃªncias de rÃ³tulos com transiÃ§Ãµes vÃ¡lidas.
    *   **Part-of-Speech Tagging:** Similarmente, em part-of-speech tagging, a tag de um verbo provavelmente serÃ¡ precedida por um substantivo ou pronome. O CRF modela bem essas transiÃ§Ãµes gramaticais.
    *   **ClassificaÃ§Ã£o de Sentimento:** Tarefas como a classificaÃ§Ã£o de sentimento por token, onde cada token expressa um sentimento independente, podem ter bom desempenho com uma camada *feedforward* simples, pois as dependÃªncias sequenciais sÃ£o mÃ­nimas.

IV. **ConclusÃ£o:** A escolha da arquitetura do classificador deve ser feita em funÃ§Ã£o da natureza da tarefa. Para tarefas com fortes dependÃªncias contextuais, o CRF geralmente Ã© a melhor escolha, pois consegue modelar as transiÃ§Ãµes entre rÃ³tulos,  enquanto para tarefas com dependÃªncias mais fracas, a camada *feedforward* simples pode ser suficiente, sendo mais simples e computacionalmente mais eficiente. A arquitetura mais adequada para o classificador depende da complexidade da tarefa e das caracterÃ­sticas dos dados, com tarefas complexas podendo se beneficiar de modelos que consideram a dependÃªncia entre rÃ³tulos. $\blacksquare$

**Teorema 1.1:** Em tarefas de **sequence labeling** com um nÃºmero elevado de rÃ³tulos, o uso de um CRF pode se tornar computacionalmente proibitivo devido ao custo de calcular a matriz de transiÃ§Ãµes entre rÃ³tulos. Nesses casos, pode ser Ãºtil recorrer a tÃ©cnicas de simplificaÃ§Ã£o ou aproximaÃ§Ã£o do CRF, ou ainda, explorar outras alternativas como modelos que utilizem redes neurais recorrentes para modelar as dependÃªncias entre rÃ³tulos.

**Prova do Teorema 1.1:**

Para provar o teorema 1.1, vamos discutir as limitaÃ§Ãµes computacionais do CRF em tarefas de **sequence labeling** com um grande nÃºmero de rÃ³tulos e explorar alternativas.

I. **Complexidade do CRF:** A principal limitaÃ§Ã£o computacional do CRF reside no cÃ¡lculo da funÃ§Ã£o de partiÃ§Ã£o $Z(x)$ e das probabilidades de transiÃ§Ã£o entre os rÃ³tulos. A funÃ§Ã£o de partiÃ§Ã£o envolve a soma sobre todas as possÃ­veis sequÃªncias de rÃ³tulos, o que resulta em uma complexidade exponencial em relaÃ§Ã£o ao tamanho da sequÃªncia e o nÃºmero de rÃ³tulos.  No caso de um grande nÃºmero de rÃ³tulos, o custo computacional aumenta drasticamente, tornando o treinamento e a inferÃªncia impraticÃ¡veis.

II. **Matriz de TransiÃ§Ã£o:** O CRF tambÃ©m mantÃ©m uma matriz de transiÃ§Ã£o $A$ de tamanho $k \times k$, onde $k$ Ã© o nÃºmero de rÃ³tulos. Essa matriz armazena os scores para todas as possÃ­veis transiÃ§Ãµes entre os rÃ³tulos. Quando $k$ Ã© grande, a memÃ³ria necessÃ¡ria para armazenar essa matriz tambÃ©m aumenta, podendo se tornar um gargalo. O cÃ¡lculo da funÃ§Ã£o de partiÃ§Ã£o exige que todos os termos nesta matriz sejam considerados.

III. **Impacto do nÃºmero de rÃ³tulos:** Em tarefas como NER com um nÃºmero limitado de rÃ³tulos (e.g. B-PER, I-PER, B-ORG, I-ORG, O), o custo computacional do CRF pode ser administrÃ¡vel. No entanto, em tarefas mais complexas, como *fine-grained entity typing* ou *part-of-speech tagging* com muitos rÃ³tulos, o uso de um CRF se torna mais desafiador.

IV. **Alternativas:** Em cenÃ¡rios onde o CRF se torna inviÃ¡vel, diversas abordagens podem ser utilizadas:

    *   **CRFs Aproximados:** Existem aproximaÃ§Ãµes para o CRF, que reduzem a complexidade do cÃ¡lculo da funÃ§Ã£o de partiÃ§Ã£o. Por exemplo, o *linear-chain CRF* Ã© uma aproximaÃ§Ã£o que limita as dependÃªncias entre rÃ³tulos e pode simplificar o problema. No entanto, estas simplificaÃ§Ãµes podem reduzir a capacidade dommodelo de capturar as complexas dependÃªncias entre os rÃ³tulos.

#### 3.2.2 Treinamento de CRFs

O treinamento de um CRF envolve a estimaÃ§Ã£o dos pesos das funÃ§Ãµes de caracterÃ­sticas de forma a maximizar a probabilidade dos dados de treinamento. Isso Ã© tipicamente feito atravÃ©s da maximizaÃ§Ã£o da verossimilhanÃ§a ou minimizaÃ§Ã£o da perda negativa de log-verossimilhanÃ§a.

**FunÃ§Ã£o de VerossimilhanÃ§a:** Dado um conjunto de dados de treinamento $\mathcal{D} = \{(x^{(i)}, y^{(i)})\}_{i=1}^{N}$, onde $x^{(i)}$ Ã© uma sequÃªncia de entrada e $y^{(i)}$ Ã© a sequÃªncia de rÃ³tulos correspondente, a funÃ§Ã£o de verossimilhanÃ§a para um CRF Ã© dada por:

$$
L(\lambda) = \prod_{i=1}^{N} P(y^{(i)}|x^{(i)}; \lambda)
$$

onde $\lambda$ Ã© o vetor de parÃ¢metros (pesos) do modelo e $P(y|x;\lambda)$ Ã© a probabilidade condicional calculada pelo CRF.

**Log-VerossimilhanÃ§a Negativa:** Em vez de maximizar a verossimilhanÃ§a, Ã© comum minimizar a log-verossimilhanÃ§a negativa, que Ã© dada por:

$$
\mathcal{L}(\lambda) = -\sum_{i=1}^{N} \log P(y^{(i)}|x^{(i)}; \lambda)
$$

O treinamento envolve encontrar os parÃ¢metros $\lambda$ que minimizam $\mathcal{L}(\lambda)$.

**OtimizaÃ§Ã£o:** O problema de otimizaÃ§Ã£o pode ser resolvido utilizando algoritmos de gradiente, como o gradiente descendente (GD) ou seus variantes como o Adam. O cÃ¡lculo do gradiente da log-verossimilhanÃ§a negativa requer o uso de algoritmos de forward-backward, que permitem calcular eficientemente as probabilidades marginais.

#### 3.2.3 InferÃªncia em CRFs

A inferÃªncia em CRFs envolve encontrar a sequÃªncia de rÃ³tulos mais provÃ¡vel $y^*$ dado uma sequÃªncia de entrada $x$ e os parÃ¢metros do modelo $\lambda$:

$$
y^* = \arg \max_y P(y|x; \lambda)
$$

O problema de inferÃªncia pode ser resolvido utilizando o algoritmo de Viterbi, que garante encontrar a sequÃªncia de rÃ³tulos Ã³tima (mais provÃ¡vel) de forma eficiente.

**Algoritmo de Viterbi:** O algoritmo de Viterbi utiliza programaÃ§Ã£o dinÃ¢mica para encontrar a melhor sequÃªncia de rÃ³tulos. Ele calcula recursivamente a melhor pontuaÃ§Ã£o atÃ© cada posiÃ§Ã£o na sequÃªncia para cada possÃ­vel rÃ³tulo e, em seguida, rastreia a sequÃªncia de rÃ³tulos Ã³tima.

##### Exemplo de InferÃªncia:

Suponha que temos um CRF para POS tagging e a seguinte sequÃªncia de entrada: "O gato preto corre rapidamente." ApÃ³s o treinamento, o modelo pode inferir a sequÃªncia de rÃ³tulos mais provÃ¡vel:

* "O" -> DET (Determinante)
* "gato" -> NOUN (Substantivo)
* "preto" -> ADJ (Adjetivo)
* "corre" -> VERB (Verbo)
* "rapidamente" -> ADV (AdvÃ©rbio)

O algoritmo de Viterbi encontra a sequÃªncia de rÃ³tulos que maximiza a probabilidade condicional $P(y|x;\lambda)$, dada a sequÃªncia de entrada "O gato preto corre rapidamente.".

#### 3.2.4 AplicaÃ§Ãµes dos CRFs

CRFs tÃªm uma ampla gama de aplicaÃ§Ãµes em processamento de linguagem natural e outras Ã¡reas, incluindo:

*   **POS tagging:** DeterminaÃ§Ã£o da classe gramatical de cada palavra em uma frase.
*   **Reconhecimento de entidades nomeadas (NER):** IdentificaÃ§Ã£o e classificaÃ§Ã£o de entidades como pessoas, organizaÃ§Ãµes e locais.
*   **SegmentaÃ§Ã£o de palavras:** Dividir texto em palavras individuais, especialmente em idiomas sem espaÃ§o entre palavras.
*   **AnÃ¡lise de sentimento:** ClassificaÃ§Ã£o do sentimento expresso em um texto.
*   **BioinformÃ¡tica:** AnÃ¡lise de sequÃªncias biolÃ³gicas, como DNA e proteÃ­nas.

#### 3.2.5 Vantagens e Desvantagens dos CRFs

**Vantagens:**

*   **Flexibilidade:** Podem incorporar uma variedade de caracterÃ­sticas.
*   **Modelagem de dependÃªncias:** Modelam dependÃªncias complexas entre rÃ³tulos.
*   **Robustez:** Geralmente sÃ£o robustos para dados de treinamento ruidosos.

**Desvantagens:**

*   **Treinamento:** O treinamento pode ser computacionalmente caro.
*   **Interpretabilidade:** Os pesos do modelo podem ser difÃ­ceis de interpretar.

### 3.3 Redes Neurais Recorrentes (RNNs)

Redes Neurais Recorrentes (RNNs) sÃ£o uma classe de redes neurais que foram projetadas para lidar com dados sequenciais. Ao contrÃ¡rio das redes neurais feedforward, as RNNs mantÃªm uma memÃ³ria interna (estado oculto) que permite processar sequÃªncias de dados, como texto, sÃ©ries temporais e outras sequÃªncias de dados variÃ¡veis.

<!-- END -->
