## Fine-Tuning para Sequence Labeling: Uma An√°lise Detalhada

### Introdu√ß√£o
Este cap√≠tulo explora o ajuste fino (fine-tuning) de modelos de linguagem pr√©-treinados para tarefas de **sequence labeling**, com foco em como os par√¢metros do modelo e um classificador s√£o otimizados para prever r√≥tulos para cada token de uma sequ√™ncia. Como vimos anteriormente [^1, 2, 3], o **fine-tuning** √© uma t√©cnica essencial para adaptar modelos de linguagem a tarefas espec√≠ficas, aproveitando o conhecimento adquirido durante o pr√©-treinamento. A se√ß√£o atual detalha como essa adapta√ß√£o √© realizada para problemas em que cada token em uma sequ√™ncia de texto precisa ser rotulado, o que difere das tarefas de classifica√ß√£o que se focam em classificar a sequ√™ncia como um todo [^1, 2, 3]. Este cap√≠tulo ir√° aprofundar o conceito de **sequence labeling** e como modelos de linguagem como BERT s√£o adaptados via fine-tuning para esta tarefa. Em particular, discutiremos a arquitetura e as t√©cnicas usadas para realizar esta tarefa, incluindo o uso de camadas *feedforward* e *Conditional Random Fields (CRF)*, expandindo sobre o que foi apresentado em se√ß√µes anteriores [^1, 2, 3]. Em especial, exploraremos o uso de **BIO tagging** como um m√©todo para modelar o NER (Named Entity Recognition) como uma tarefa de **sequence labeling**, definindo o in√≠cio, o interior ou a parte de fora de uma entidade nomeada [^1, 2, 3].

### Conceitos Fundamentais

Em **sequence labeling**, o objetivo √© atribuir um r√≥tulo a cada token em uma sequ√™ncia de entrada [^1, 2, 3]. Diferentemente da **sequence classification**, onde um √∫nico r√≥tulo √© atribu√≠do a toda a sequ√™ncia, aqui cada token dentro da sequ√™ncia requer uma classifica√ß√£o. Esta abordagem √© fundamental para uma variedade de tarefas de processamento de linguagem natural, como o reconhecimento de entidades nomeadas (NER) [^1, 2, 3], *part-of-speech tagging* ou extra√ß√£o de informa√ß√£o. O ajuste fino para **sequence labeling** envolve uma arquitetura onde um modelo pr√©-treinado de *transformer* √© combinado com um classificador de *feedforward* [^1, 2, 3]. Em ess√™ncia, o problema de **sequence labeling**, utiliza uma arquitetura similar ao fine-tuning [^1, 2, 3], onde as sa√≠das do transformador s√£o levadas para um classificador, ou um CRF, para prever a sequ√™ncia de r√≥tulos.

Para realizar o ajuste fino, passamos o vetor de sa√≠da final do modelo pr√©-treinado para cada token de entrada para um classificador que produz uma distribui√ß√£o softmax sobre o conjunto de r√≥tulos poss√≠veis [^1, 2, 3]. Este classificador aprende uma matriz de pesos $W_k$ de tamanho $[d \times k]$, onde $d$ √© a dimensionalidade do modelo e $k$ √© o n√∫mero de r√≥tulos poss√≠veis. A distribui√ß√£o de probabilidades sobre os r√≥tulos √© ent√£o usada para computar a perda durante o treinamento. A sa√≠da de cada token, ap√≥s passar pela camada *feedforward*, √© usada para determinar o r√≥tulo apropriado para o token espec√≠fico na sequ√™ncia.

A express√£o matem√°tica para o **sequence labeling** com uma √∫nica camada *feedforward* pode ser descrita da seguinte forma [^1, 2, 3]:
$$
y_i = \text{softmax}(h_i W_k)
$$
$$
t_i = \text{argmax}(y_i)
$$
onde $y_i$ √© um vetor de probabilidades sobre os r√≥tulos para o token $i$, $h_i$ √© o vetor de sa√≠da do modelo *transformer* para o token $i$, $W_k$ s√£o os pesos da camada *feedforward*, e $t_i$ √© o r√≥tulo previsto (o *argmax* do vetor $y_i$).

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo *transformer* com dimensionalidade $d=768$ e estamos trabalhando com uma tarefa de NER com $k=5$ r√≥tulos (B-PER, I-PER, B-ORG, I-ORG, O). O vetor de sa√≠da $h_i$ do *transformer* para um token espec√≠fico tem dimens√£o 768. A matriz de pesos $W_k$ ter√° dimens√£o [768 x 5]. Vamos supor um vetor de sa√≠da hipot√©tico $h_i$ e uma matriz de pesos $W_k$:
>
> ```python
> import numpy as np
>
> # Vetor de sa√≠da do transformer (exemplo)
> h_i = np.random.rand(768)
>
> # Matriz de pesos da camada feedforward (exemplo)
> W_k = np.random.rand(768, 5)
>
> # Calculo da saida da camada feedforward
> z_i = np.dot(h_i, W_k)
>
> # Aplica√ß√£o do softmax para obter as probabilidades
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> y_i = softmax(z_i)
>
> # Calculo do r√≥tulo previsto
> t_i = np.argmax(y_i)
>
> print("Sa√≠da do transformer (h_i):", h_i[:5])
> print("Pesos da camada feedforward (W_k):", W_k[:2,:2])
> print("Sa√≠da antes do softmax (z_i):", z_i[:5])
> print("Probabilidades (y_i):", y_i)
> print("R√≥tulo previsto (t_i):", t_i)
> ```
> A sa√≠da ``y_i`` √© um vetor de 5 elementos, onde cada elemento representa a probabilidade de um dos 5 r√≥tulos para o token. O r√≥tulo predito ``t_i`` corresponde ao √≠ndice do elemento com a maior probabilidade. Por exemplo, se ``t_i`` for 2, isso significa que o modelo est√° prevendo o terceiro r√≥tulo da lista (√≠ndice 2) para o token atual.

**Observa√ß√£o 1:** A escolha da fun√ß√£o *softmax* garante que as sa√≠das $y_i$ sejam v√°lidas distribui√ß√µes de probabilidade, ou seja, todos os valores s√£o n√£o-negativos e somam 1. Isso √© crucial para o uso da entropia cruzada como fun√ß√£o de perda, j√° que esta fun√ß√£o opera sobre distribui√ß√µes de probabilidade.

**Observa√ß√£o 1.1:** Uma alternativa para a fun√ß√£o softmax seria utilizar a fun√ß√£o sigm√≥ide em cen√°rios onde os r√≥tulos n√£o s√£o mutuamente exclusivos (e.g. um mesmo token poder ter m√∫ltiplos r√≥tulos). Neste caso, a sa√≠da $y_i$ seria um vetor de probabilidades independentes, e a fun√ß√£o de perda poderia ser a *binary cross entropy* para cada r√≥tulo individualmente.

A fun√ß√£o de perda usada no treinamento √© tipicamente a entropia cruzada, que mede a diferen√ßa entre a distribui√ß√£o prevista e a distribui√ß√£o real dos r√≥tulos [^1, 2, 3]. O objetivo do treinamento √© ajustar os pesos $W_k$ para minimizar esta perda. A adapta√ß√£o pode envolver a atualiza√ß√£o n√£o apenas dos pesos do classificador, mas tamb√©m, em alguns casos, os pesos das camadas do *transformer*, embora isso seja menos comum [^1, 2, 3].

> üí° **Exemplo Num√©rico:** Vamos supor que para um determinado token, o r√≥tulo verdadeiro seja o r√≥tulo 1 (por exemplo, I-PER). O vetor de probabilidade previsto pelo nosso modelo √© ``y_i = [0.1, 0.6, 0.1, 0.1, 0.1]``. A distribui√ß√£o one-hot do r√≥tulo verdadeiro seria ``[0, 1, 0, 0, 0]``.
> A entropia cruzada √© calculada como:
> $$ L = - \sum_{j=1}^{k}  p_j \log(q_j) $$
>  onde $p_j$ √© a probabilidade do r√≥tulo verdadeiro e $q_j$ √© a probabilidade prevista.
>
> ```python
> import numpy as np
>
> # Probabilidades previstas (exemplo)
> y_i = np.array([0.1, 0.6, 0.1, 0.1, 0.1])
>
> # R√≥tulo verdadeiro (one-hot encoding)
> true_label = np.array([0, 1, 0, 0, 0])
>
> # C√°lculo da entropia cruzada
> cross_entropy_loss = -np.sum(true_label * np.log(y_i))
>
> print("Probabilidades previstas:", y_i)
> print("R√≥tulo verdadeiro (one-hot):", true_label)
> print("Entropia cruzada:", cross_entropy_loss)
> ```
> Este valor da perda √© usado para ajustar os pesos do modelo e do classificador atrav√©s da retropropaga√ß√£o. O objetivo √© que, ap√≥s o treinamento, o modelo preveja distribui√ß√µes de probabilidade mais pr√≥ximas da verdade, e consequentemente, minimize essa perda.

### Detalhes do Processo de Fine-Tuning

1.  **Pr√©-processamento:** A sequ√™ncia de entrada √© tokenizada usando um tokenizador de subpalavras, como *WordPiece* ou *SentencePiece* [^1, 2, 3].
2.  **Passagem pelo Modelo:** A sequ√™ncia de tokens √© passada pelo modelo *transformer* bidirecional [^1, 2, 3], produzindo um vetor de sa√≠da para cada token.
3.  **Classifica√ß√£o:** Cada vetor de sa√≠da √© passado por uma camada *feedforward* seguida por uma fun√ß√£o *softmax*. O resultado √© uma distribui√ß√£o de probabilidades sobre os r√≥tulos poss√≠veis para cada token.
4.  **C√°lculo da Perda:** Usamos a fun√ß√£o de perda de entropia cruzada para comparar a distribui√ß√£o de probabilidades prevista com o r√≥tulo verdadeiro de cada token.
5.  **Retropropaga√ß√£o:** Os gradientes da perda s√£o calculados e usados para atualizar os pesos do classificador $W_k$ e, opcionalmente, os pesos do *transformer*.
6.  **Repeti√ß√£o:** Repetimos os passos 2 a 5 em um conjunto de dados de treinamento rotulado at√© que o modelo convirja.

**Lema 1:** O processo de retropropaga√ß√£o (passo 5) usa a regra da cadeia para calcular os gradientes da fun√ß√£o de perda em rela√ß√£o aos pesos da rede. Isso permite atualizar iterativamente os pesos para minimizar a perda. Formalmente, seja $L$ a fun√ß√£o de perda, o gradiente de $L$ em rela√ß√£o a um peso $w$ √© dado por $\frac{\partial L}{\partial w} = \frac{\partial L}{\partial y_i} \frac{\partial y_i}{\partial w}$.

**Prova do Lema 1:**
Para provar o lema 1, vamos demonstrar como a regra da cadeia √© aplicada para calcular o gradiente da fun√ß√£o de perda $L$ em rela√ß√£o a um peso $w$.

I. Seja $L$ a fun√ß√£o de perda que depende de $y_i$, e $y_i$ depende dos pesos $w$ da rede. Queremos encontrar $\frac{\partial L}{\partial w}$.

II. Pela regra da cadeia, o gradiente de $L$ em rela√ß√£o a $w$ pode ser expresso como:
    $$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial y_i} \cdot \frac{\partial y_i}{\partial w}$$
   Este passo quebra o problema em dois termos: como a perda $L$ muda em rela√ß√£o √† sa√≠da do classificador $y_i$, e como a sa√≠da $y_i$ muda em rela√ß√£o aos pesos $w$.

III. O termo $\frac{\partial L}{\partial y_i}$ representa o gradiente da fun√ß√£o de perda em rela√ß√£o √† sa√≠da do classificador, e este depende da fun√ß√£o de perda especifica que esta sendo usada. Por exemplo, se a fun√ß√£o de perda √© a entropia cruzada, podemos calcular este termo usando as derivadas da entropia cruzada em rela√ß√£o a $y_i$.

IV. O termo $\frac{\partial y_i}{\partial w}$ representa o gradiente da sa√≠da do classificador em rela√ß√£o aos pesos $w$. Este termo depende da estrutura da camada de classificador, que, neste caso, √© uma camada *feedforward* seguida por um *softmax*. O c√°lculo desse gradiente √© feito aplicando a regra da cadeia novamente, no entanto, o resultado final √© que o gradiente depende dos valores dos pesos e dos valores de ativa√ß√£o da camada de entrada. Especificamente, se $y_i = \text{softmax}(h_i W_k)$ e $z_i = h_i W_k$, ent√£o $\frac{\partial y_i}{\partial w} = \frac{\partial y_i}{\partial z_i} \frac{\partial z_i}{\partial w}$.

V. Portanto, ao multiplicar esses dois termos, obtemos o gradiente da fun√ß√£o de perda em rela√ß√£o aos pesos $w$, $\frac{\partial L}{\partial w}$, que √© ent√£o usado no processo de retropropaga√ß√£o para atualizar iterativamente os pesos e minimizar a perda. $\blacksquare$

### NER como um Exemplo de Sequence Labeling
Para ilustrar o **sequence labeling** em pr√°tica, usamos o exemplo do reconhecimento de entidades nomeadas (NER). NER envolve a identifica√ß√£o de *spans* de texto que representam nomes pr√≥prios e a classifica√ß√£o desses *spans* em categorias como pessoas (PER), organiza√ß√µes (ORG), locais (LOC), ou entidades geogr√°ficas-pol√≠ticas (GPE) [^1, 2, 3]. No exemplo da se√ß√£o anterior, "Jane Villanueva" e "United Airlines Holding" foram identificadas como entidades nomeadas, com "Jane Villanueva" sendo classificada como uma pessoa e "United Airlines Holding" como uma organiza√ß√£o [^1, 2, 3].

Para modelar NER usando **sequence labeling**, usamos *BIO tagging* [^1, 2, 3]. O *BIO tagging* atribui um r√≥tulo a cada token que indica se o token come√ßa uma entidade (B), est√° dentro de uma entidade (I) ou n√£o faz parte de nenhuma entidade (O). Este sistema de rotulagem nos permite capturar a extens√£o e o tipo de cada entidade na sequ√™ncia. Usando o *BIO tagging* com modelos como o BERT, podemos aplicar o *fine-tuning* para otimizar os par√¢metros para prever as tags BIO corretas para cada token.

> üí° **Exemplo Num√©rico:** Consideremos a frase "Apple anunciou um novo iPhone em Cupertino". Usando o *BIO tagging* para NER, ter√≠amos as seguintes etiquetas:
>
> | Token     | R√≥tulo |
> |-----------|--------|
> | Apple     | B-ORG  |
> | anunciou  | O      |
> | um        | O      |
> | novo      | O      |
> | iPhone    | B-PROD |
> | em        | O      |
> | Cupertino | B-LOC  |
>
>  Aqui, "Apple" √© o in√≠cio (B) de uma organiza√ß√£o (ORG), "iPhone" √© o in√≠cio de um produto (PROD), e "Cupertino" √© o in√≠cio de uma localiza√ß√£o (LOC). As outras palavras s√£o rotuladas como O (fora de qualquer entidade nomeada). Este tipo de rotula√ß√£o √© essencial para o treinamento de modelos de **sequence labeling** para NER. Em ess√™ncia, o *BIO tagging* transforma um problema de detec√ß√£o de *spans* em um problema de rotula√ß√£o de tokens, tornando poss√≠vel o uso de modelos de *sequence labeling* para NER. O *BIO tagging*, como m√©todo para modelar o NER como uma tarefa de **sequence labeling**, permite que o problema seja abordado como um problema de classifica√ß√£o de tokens, onde o modelo deve prever um r√≥tulo para cada token da sequ√™ncia. As tags BIO (B-in√≠cio, I-interior, O-fora) s√£o combinadas com os tipos de entidades (e.g. ORG, PER, LOC), resultando em r√≥tulos que representam tanto o tipo da entidade quanto a informa√ß√£o sobre a extens√£o da entidade na sequ√™ncia.

### Considera√ß√µes Importantes

- **Alinhamento de Tokens e R√≥tulos:** O tokenizador de subpalavras pode resultar em tokens que n√£o correspondem diretamente √†s palavras. Em tarefas de NER, onde as anota√ß√µes s√£o geralmente feitas em palavras, um dos desafios √© lidar com esse desalinhamento [^1, 2, 3]. Para o treinamento, podemos simplesmente atribuir o r√≥tulo da palavra a todos os sub-tokens derivados da mesma. Para a decodifica√ß√£o, uma abordagem comum √© usar o r√≥tulo do primeiro subtoken para representar a palavra.

- **CRF:** Podemos passar os r√≥tulos da camada *softmax* para uma camada *Conditional Random Field* (CRF), que pode modelar transi√ß√µes entre r√≥tulos [^1, 2, 3]. A camada CRF √© especialmente √∫til em problemas como NER, onde as transi√ß√µes de r√≥tulo tem depend√™ncias.

**Teorema 1:** A utiliza√ß√£o de um CRF ap√≥s a camada softmax em tarefas de **sequence labeling** como NER, pode levar a uma melhoria no desempenho, em especial em cen√°rios com forte depend√™ncia contextual entre r√≥tulos. Isso ocorre porque o CRF modela explicitamente a probabilidade de uma sequ√™ncia de r√≥tulos, e n√£o apenas a probabilidade de um r√≥tulo individual, como faz uma camada *softmax* isolada.

**Prova do Teorema 1:**

Para provar o teorema 1, vamos demonstrar porque o uso de um CRF ap√≥s o softmax em **sequence labeling** pode levar a uma melhoria no desempenho, especialmente quando h√° depend√™ncias contextuais entre os r√≥tulos.

I. Em um modelo de **sequence labeling** com uma camada *softmax* isolada, a probabilidade de um r√≥tulo para um token √© calculada independentemente de outros tokens na sequ√™ncia. Isso ignora as depend√™ncias contextuais entre r√≥tulos adjacentes.

II. Um modelo CRF, por outro lado, modela a probabilidade de toda a sequ√™ncia de r√≥tulos, levando em considera√ß√£o as transi√ß√µes entre r√≥tulos adjacentes. Formalmente, a probabilidade de uma sequ√™ncia de r√≥tulos $y = [y_1, y_2, \ldots, y_n]$ dado uma sequ√™ncia de entrada $x$ √© modelada como:
    $$P(y|x) = \frac{1}{Z(x)} \exp(\sum_{i=1}^{n} A_{y_{i-1}, y_i} + \sum_{i=1}^{n} P(y_i|x))$$
     onde $A_{y_{i-1}, y_i}$ representa os *scores* de transi√ß√£o entre os r√≥tulos $y_{i-1}$ e $y_i$, $P(y_i|x)$ s√£o os *scores* obtidos da camada *softmax* para o r√≥tulo $y_i$ e $Z(x)$ √© um fator de normaliza√ß√£o que garante que a distribui√ß√£o $P(y|x)$ seja uma distribui√ß√£o de probabilidade v√°lida.

III. Ao modelar transi√ß√µes de r√≥tulos usando os *scores* $A_{y_{i-1}, y_i}$, o CRF consegue capturar as depend√™ncias contextuais que s√£o comuns em tarefas como NER. Por exemplo, √© muito mais prov√°vel que um r√≥tulo 'I-PER' (inside person) siga um r√≥tulo 'B-PER' (begin person) do que um r√≥tulo 'O' (outside). O CRF atribui scores de transi√ß√£o mais altos para sequ√™ncias que seguem regras como essa, e penaliza sequ√™ncias improv√°veis.

IV. Portanto, o CRF modela a probabilidade conjunta de uma sequ√™ncia de r√≥tulos, em vez de r√≥tulos independentes. A considera√ß√£o da probabilidade da sequ√™ncia completa permite que o CRF fa√ßa previs√µes mais coerentes e precisas.

V. Em resumo, ao modelar as depend√™ncias entre r√≥tulos, o CRF pode melhorar a precis√£o das previs√µes, especialmente em cen√°rios onde as depend√™ncias contextuais entre os r√≥tulos s√£o fortes. $\blacksquare$

> üí° **Exemplo Num√©rico:** Suponha que o modelo *softmax* preveja as seguintes probabilidades para a sequ√™ncia de r√≥tulos "B-PER", "I-PER", "O":
>  - Para o primeiro token: $P(\text{B-PER}) = 0.8$, $P(\text{I-PER}) = 0.1$, $P(\text{O}) = 0.1$.
> - Para o segundo token: $P(\text{B-PER}) = 0.2$, $P(\text{I-PER}) = 0.7$, $P(\text{O}) = 0.1$.
> - Para o terceiro token: $P(\text{B-PER}) = 0.1$, $P(\text{I-PER}) = 0.2$, $P(\text{O}) = 0.7$.
>
>  Um CRF pode modelar transi√ß√µes mais prov√°veis, como a transi√ß√£o de B-PER para I-PER, e penalizar transi√ß√µes improv√°veis como B-PER para O. Os pesos de transi√ß√£o podem ser expressos como uma matriz, onde cada elemento $A_{ij}$ representa a pontua√ß√£o da transi√ß√£o do r√≥tulo $i$ para o r√≥tulo $j$.
>
> ```python
> import numpy as np
>
> # Probabilidades de saida do softmax (exemplo)
> softmax_probs = np.array([
>    [0.8, 0.1, 0.1], # B-PER, I-PER, O para o primeiro token
>    [0.2, 0.7, 0.1], # B-PER, I-PER, O para o segundo token
>    [0.1, 0.2, 0.7]  # B-PER, I-PER, O para o terceiro token
> ])
>
> # Matriz de transi√ß√£o CRF (exemplo)
> transition_scores = np.array([
>    [0.5, 1.0, -2.0], # B-PER para B-PER, I-PER, O
>    [-1.0, 0.8, -0.5],# I-PER para B-PER, I-PER, O
>    [-0.5, -1.0, 0.9] # O para B-PER, I-PER, O
> ])
>
> def calculate_sequence_score(softmax_probs, transition_scores, labels):
>  score = 0
>  for i, label_idx in enumerate(labels):
>      score += np.log(softmax_probs[i][label_idx])
>      if i > 0:
>        score += transition_scores[labels[i-1]][label_idx]
>  return score
>
> labels1 = [0,1,2] # Sequencia B-PER, I-PER, O
> labels2 = [0,0,2] # Sequencia B-PER, B-PER, O
>
> score1 = calculate_sequence_score(softmax_probs, transition_scores, labels1)
> score2 = calculate_sequence_score(softmax_probs, transition_scores, labels2)
> print(f"Pontua√ß√£o da sequ√™ncia B-PER, I-PER, O: {score1:.2f}")
> print(f"Pontua√ß√£o da sequ√™ncia B-PER, B-PER, O: {score2:.2f}")
> ```
>
> No exemplo, a pontua√ß√£o da sequ√™ncia correta (B-PER, I-PER, O) √© maior do que a da sequ√™ncia incorreta (B-PER, B-PER, O), mostrando como o CRF ajuda a modelar as depend√™ncias e transi√ß√µes de r√≥tulos.

- **M√©tricas de Avalia√ß√£o:** Os modelos de **sequence labeling** s√£o avaliados usando m√©tricas como precis√£o, *recall*, e *F1-score*, que medem a efic√°cia do modelo na previs√£o de r√≥tulos [^1, 2, 3]. Essas m√©tricas s√£o calculadas tanto no n√≠vel do token quanto no n√≠vel da entidade.

**Corol√°rio 1.1:** Ao avaliar modelos de NER, √© importante reportar m√©tricas tanto no n√≠vel do token quanto no n√≠vel da entidade. As m√©tricas em n√≠vel de token fornecem uma vis√£o da capacidade do modelo em rotular corretamente cada token individualmente, enquanto as m√©tricas em n√≠vel da entidade refletem a precis√£o do modelo na detec√ß√£o e classifica√ß√£o de entidades completas.

**Prova do Corol√°rio 1.1:**

Para demonstrar a import√¢ncia de reportar m√©tricas de avalia√ß√£o tanto no n√≠vel do token quanto no n√≠vel da entidade para tarefas de NER, vamos analisar as diferen√ßas e complementaridades dessas medidas:

I.  **M√©tricas no n√≠vel do token**: Essas m√©tricas (precis√£o, *recall* e *F1-score*) s√£o calculadas considerando cada token individualmente. Elas avaliam se cada token foi rotulado corretamente ou n√£o.

    *   A *precis√£o* no n√≠vel do token mede a propor√ß√£o de tokens rotulados corretamente em rela√ß√£o a todos os tokens que o modelo rotulou como parte de alguma entidade.
    *   O *recall* no n√≠vel do token mede a propor√ß√£o de tokens rotulados corretamente em rela√ß√£o a todos os tokens que *realmente* fazem parte de alguma entidade.
    *   O *F1-score* no n√≠vel do token √© a m√©dia harm√¥nica entre precis√£o e *recall*, fornecendo uma m√©trica balanceada.

II. **M√©tricas no n√≠vel da entidade**: Essas m√©tricas s√£o calculadas considerando as entidades como um todo. Uma entidade √© considerada corretamente identificada apenas se seu *span* completo foi detectado corretamente e todos os r√≥tulos de tokens dentro do *span* estiverem corretos.

    *   A *precis√£o* no n√≠vel da entidade mede a propor√ß√£o de entidades corretamente identificadas em rela√ß√£o ao total de entidades que o modelo detectou.
    *   O *recall* no n√≠vel da entidade mede a propor√ß√£o de entidades corretamente identificadas em rela√ß√£o ao total de entidades presentes no conjunto de dados.
    *   O *F1-score* no n√≠vel da entidade √© a m√©dia harm√¥nica entre precis√£o e *recall* no n√≠vel da entidade.

III. **Complementaridade:** As m√©tricas no n√≠vel do token avaliam o desempenho em termos de cada r√≥tulo de token individual, enquanto as m√©tricas no n√≠vel da entidade avaliam o desempenho em termos da identifica√ß√£o correta de *spans* e tipos de entidades.

    *   Por exemplo, um modelo pode ter uma alta precis√£o no n√≠vel do token, mas ter um baixo *recall* no n√≠vel da entidade se ele frequentemente rotular entidades incorretamente, por exemplo, rotulando apenas alguns dos tokens que comp√µem a entidade corretamente, ou fazendo uma m√° delimita√ß√£o dos *spans* da entidade.
    *   Em contrapartida, um modelo pode ter um alto *recall* no n√≠vel da entidade, mas baixa precis√£o no n√≠vel do token se ele muitas vezes errar na rotula√ß√£o dos tokens dentro das entidades, ou rotulando entidades que n√£o existem.

IV. **Conclus√£o:** Ao reportar ambas as m√©tricas, avaliamos o desempenho do modelo de maneira abrangente. M√©trica de n√≠vel do token nos informa a capacidade do modelo de rotular cada token corretamente, enquanto a m√©trica de n√≠vel da entidade nos informa se o modelo √© capaz de identificar corretamente entidades completas. Portanto, √© crucial reportar ambas as m√©tricas para ter uma avalia√ß√£o completa da capacidade do modelo em tarefas de NER. $\blacksquare$

> üí° **Exemplo Num√©rico:** Vamos supor que nosso modelo tenha as seguintes previs√µes para uma frase (com entidades em negrito) : "A **Apple** lan√ßou o novo **iPhone** em **Cupertino**".
>
>  **R√≥tulos verdadeiros:**
>
>   - A: O
>   - Apple: B-ORG
>   - lan√ßou: O
>   - o: O
>   - novo: O
>   - iPhone: B-PROD
>   - em: O
>   - Cupertino: B-LOC
>
> **R√≥tulos previstos:**
>
>  - A: O
>   - Apple: B-ORG
>   - lan√ßou: O
>   - o: O
>   - novo: O
>   - iPhone: I-PROD  *(erro)*
>   - em: O
>   - Cupertino: B-LOC
>
> **An√°lise:**
>
> *   **N√≠vel do Token:**
>     *   **Precis√£o:** 7/8 = 0.875 (7 r√≥tulos corretos de 8 previstos como entidade)
>     *   **Recall:** 7/8 = 0.875 (7 r√≥tulos corretos de 8 r√≥tulos reais como entidade)
>     *  **F1-Score:** $2 * (0.875*0.875) / (0.875 + 0.875) = 0.875$
> *   **N√≠vel da Entidade:**
>     *   **Precis√£o:** 2/2 = 1.0 (2 entidades detectadas corretamente de 2 detectadas)
>     *   **Recall:** 2/3 = 0.67 (2 entidades detectadas corretamente de 3 entidades reais)
>     *   **F1-Score:** $2 * (1.0 * 0.67) / (1.0 + 0.67) = 0.80$
>
>  Note que, apesar do bom desempenho no n√≠vel do token, o *recall* no n√≠vel da entidade √© mais baixo porque o modelo errou ao rotular o token "iPhone" como "I-PROD" em vez de "B-PROD", o que resultou em uma entidade incorreta. Este exemplo ilustra a import√¢ncia de reportar m√©tricas em ambos os n√≠veis.

**Proposi√ß√£o 1:** A escolha da arquitetura para o classificador em **sequence labeling** (e.g., uso de uma simples camada feedforward ou um CRF) pode impactar no desempenho do modelo de maneira consider√°vel, dependendo da tarefa e das depend√™ncias entre r√≥tulos. Tarefas com fortes depend√™ncias contextuais podem se beneficiar mais do uso de um CRF, enquanto tarefas com depend√™ncias mais fracas podem ter um bom desempenho com uma camada feedforward simples.

**Prova da Proposi√ß√£o 1:**

Para demonstrar a influ√™ncia da arquitetura do classificador no desempenho do modelo de **sequence labeling**, vamos discutir como diferentes escolhas de arquitetura impactam o modelo em tarefas distintas:

I. **Camada Feedforward Simples:** A camada feedforward (seguida pelo *softmax*) opera independentemente em cada token, ou seja, a previs√£o do r√≥tulo de um token n√£o depende da previs√£o dos r√≥tulos adjacentes. Matematicamente, isso pode ser representado por $y_i = \text{softmax}(h_i W_k)$, onde a probabilidade de um r√≥tulo para o token $i$ depende apenas do vetor de entrada $h_i$ e dos pesos $W_k$ da camada *feedforward*.

     *  **Vantagens:** Simples e computacionalmente eficiente. Funciona bem em tarefas onde as depend√™ncias entre r√≥tulos s√£o fracas ou inexistentes (ex: classifica√ß√£o de sentimento por token, quando o contexto √© pequeno).
     * **Desvantagens:** N√£o captura depend√™ncias sequenciais entre r√≥tulos.  Pode apresentar dificuldades em cen√°rios onde a probabilidade de um r√≥tulo depende de r√≥tulos precedentes ou subsequentes.

II. **Conditional Random Field (CRF):** O CRF, por sua vez, modela a probabilidade de uma sequ√™ncia de r√≥tulos, levando em considera√ß√£o as transi√ß√µes entre eles. Isso permite que o modelo aprenda depend√™ncias sequenciais entre os r√≥tulos. Formalmente, um CRF modela a probabilidade de uma sequ√™ncia de r√≥tulos $y$ dada uma sequ√™ncia de entrada $x$ como:
    $$P(y|x) = \frac{1}{Z(x)} \exp(\sum_{i=1}^{n} A_{y_{i-1}, y_i} + \sum_{i=1}^{n} P(y_i|x))$$
    onde o termo $A_{y_{i-1}, y_i}$ modela as depend√™ncias de transi√ß√£o entre os r√≥tulos, e $P(y_i|x)$ √© a sa√≠da da camada *softmax* para o token $i$.

    *  **Vantagens:** Modelagem de depend√™ncias entre r√≥tulos, levando a previs√µes mais consistentes. √ötil para tarefas como NER ou part-of-speech tagging onde a ordem dos r√≥tulos √© importante.
    *  **Desvantagens:** Computacionalmente mais custoso que uma camada *feedforward* simples. Requer um treinamento mais cuidadoso e pode ser mais dif√≠cil de otimizar.

III. **Impacto nas Tarefas:**

    *   **NER:** No NER, por exemplo, um token com r√≥tulo 'I-PER' geralmente precede ou segue um r√≥tulo 'B-PER'. Um modelo *feedforward* simples n√£o captura essa depend√™ncia, enquanto um CRF faz isso de forma natural, atribuindo *scores* de transi√ß√£o mais altos para sequ√™ncias de r√≥tulos com transi√ß√µes v√°lidas.
    *   **Part-of-Speech Tagging:** Similarmente, em part-of-speech tagging, a tag de um verbo provavelmente ser√° precedida por um substantivo ou pronome. O CRF modela bem essas transi√ß√µes gramaticais.
    *   **Classifica√ß√£o de Sentimento:** Tarefas como a classifica√ß√£o de sentimento por token, onde cada token expressa um sentimento independente, podem ter bom desempenho com uma camada *feedforward* simples, pois as depend√™ncias sequenciais s√£o m√≠nimas.

IV. **Conclus√£o:** A escolha da arquitetura do classificador deve ser feita em fun√ß√£o da natureza da tarefa. Para tarefas com fortes depend√™ncias contextuais, o CRF geralmente √© a melhor escolha, pois consegue modelar as transi√ß√µes entre r√≥tulos,  enquanto para tarefas com depend√™ncias mais fracas, a camada *feedforward* simples pode ser suficiente, sendo mais simples e computacionalmente mais eficiente. A arquitetura mais adequada para o classificador depende da complexidade da tarefa e das caracter√≠sticas dos dados, com tarefas complexas podendo se beneficiar de modelos que consideram a depend√™ncia entre r√≥tulos. $\blacksquare$

**Teorema 1.1:** Em tarefas de **sequence labeling** com um n√∫mero elevado de r√≥tulos, o uso de um CRF pode se tornar computacionalmente proibitivo devido ao custo de calcular a matriz de transi√ß√µes entre r√≥tulos. Nesses casos, pode ser √∫til recorrer a t√©cnicas de simplifica√ß√£o ou aproxima√ß√£o do CRF, ou ainda, explorar outras alternativas como modelos que utilizem redes neurais recorrentes para modelar as depend√™ncias entre r√≥tulos.

**Prova do Teorema 1.1:**

Para provar o teorema 1.1, vamos discutir as limita√ß√µes computacionais do CRF em tarefas de **sequence labeling** com um grande n√∫mero de r√≥tulos e explorar alternativas.

I. **Complexidade do CRF:** A principal limita√ß√£o computacional do CRF reside no c√°lculo da fun√ß√£o de parti√ß√£o $Z(x)$ e das probabilidades de transi√ß√£o entre os r√≥tulos. A fun√ß√£o de parti√ß√£o envolve a soma sobre todas as poss√≠veis sequ√™ncias de r√≥tulos, o que resulta em uma complexidade exponencial em rela√ß√£o ao tamanho da sequ√™ncia e o n√∫mero de r√≥tulos.  No caso de um grande n√∫mero de r√≥tulos, o custo computacional aumenta drasticamente, tornando o treinamento e a infer√™ncia impratic√°veis.

II. **Matriz de Transi√ß√£o:** O CRF tamb√©m mant√©m uma matriz de transi√ß√£o $A$ de tamanho $k \times k$, onde $k$ √© o n√∫mero de r√≥tulos. Essa matriz armazena os scores para todas as poss√≠veis transi√ß√µes entre os r√≥tulos. Quando $k$ √© grande, a mem√≥ria necess√°ria para armazenar essa matriz tamb√©m aumenta, podendo se tornar um gargalo. O c√°lculo da fun√ß√£o de parti√ß√£o exige que todos os termos nesta matriz sejam considerados.

III. **Impacto do n√∫mero de r√≥tulos:** Em tarefas como NER com um n√∫mero limitado de r√≥tulos (e.g. B-PER, I-PER, B-ORG, I-ORG, O), o custo computacional do CRF pode ser administr√°vel. No entanto, em tarefas mais complexas, como *fine-grained entity typing* ou *part-of-speech tagging*, onde o n√∫mero de r√≥tulos pode ser muito grande, o uso de um modelo de CRF pode se tornar proibitivamente caro computacionalmente.

### Vantagens e Desvantagens do CRF

**Vantagens:**

*   **Modelagem de Depend√™ncias:** CRFs s√£o excelentes em modelar depend√™ncias sequenciais entre r√≥tulos.
*   **Flexibilidade:** Permitem a incorpora√ß√£o de uma variedade de caracter√≠sticas (features) do input, o que pode ser muito √∫til em diversas tarefas de NLP.
*   **Desempenho:** CRFs geralmente entregam um bom desempenho em tarefas de rotula√ß√£o de sequ√™ncia.

**Desvantagens:**

*   **Custo Computacional:** O custo computacional pode se tornar alto em problemas com muitos r√≥tulos.
*   **Treinamento:** O treinamento de um modelo CRF pode ser mais complexo do que o treinamento de modelos como HMMs.
*   **Interpreta√ß√£o:** A interpreta√ß√£o dos pesos aprendidos pelo modelo pode ser dif√≠cil.

### Aplica√ß√µes Pr√°ticas de CRFs

CRFs t√™m sido aplicados em uma ampla gama de tarefas em NLP, incluindo:

1.  **Reconhecimento de Entidades Nomeadas (NER):** Identificar e classificar entidades como pessoas, organiza√ß√µes e locais em textos.
2.  **Marca√ß√£o de Partes do Discurso (POS Tagging):** Atribuir r√≥tulos gramaticais (e.g., substantivo, verbo, adjetivo) a cada palavra em uma frase.
3.  **Extra√ß√£o de Informa√ß√£o:** Extrair informa√ß√µes estruturadas de textos n√£o estruturados.
4.  **An√°lise de Sentimento:** Identificar o sentimento expresso em um texto.
5.  **Segmenta√ß√£o de Texto:** Dividir um texto em segmentos significativos.

### Uma Vis√£o R√°pida de Modelos Alternativos

Embora os CRFs sejam uma ferramenta poderosa, existem outras t√©cnicas e modelos que podem ser considerados para tarefas de modelagem de sequ√™ncia. Alguns deles incluem:

1.  **Hidden Markov Models (HMMs):** Um modelo probabil√≠stico que assume que o estado atual depende apenas do estado anterior. √â mais simples que CRFs, mas pode n√£o ser adequado para tarefas com muitas depend√™ncias.
2.  **Recurrent Neural Networks (RNNs):** Redes neurais que podem processar sequ√™ncias de dados. Modelos como LSTMs e GRUs t√™m sido muito eficazes em tarefas de modelagem de sequ√™ncia.
3.  **Transformers:** Modelos de aten√ß√£o que t√™m se tornado padr√£o em NLP, especialmente para tarefas que envolvem depend√™ncias de longo alcance em sequ√™ncias.

### Conclus√£o

Os Conditional Random Fields s√£o uma ferramenta poderosa para modelagem de sequ√™ncia, especialmente em tarefas que requerem modelagem de depend√™ncias entre r√≥tulos. No entanto, √© importante considerar suas limita√ß√µes, como o custo computacional, ao escolher um modelo para uma tarefa espec√≠fica. O avan√ßo de modelos alternativos como RNNs e Transformers tem oferecido op√ß√µes mais eficientes e poderosas para muitas aplica√ß√µes de modelagem de sequ√™ncia.

<!-- END -->
