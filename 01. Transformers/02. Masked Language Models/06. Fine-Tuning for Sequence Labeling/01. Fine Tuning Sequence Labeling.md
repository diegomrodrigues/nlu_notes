## Fine-Tuning para Sequence Labeling: Uma An√°lise Detalhada

### Introdu√ß√£o
Este cap√≠tulo explora o ajuste fino (fine-tuning) de modelos de linguagem pr√©-treinados para tarefas de *sequence labeling*, com foco em como os par√¢metros do modelo e um classificador s√£o otimizados para prever r√≥tulos para cada token de uma sequ√™ncia. Como vimos anteriormente [^1], o *fine-tuning* √© uma t√©cnica essencial para adaptar modelos de linguagem a tarefas espec√≠ficas, aproveitando o conhecimento adquirido durante o pr√©-treinamento. A se√ß√£o atual detalha como essa adapta√ß√£o √© realizada para problemas em que cada token em uma sequ√™ncia de texto precisa ser rotulado, o que difere das tarefas de classifica√ß√£o que se focam em classificar a sequ√™ncia como um todo [^1].

### Conceitos Fundamentais

Em *sequence labeling*, o objetivo √© atribuir um r√≥tulo a cada token em uma sequ√™ncia de entrada [^1]. Diferentemente da *sequence classification*, onde um √∫nico r√≥tulo √© atribu√≠do a toda a sequ√™ncia, aqui cada token dentro da sequ√™ncia requer uma classifica√ß√£o. Esta abordagem √© fundamental para uma variedade de tarefas de processamento de linguagem natural, como o reconhecimento de entidades nomeadas (NER) [^1], *part-of-speech tagging* ou extra√ß√£o de informa√ß√£o. O ajuste fino para *sequence labeling* envolve uma arquitetura onde um modelo pr√©-treinado de *transformer* √© combinado com um classificador de *feedforward*.

Para realizar o ajuste fino, passamos o vetor de sa√≠da final do modelo pr√©-treinado para cada token de entrada para um classificador que produz uma distribui√ß√£o softmax sobre o conjunto de r√≥tulos poss√≠veis [^1]. Este classificador aprende uma matriz de pesos $W_k$ de tamanho $[d \times k]$, onde $d$ √© a dimensionalidade do modelo e $k$ √© o n√∫mero de r√≥tulos poss√≠veis. A distribui√ß√£o de probabilidades sobre os r√≥tulos √© ent√£o usada para computar a perda durante o treinamento. A sa√≠da de cada token, ap√≥s passar pela camada *feedforward*, √© usada para determinar o r√≥tulo apropriado para o token espec√≠fico na sequ√™ncia.

A express√£o matem√°tica para o *sequence labeling* com uma √∫nica camada *feedforward* pode ser descrita da seguinte forma [^1]:
$$
y_i = \text{softmax}(h_i W_k)
$$
$$
t_i = \text{argmax}(y_i)
$$
onde $y_i$ √© um vetor de probabilidades sobre os r√≥tulos para o token $i$, $h_i$ √© o vetor de sa√≠da do modelo *transformer* para o token $i$, $W_k$ s√£o os pesos da camada *feedforward*, e $t_i$ √© o r√≥tulo previsto (o *argmax* do vetor $y_i$).

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo *transformer* com dimensionalidade $d=768$ e estamos trabalhando com uma tarefa de NER com $k=5$ r√≥tulos (B-PER, I-PER, B-ORG, I-ORG, O). O vetor de sa√≠da $h_i$ do *transformer* para um token espec√≠fico tem dimens√£o 768. A matriz de pesos $W_k$ ter√° dimens√£o [768 x 5]. Vamos supor um vetor de sa√≠da hipot√©tico $h_i$ e uma matriz de pesos $W_k$:
>
> ```python
> import numpy as np
>
> # Vetor de sa√≠da do transformer (exemplo)
> h_i = np.random.rand(768)
>
> # Matriz de pesos da camada feedforward (exemplo)
> W_k = np.random.rand(768, 5)
>
> # Calculo da saida da camada feedforward
> z_i = np.dot(h_i, W_k)
>
> # Aplica√ß√£o do softmax para obter as probabilidades
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> y_i = softmax(z_i)
>
> # Calculo do r√≥tulo previsto
> t_i = np.argmax(y_i)
>
> print("Sa√≠da do transformer (h_i):", h_i[:5])
> print("Pesos da camada feedforward (W_k):", W_k[:2,:2])
> print("Sa√≠da antes do softmax (z_i):", z_i[:5])
> print("Probabilidades (y_i):", y_i)
> print("R√≥tulo previsto (t_i):", t_i)
> ```
> A sa√≠da ``y_i`` √© um vetor de 5 elementos, onde cada elemento representa a probabilidade de um dos 5 r√≥tulos para o token. O r√≥tulo predito ``t_i`` corresponde ao √≠ndice do elemento com a maior probabilidade. Por exemplo, se ``t_i`` for 2, isso significa que o modelo est√° prevendo o terceiro r√≥tulo da lista (√≠ndice 2) para o token atual.

**Observa√ß√£o 1:** A escolha da fun√ß√£o *softmax* garante que as sa√≠das $y_i$ sejam v√°lidas distribui√ß√µes de probabilidade, ou seja, todos os valores s√£o n√£o-negativos e somam 1. Isso √© crucial para o uso da entropia cruzada como fun√ß√£o de perda, j√° que esta fun√ß√£o opera sobre distribui√ß√µes de probabilidade.

A fun√ß√£o de perda usada no treinamento √© tipicamente a entropia cruzada, que mede a diferen√ßa entre a distribui√ß√£o prevista e a distribui√ß√£o real dos r√≥tulos [^1]. O objetivo do treinamento √© ajustar os pesos $W_k$ para minimizar esta perda. A adapta√ß√£o pode envolver a atualiza√ß√£o n√£o apenas dos pesos do classificador, mas tamb√©m, em alguns casos, os pesos das camadas do *transformer*, embora isso seja menos comum [^1].

> üí° **Exemplo Num√©rico:** Vamos supor que para um determinado token, o r√≥tulo verdadeiro seja o r√≥tulo 1 (por exemplo, I-PER). O vetor de probabilidade previsto pelo nosso modelo √© ``y_i = [0.1, 0.6, 0.1, 0.1, 0.1]``. A distribui√ß√£o one-hot do r√≥tulo verdadeiro seria ``[0, 1, 0, 0, 0]``.
> A entropia cruzada √© calculada como:
> $$ L = - \sum_{j=1}^{k}  p_j \log(q_j) $$
>  onde $p_j$ √© a probabilidade do r√≥tulo verdadeiro e $q_j$ √© a probabilidade prevista.
>
> ```python
> import numpy as np
>
> # Probabilidades previstas (exemplo)
> y_i = np.array([0.1, 0.6, 0.1, 0.1, 0.1])
>
> # R√≥tulo verdadeiro (one-hot encoding)
> true_label = np.array([0, 1, 0, 0, 0])
>
> # C√°lculo da entropia cruzada
> cross_entropy_loss = -np.sum(true_label * np.log(y_i))
>
> print("Probabilidades previstas:", y_i)
> print("R√≥tulo verdadeiro (one-hot):", true_label)
> print("Entropia cruzada:", cross_entropy_loss)
> ```
> Este valor da perda √© usado para ajustar os pesos do modelo e do classificador atrav√©s da retropropaga√ß√£o. O objetivo √© que, ap√≥s o treinamento, o modelo preveja distribui√ß√µes de probabilidade mais pr√≥ximas da verdade, e consequentemente, minimize essa perda.

### Detalhes do Processo de Fine-Tuning

1. **Pr√©-processamento:** A sequ√™ncia de entrada √© tokenizada usando um tokenizador de subpalavras, como *WordPiece* ou *SentencePiece* [^1].
2. **Passagem pelo Modelo:** A sequ√™ncia de tokens √© passada pelo modelo *transformer* bidirecional [^1], produzindo um vetor de sa√≠da para cada token.
3. **Classifica√ß√£o:** Cada vetor de sa√≠da √© passado por uma camada *feedforward* seguida por uma fun√ß√£o *softmax*. O resultado √© uma distribui√ß√£o de probabilidades sobre os r√≥tulos poss√≠veis para cada token.
4. **C√°lculo da Perda:** Usamos a fun√ß√£o de perda de entropia cruzada para comparar a distribui√ß√£o de probabilidades prevista com o r√≥tulo verdadeiro de cada token.
5. **Retropropaga√ß√£o:** Os gradientes da perda s√£o calculados e usados para atualizar os pesos do classificador $W_k$ e, opcionalmente, os pesos do *transformer*.
6. **Repeti√ß√£o:** Repetimos os passos 2 a 5 em um conjunto de dados de treinamento rotulado at√© que o modelo convirja.

**Lema 1:** O processo de retropropaga√ß√£o (passo 5) usa a regra da cadeia para calcular os gradientes da fun√ß√£o de perda em rela√ß√£o aos pesos da rede. Isso permite atualizar iterativamente os pesos para minimizar a perda. Formalmente, seja $L$ a fun√ß√£o de perda, o gradiente de $L$ em rela√ß√£o a um peso $w$ √© dado por $\frac{\partial L}{\partial w} = \frac{\partial L}{\partial y_i} \frac{\partial y_i}{\partial w}$.

**Prova do Lema 1:**
Para provar o lema 1, vamos demonstrar como a regra da cadeia √© aplicada para calcular o gradiente da fun√ß√£o de perda $L$ em rela√ß√£o a um peso $w$.

I. Seja $L$ a fun√ß√£o de perda que depende de $y_i$, e $y_i$ depende dos pesos $w$ da rede. Queremos encontrar $\frac{\partial L}{\partial w}$.

II. Pela regra da cadeia, o gradiente de $L$ em rela√ß√£o a $w$ pode ser expresso como:
    $$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial y_i} \cdot \frac{\partial y_i}{\partial w}$$
   Este passo quebra o problema em dois termos: como a perda $L$ muda em rela√ß√£o √† sa√≠da do classificador $y_i$, e como a sa√≠da $y_i$ muda em rela√ß√£o aos pesos $w$.

III. O termo $\frac{\partial L}{\partial y_i}$ representa o gradiente da fun√ß√£o de perda em rela√ß√£o √† sa√≠da do classificador, e este depende da fun√ß√£o de perda especifica que esta sendo usada.

IV. O termo $\frac{\partial y_i}{\partial w}$ representa o gradiente da sa√≠da do classificador em rela√ß√£o aos pesos $w$. Este termo depende da estrutura da camada de classificador, que, neste caso, √© uma camada *feedforward* seguida por um *softmax*. O c√°lculo desse gradiente √© feito aplicando a regra da cadeia novamente, no entanto, o resultado final √© que o gradiente depende dos valores dos pesos e dos valores de ativa√ß√£o da camada de entrada.

V. Portanto, ao multiplicar esses dois termos, obtemos o gradiente da fun√ß√£o de perda em rela√ß√£o aos pesos $w$, $\frac{\partial L}{\partial w}$, que √© ent√£o usado no processo de retropropaga√ß√£o para atualizar iterativamente os pesos e minimizar a perda. ‚ñ†

### NER como um Exemplo de Sequence Labeling
Para ilustrar o *sequence labeling* em pr√°tica, usamos o exemplo do reconhecimento de entidades nomeadas (NER).  NER envolve a identifica√ß√£o de *spans* de texto que representam nomes pr√≥prios e a classifica√ß√£o desses *spans* em categorias como pessoas (PER), organiza√ß√µes (ORG), locais (LOC), ou entidades geogr√°ficas-pol√≠ticas (GPE) [^1].  No exemplo da se√ß√£o anterior, "Jane Villanueva" e "United Airlines Holding" foram identificadas como entidades nomeadas, com "Jane Villanueva" sendo classificada como uma pessoa e "United Airlines Holding" como uma organiza√ß√£o [^1].

Para modelar NER usando *sequence labeling*, usamos *BIO tagging* [^1].  O *BIO tagging* atribui um r√≥tulo a cada token que indica se o token come√ßa uma entidade (B), est√° dentro de uma entidade (I) ou n√£o faz parte de nenhuma entidade (O). Este sistema de rotulagem nos permite capturar a extens√£o e o tipo de cada entidade na sequ√™ncia. Usando o *BIO tagging* com modelos como o BERT, podemos aplicar o *fine-tuning* para otimizar os par√¢metros para prever as tags BIO corretas para cada token.

> üí° **Exemplo Num√©rico:** Consideremos a frase "Apple anunciou um novo iPhone em Cupertino". Usando o *BIO tagging* para NER, ter√≠amos as seguintes etiquetas:
>
> | Token     | R√≥tulo |
> |-----------|--------|
> | Apple     | B-ORG  |
> | anunciou  | O      |
> | um        | O      |
> | novo      | O      |
> | iPhone    | B-PROD |
> | em        | O      |
> | Cupertino | B-LOC  |
>
>  Aqui, "Apple" √© o in√≠cio (B) de uma organiza√ß√£o (ORG), "iPhone" √© o in√≠cio de um produto (PROD), e "Cupertino" √© o in√≠cio de uma localiza√ß√£o (LOC). As outras palavras s√£o rotuladas como O (fora de qualquer entidade nomeada). Este tipo de rotula√ß√£o √© essencial para o treinamento de modelos de *sequence labeling* para NER.

### Considera√ß√µes Importantes

- **Alinhamento de Tokens e R√≥tulos:** O tokenizador de subpalavras pode resultar em tokens que n√£o correspondem diretamente √†s palavras. Em tarefas de NER, onde as anota√ß√µes s√£o geralmente feitas em palavras, um dos desafios √© lidar com esse desalinhamento [^1]. Para o treinamento, podemos simplesmente atribuir o r√≥tulo da palavra a todos os sub-tokens derivados da mesma. Para a decodifica√ß√£o, uma abordagem comum √© usar o r√≥tulo do primeiro subtoken para representar a palavra.

- **CRF:** Podemos passar os r√≥tulos da camada *softmax* para uma camada *Conditional Random Field* (CRF), que pode modelar transi√ß√µes entre r√≥tulos [^1]. A camada CRF √© especialmente √∫til em problemas como NER, onde as transi√ß√µes de r√≥tulo tem depend√™ncias.

**Teorema 1:** A utiliza√ß√£o de um CRF ap√≥s a camada softmax em tarefas de *sequence labeling* como NER, pode levar a uma melhoria no desempenho, em especial em cen√°rios com forte depend√™ncia contextual entre r√≥tulos. Isso ocorre porque o CRF modela explicitamente a probabilidade de uma sequ√™ncia de r√≥tulos, e n√£o apenas a probabilidade de um r√≥tulo individual, como faz uma camada *softmax* isolada.

**Prova do Teorema 1:**

Para provar o teorema 1, vamos demonstrar porque o uso de um CRF ap√≥s o softmax em *sequence labeling* pode levar a uma melhoria no desempenho, especialmente quando h√° depend√™ncias contextuais entre os r√≥tulos.

I. Em um modelo de *sequence labeling* com uma camada *softmax* isolada, a probabilidade de um r√≥tulo para um token √© calculada independentemente de outros tokens na sequ√™ncia. Isso ignora as depend√™ncias contextuais entre r√≥tulos adjacentes.

II. Um modelo CRF, por outro lado, modela a probabilidade de toda a sequ√™ncia de r√≥tulos, levando em considera√ß√£o as transi√ß√µes entre r√≥tulos adjacentes. Formalmente, a probabilidade de uma sequ√™ncia de r√≥tulos $y = [y_1, y_2, \ldots, y_n]$ dado uma sequ√™ncia de entrada $x$ √© modelada como:
    $$P(y|x) = \frac{1}{Z(x)} \exp(\sum_{i=1}^{n} A_{y_{i-1}, y_i} + \sum_{i=1}^{n} P(y_i|x))$$
     onde $A_{y_{i-1}, y_i}$ representa os *scores* de transi√ß√£o entre os r√≥tulos $y_{i-1}$ e $y_i$, $P(y_i|x)$ s√£o os *scores* obtidos da camada *softmax* para o r√≥tulo $y_i$ e $Z(x)$ √© um fator de normaliza√ß√£o.

III. Ao modelar transi√ß√µes de r√≥tulos usando os *scores* $A_{y_{i-1}, y_i}$, o CRF consegue capturar as depend√™ncias contextuais que s√£o comuns em tarefas como NER. Por exemplo, √© muito mais prov√°vel que um r√≥tulo 'I-PER' (inside person) siga um r√≥tulo 'B-PER' (begin person) do que um r√≥tulo 'O' (outside).

IV. Portanto, o CRF modela a probabilidade conjunta de uma sequ√™ncia de r√≥tulos, em vez de r√≥tulos independentes. A considera√ß√£o da probabilidade da sequ√™ncia completa permite que o CRF fa√ßa previs√µes mais coerentes e precisas.

V. Em resumo, ao modelar as depend√™ncias entre r√≥tulos, o CRF pode melhorar a precis√£o das previs√µes, especialmente em cen√°rios onde as depend√™ncias contextuais entre os r√≥tulos s√£o fortes. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que o modelo *softmax* preveja as seguintes probabilidades para a sequ√™ncia de r√≥tulos "B-PER", "I-PER", "O":
>  - Para o primeiro token: $P(\text{B-PER}) = 0.8$, $P(\text{I-PER}) = 0.1$, $P(\text{O}) = 0.1$.
> - Para o segundo token: $P(\text{B-PER}) = 0.2$, $P(\text{I-PER}) = 0.7$, $P(\text{O}) = 0.1$.
> - Para o terceiro token: $P(\text{B-PER}) = 0.1$, $P(\text{I-PER}) = 0.2$, $P(\text{O}) = 0.7$.
>
>  Um CRF pode modelar transi√ß√µes mais prov√°veis, como a transi√ß√£o de B-PER para I-PER, e penalizar transi√ß√µes improv√°veis como B-PER para O. Os pesos de transi√ß√£o podem ser expressos como uma matriz, onde cada elemento $A_{ij}$ representa a pontua√ß√£o da transi√ß√£o do r√≥tulo $i$ para o r√≥tulo $j$.
>
> ```python
> import numpy as np
>
> # Probabilidades de saida do softmax (exemplo)
> softmax_probs = np.array([
>    [0.8, 0.1, 0.1], # B-PER, I-PER, O para o primeiro token
>    [0.2, 0.7, 0.1], # B-PER, I-PER, O para o segundo token
>    [0.1, 0.2, 0.7]  # B-PER, I-PER, O para o terceiro token
> ])
>
> # Matriz de transi√ß√£o CRF (exemplo)
> transition_scores = np.array([
>    [0.5, 1.0, -2.0], # B-PER para B-PER, I-PER, O
>    [-1.0, 0.8, -0.5],# I-PER para B-PER, I-PER, O
>    [-0.5, -1.0, 0.9] # O para B-PER, I-PER, O
> ])
>
> def calculate_sequence_score(softmax_probs, transition_scores, labels):
>  score = 0
>  for i, label_idx in enumerate(labels):
>      score += np.log(softmax_probs[i][label_idx])
>      if i > 0:
>        score += transition_scores[labels[i-1]][label_idx]
>  return score
>
> labels1 = [0,1,2] # Sequencia B-PER, I-PER, O
> labels2 = [0,0,2] # Sequencia B-PER, B-PER, O
>
> score1 = calculate_sequence_score(softmax_probs, transition_scores, labels1)
> score2 = calculate_sequence_score(softmax_probs, transition_scores, labels2)
> print(f"Pontua√ß√£o da sequ√™ncia B-PER, I-PER, O: {score1:.2f}")
> print(f"Pontua√ß√£o da sequ√™ncia B-PER, B-PER, O: {score2:.2f}")
> ```
>
> No exemplo, a pontua√ß√£o da sequ√™ncia correta (B-PER, I-PER, O) √© maior do que a da sequ√™ncia incorreta (B-PER, B-PER, O), mostrando como o CRF ajuda a modelar as depend√™ncias e transi√ß√µes de r√≥tulos.

- **M√©tricas de Avalia√ß√£o:** Os modelos de *sequence labeling* s√£o avaliados usando m√©tricas como precis√£o, *recall*, e *F1-score*, que medem a efic√°cia do modelo na previs√£o de r√≥tulos [^1]. Essas m√©tricas s√£o calculadas tanto no n√≠vel do token quanto no n√≠vel da entidade.

**Corol√°rio 1.1:** Ao avaliar modelos de NER, √© importante reportar m√©tricas tanto no n√≠vel do token quanto no n√≠vel da entidade. As m√©tricas em n√≠vel de token fornecem uma vis√£o da capacidade do modelo em rotular corretamente cada token individualmente, enquanto as m√©tricas em n√≠vel da entidade refletem a precis√£o do modelo na detec√ß√£o e classifica√ß√£o de entidades completas.

**Prova do Corol√°rio 1.1:**

Para demonstrar a import√¢ncia de reportar m√©tricas de avalia√ß√£o tanto no n√≠vel do token quanto no n√≠vel da entidade para tarefas de NER, vamos analisar as diferen√ßas e complementaridades dessas medidas:

I.  **M√©tricas no n√≠vel do token**: Essas m√©tricas (precis√£o, *recall* e *F1-score*) s√£o calculadas considerando cada token individualmente. Elas avaliam se cada token foi rotulado corretamente ou n√£o.

    *   A *precis√£o* no n√≠vel do token mede a propor√ß√£o de tokens rotulados corretamente em rela√ß√£o a todos os tokens que o modelo rotulou como parte de alguma entidade.
    *   O *recall* no n√≠vel do token mede a propor√ß√£o de tokens rotulados corretamente em rela√ß√£o a todos os tokens que *realmente* fazem parte de alguma entidade.
    *   O *F1-score* no n√≠vel do token √© a m√©dia harm√¥nica entre precis√£o e *recall*, fornecendo uma m√©trica balanceada.

II. **M√©tricas no n√≠vel da entidade**: Essas m√©tricas s√£o calculadas considerando as entidades como um todo. Uma entidade √© considerada corretamente identificada apenas se seu *span* completo foi detectado corretamente e todos os r√≥tulos de tokens dentro do *span* estiverem corretos.

    *   A *precis√£o* no n√≠vel da entidade mede a propor√ß√£o de entidades corretamente identificadas em rela√ß√£o ao total de entidades que o modelo detectou.
    *   O *recall* no n√≠vel da entidade mede a propor√ß√£o de entidades corretamente identificadas em rela√ß√£o ao total de entidades presentes no conjunto de dados.
    *   O *F1-score* no n√≠vel da entidade √© a m√©dia harm√¥nica entre precis√£o e *recall* no n√≠vel da entidade.

III. **Complementaridade:** As m√©tricas no n√≠vel do token avaliam o desempenho em termos de cada r√≥tulo de token individual, enquanto as m√©tricas no n√≠vel da entidade avaliam o desempenho em termos da identifica√ß√£o correta de *spans* e tipos de entidades.

    *   Por exemplo, um modelo pode ter uma alta precis√£o no n√≠vel do token, mas ter um baixo *recall* no n√≠vel da entidade se ele frequentemente rotular entidades incorretamente, por exemplo, rotulando apenas alguns dos tokens que comp√µem a entidade corretamente.
    *   Em contrapartida, um modelo pode ter um alto *recall* no n√≠vel da entidade, mas baixa precis√£o no n√≠vel do token se ele muitas vezes errar na rotula√ß√£o dos tokens dentro das entidades.

IV. **Conclus√£o:** Ao reportar ambas as m√©tricas, avaliamos o desempenho do modelo de maneira abrangente. M√©trica de n√≠vel do token nos informa a capacidade do modelo de rotular cada token corretamente, enquanto a m√©trica de n√≠vel da entidade nos informa se o modelo √© capaz de identificar corretamente entidades completas. Portanto, √© crucial reportar ambas as m√©tricas para ter uma avalia√ß√£o completa da capacidade do modelo em tarefas de NER. ‚ñ†

> üí° **Exemplo Num√©rico:** Vamos supor que nosso modelo tenha as seguintes previs√µes para uma frase (com entidades em negrito) : "A **Apple** lan√ßou o novo **iPhone** em **Cupertino**".
>
>  **R√≥tulos verdadeiros:**
>
>   - A: O
>   - Apple: B-ORG
>   - lan√ßou: O
>   - o: O
>   - novo: O
>   - iPhone: B-PROD
>   - em: O
>   - Cupertino: B-LOC
>
> **R√≥tulos previstos:**
>
>  - A: O
>   - Apple: B-ORG
>   - lan√ßou: O
>   - o: O
>   - novo: O
>   - iPhone: I-PROD  *(erro)*
>   - em: O
>   - Cupertino: B-LOC
>
> **An√°lise:**
>
> *   **N√≠vel do Token:**
>     *   **Precis√£o:** 7/8 = 0.875 (7 r√≥tulos corretos de 8 previstos como entidade)
>     *   **Recall:** 7/8 = 0.875 (7 r√≥tulos corretos de 8 r√≥tulos reais como entidade)
>     *  **F1-Score:** 2 * (0.875*0.875) / (0.875 + 0.875) = 0.875
> *   **N√≠vel da Entidade:**
>     *   **Precis√£o:** 2/2 = 1.0 (2 entidades detectadas corretamente de 2 detectadas)
>     *   **Recall:** 2/3 = 0.67 (2 entidades detectadas corretamente de 3 entidades reais)
>     *   **F1-Score:** 2 * (1.0 * 0.67) / (1.0 + 0.67) = 0.80
>
>  Note que, apesar do bom desempenho no n√≠vel do token, o *recall* no n√≠vel da entidade √© mais baixo porque o modelo errou ao rotular o token "iPhone" como "I-PROD" em vez de "B-PROD", o que resultou em uma entidade incorreta. Este exemplo ilustra a import√¢ncia de reportar m√©tricas em ambos os n√≠veis.

### Conclus√£o

O ajuste fino para o *sequence labeling* √© uma t√©cnica poderosa para adaptar modelos de linguagem pr√©-treinados para tarefas que requerem classifica√ß√£o em n√≠vel de token, usando uma camada *feedforward* seguida por um *softmax* ou um CRF. Este processo envolve a otimiza√ß√£o dos pesos do modelo e do classificador para prever os r√≥tulos corretos para cada token em uma sequ√™ncia. Atrav√©s de t√©cnicas como *BIO tagging*, podemos lidar com problemas como o NER, capturando as entidades e suas categorias usando *sequence labeling*. O *fine-tuning* permite que modelos de linguagem pr√©-treinados sejam adaptados para resolver problemas mais complexos em *natural language processing*.

### Refer√™ncias
[^1]: Texto fornecido anteriormente neste cap√≠tulo.
<!-- END -->
