## Modelos de Linguagem Mascarados: Uma An√°lise Profunda

### Introdu√ß√£o
Este cap√≠tulo aprofunda o conceito de **Masked Language Models (MLMs)**, uma abordagem fundamental no campo de modelos de linguagem pr√©-treinados, contrastando-os com os modelos causais previamente explorados [^1]. Enquanto modelos causais, como os apresentados no cap√≠tulo anterior, predizem a pr√≥xima palavra em uma sequ√™ncia, MLMs utilizam um paradigma de modelagem de linguagem mascarada onde o modelo √© treinado para prever palavras que foram intencionalmente "mascaradas" dentro da sequ√™ncia [^1]. Esta t√©cnica, ao contr√°rio da abordagem causal, permite que o modelo aprenda a partir de um contexto bidirecional, considerando informa√ß√µes tanto √† esquerda quanto √† direita do token mascarado [^1]. Este m√©todo resulta em representa√ß√µes contextuais mais ricas e um melhor entendimento das rela√ß√µes entre palavras, embora torne os MLMs menos adequados para a gera√ß√£o de texto, o seu ponto forte √© a compreens√£o e infer√™ncia [^2].

### Conceitos Fundamentais
#### Arquitetura e Mecanismos
O n√∫cleo dos MLMs √© o **codificador transformer bidirecional** [^1]. Ao contr√°rio dos modelos causais, que processam informa√ß√µes sequencialmente da esquerda para a direita [^1], os codificadores bidirecionais utilizam a **autoaten√ß√£o** para mapear sequ√™ncias de embeddings de entrada $(x_1, ..., x_n)$ em sequ√™ncias de embeddings de sa√≠da $(h_1, ..., h_n)$, onde cada vetor de sa√≠da √© contextualizado usando informa√ß√µes de toda a sequ√™ncia de entrada [^2]. Esta contextualiza√ß√£o permite que o modelo compreenda melhor o papel de cada palavra no contexto, tornando-os ideais para tarefas de classifica√ß√£o e decis√£o baseadas no contexto [^2].

A implementa√ß√£o da arquitetura bidirecional √© realizada removendo a etapa de mascaramento da matriz $Q K^T$ [^2]. Anteriormente, em modelos causais, o mascaramento era necess√°rio para garantir que a aten√ß√£o n√£o "olhasse" para tokens futuros [^2]. A remo√ß√£o dessa m√°scara permite que cada token atenda a todos os outros tokens na sequ√™ncia [^2, 3]. A computa√ß√£o da aten√ß√£o em MLMs segue a mesma equa√ß√£o apresentada anteriormente, mas sem a m√°scara:

$$A = \text{softmax} \left(\frac{Q K^T}{\sqrt{d_k}}\right) V$$ [^3]

Esta mudan√ßa permite que o modelo aprenda rela√ß√µes bidirecionais, enquanto mant√©m o restante da arquitetura do transformer, incluindo as camadas feedforward e de normaliza√ß√£o [^3].

**Lema 1** (Conex√£o entre Autoaten√ß√£o e Contexto Bidirecional) A remo√ß√£o da m√°scara na matriz $QK^T$ permite que cada token em uma sequ√™ncia de entrada atenda a todos os outros tokens, resultando em uma representa√ß√£o contextual bidirecional. Isso √© crucial para que MLMs capturem depend√™ncias de longo alcance na sequ√™ncia, o que √© essencial para tarefas de compreens√£o de linguagem natural.

*Prova:*
I. A autoaten√ß√£o calcula a import√¢ncia de cada token em rela√ß√£o aos demais, usando as matrizes de consulta $Q$, chave $K$ e valor $V$.
II. Em modelos causais, uma m√°scara √© usada na matriz de aten√ß√£o $QK^T$ para impedir que um token atenda a tokens futuros.
III. Ao remover essa m√°scara, cada token passa a ter acesso √†s informa√ß√µes de todos os outros tokens na sequ√™ncia, tanto os anteriores quanto os posteriores.
IV. Essa capacidade de atender a todos os tokens na sequ√™ncia permite que cada token se torne contextualizado por todos os outros tokens, permitindo ao modelo obter um entendimento bidirecional do contexto.
V. Portanto, a remo√ß√£o da m√°scara na matriz $QK^T$ permite que cada token em uma sequ√™ncia de entrada atenda a todos os outros tokens, resultando em uma representa√ß√£o contextual bidirecional.
‚ñ†
> üí° **Exemplo Num√©rico:**
>
> Considere a frase "o gato preto dorme". Vamos representar esta frase com embeddings simples para fins ilustrativos:
>
>   - "o": [0.1, 0.2]
>   - "gato": [0.3, 0.4]
>   - "preto": [0.5, 0.6]
>   - "dorme": [0.7, 0.8]
>
> Inicialmente,  $Q$, $K$, e $V$ seriam transforma√ß√µes desses embeddings. Vamos supor para simplificar que $Q=K=V$, ent√£o $Q$,$K$, e $V$ tamb√©m s√£o:
>
>   - "o": [0.1, 0.2]
>   - "gato": [0.3, 0.4]
>   - "preto": [0.5, 0.6]
>   - "dorme": [0.7, 0.8]
>
>
> Agora, para calcular a matriz de aten√ß√£o $A$, vamos primeiro calcular $QK^T$:
>
> $$QK^T = \begin{bmatrix}
> 0.1 & 0.2 \\
> 0.3 & 0.4 \\
> 0.5 & 0.6 \\
> 0.7 & 0.8
> \end{bmatrix}
> \begin{bmatrix}
> 0.1 & 0.3 & 0.5 & 0.7 \\
> 0.2 & 0.4 & 0.6 & 0.8
> \end{bmatrix}
> = \begin{bmatrix}
> 0.05 & 0.11 & 0.17 & 0.23 \\
> 0.11 & 0.25 & 0.39 & 0.53 \\
> 0.17 & 0.39 & 0.61 & 0.83 \\
> 0.23 & 0.53 & 0.83 & 1.13
> \end{bmatrix}$$
>
> Considerando $d_k = 2$, ent√£o $\sqrt{d_k} = \sqrt{2} \approx 1.414$
>
> Dividindo $QK^T$ por $\sqrt{d_k}$:
>
> $$\frac{QK^T}{\sqrt{d_k}} = \begin{bmatrix}
> 0.035 & 0.078 & 0.120 & 0.163 \\
> 0.078 & 0.177 & 0.276 & 0.375 \\
> 0.120 & 0.276 & 0.431 & 0.587 \\
> 0.163 & 0.375 & 0.587 & 0.799
> \end{bmatrix}$$
>
>Aplicando a fun√ß√£o softmax a cada linha, obtemos a matriz de aten√ß√£o $A$. O resultado final da aten√ß√£o $AV$ ir√° contextualizar os embeddings originais, ajustando a import√¢ncia de cada palavra com base em todas as outras palavras na frase. Note que este √© um exemplo com valores simplificados, e os embeddings reais e as transforma√ß√µes $Q,K,V$ em MLMs s√£o muito mais complexas.
>
> ```mermaid
> graph LR
>     A[Input Embeddings] --> B(Q,K,V Transformation)
>     B --> C(QK^T Calculation)
>     C --> D(Scaled QK^T)
>     D --> E(Softmax)
>     E --> F(Attention Matrix A)
>     F --> G(AV)
>     G --> H[Contextualized Embeddings]
> ```

#### Treinamento de Modelos MLMs
O treinamento de MLMs √© feito atrav√©s do preenchimento de lacunas, conhecido como **cloze task** [^4]. Em vez de prever a pr√≥xima palavra, como em modelos causais, MLMs preveem tokens que foram removidos ou mascarados do texto de entrada [^4]. Esta t√©cnica √© tamb√©m referida como **denoising**, onde o modelo aprende a reconstruir um input corrompido ou ruidoso [^4].

A t√©cnica de **Masked Language Modeling (MLM)** seleciona aleatoriamente tokens da sequ√™ncia de entrada para treinamento [^4]. Os tokens selecionados s√£o tratados da seguinte forma:
- 80% s√£o substitu√≠dos pelo token especial `[MASK]` [^5]
- 10% s√£o substitu√≠dos por outros tokens aleat√≥rios do vocabul√°rio [^5]
- 10% permanecem inalterados [^5]

Esta abordagem de mascaramento garante que o modelo n√£o apenas aprenda a prever tokens, mas tamb√©m a lidar com informa√ß√µes ruidosas e a generalizar a partir de um contexto variado [^5].

O objetivo do treinamento MLM √© prever os tokens originais que foram mascarados [^5]. O modelo gera uma distribui√ß√£o de probabilidade sobre o vocabul√°rio para cada token mascarado, e a perda de entropia cruzada entre as previs√µes do modelo e as palavras mascaradas originais √© usada para otimizar os par√¢metros do modelo [^5]. √â importante notar que todos os tokens de input contribuem para o processo de auto-aten√ß√£o, mas apenas os tokens mascarados contribuem para a perda [^5].

**Proposi√ß√£o 1** (Impacto do Mascaramento Aleat√≥rio) A estrat√©gia de mascaramento aleat√≥rio, incluindo a substitui√ß√£o por `[MASK]`, tokens aleat√≥rios e a preserva√ß√£o de tokens originais, √© crucial para o desempenho dos MLMs. Essa t√©cnica for√ßa o modelo a aprender representa√ß√µes robustas, capazes de lidar com ru√≠do e incerteza, promovendo uma melhor generaliza√ß√£o em tarefas de downstream.

*Prova:*
I. A substitui√ß√£o de 80% dos tokens por `[MASK]` for√ßa o modelo a usar o contexto bidirecional para inferir a palavra mascarada.
II. A substitui√ß√£o de 10% dos tokens por tokens aleat√≥rios introduz ru√≠do no input, o que obriga o modelo a aprender a lidar com informa√ß√µes corrompidas e a identificar a palavra original corretamente.
III. A preserva√ß√£o de 10% dos tokens originais evita o sobreajuste ao for√ßar o modelo a n√£o se concentrar apenas em tokens mascarados.
IV. A combina√ß√£o dessas tr√™s estrat√©gias garante que o modelo aprenda a reconstruir o input original de um input parcialmente corrupto ou desconhecido.
V. Portanto, a estrat√©gia de mascaramento aleat√≥rio, incluindo a substitui√ß√£o por `[MASK]`, tokens aleat√≥rios e a preserva√ß√£o de tokens originais, √© crucial para o desempenho dos MLMs, for√ßando o modelo a aprender representa√ß√µes robustas, capazes de lidar com ru√≠do e incerteza, promovendo uma melhor generaliza√ß√£o em tarefas de downstream.
‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere a seguinte frase: "O cachorro corre r√°pido na rua". Durante o treinamento MLM, essa frase poderia ser transformada da seguinte maneira:
>
> 1. **Sele√ß√£o Aleat√≥ria:** Vamos supor que os tokens "cachorro" e "na" sejam selecionados aleatoriamente para mascaramento.
> 2. **Aplica√ß√£o da M√°scara:**
>    - 80% dos tokens selecionados s√£o substitu√≠dos por `[MASK]`. Suponha que "cachorro" seja mascarado como `[MASK]`.
>    - 10% dos tokens s√£o substitu√≠dos por um token aleat√≥rio. Suponha que "na" seja substitu√≠do por "em".
>    - 10% dos tokens s√£o mantidos originais (nesse caso, vamos supor que nenhum token foi selecionado para mascaramento).
>
> A frase transformada seria: "O `[MASK]` corre r√°pido em rua". O modelo ent√£o tentaria prever "cachorro" para o primeiro `[MASK]` e "na" para a palavra "em" (considerando o contexto).
>
> A perda √© calculada com base na diferen√ßa entre as probabilidades preditas pelo modelo para as palavras mascaradas e os seus valores reais. As probabilidades s√£o calculadas utilizando as matrizes de *unembedding* $E^T$ e softmax.
>
> Se, por exemplo, ap√≥s a passagem pela rede, a sa√≠da $h_i$ para o token `[MASK]` (que corresponde a "cachorro") for representada por um vetor, por exemplo, [0.2, 0.4, 0.1, 0.3], e a matriz de *unembedding* $E^T$ for uma matriz que relaciona cada token do vocabul√°rio a um vetor (supondo um vocabul√°rio de 5 palavras), a matriz de *unembedding* pode ser representada como:
> $$E^T = \begin{bmatrix}
>  0.1 & 0.2 & 0.3 & 0.4 \\
>  0.5 & 0.6 & 0.7 & 0.8 \\
>  0.9 & 0.1 & 0.2 & 0.3 \\
>  0.4 & 0.5 & 0.6 & 0.7 \\
>  0.8 & 0.9 & 0.1 & 0.2 \\
> \end{bmatrix}$$
>
> O c√°lculo de $u_i$ seria:
>
> $$u_i = h_i E^T = \begin{bmatrix} 0.2 & 0.4 & 0.1 & 0.3 \end{bmatrix} \begin{bmatrix}
>  0.1 & 0.2 & 0.3 & 0.4 \\
>  0.5 & 0.6 & 0.7 & 0.8 \\
>  0.9 & 0.1 & 0.2 & 0.3 \\
>  0.4 & 0.5 & 0.6 & 0.7 \\
>  0.8 & 0.9 & 0.1 & 0.2 \\
> \end{bmatrix} = \begin{bmatrix} 0.59 & 0.68 & 0.61 & 0.71 \end{bmatrix}$$
>
> O c√°lculo de $y_i$ seria:
>
> $$y_i = \text{softmax}(u_i) = \text{softmax}\begin{bmatrix} 0.59 & 0.68 & 0.61 & 0.71 \end{bmatrix} = \begin{bmatrix} 0.23 & 0.25 & 0.23 & 0.29 \end{bmatrix}$$
>
> A sa√≠da do softmax nos d√° a probabilidade de cada palavra do vocabul√°rio ser a palavra mascarada. No nosso exemplo, o modelo est√° 29% seguro que a palavra correcta √© a quarta palavra do vocabul√°rio. Quanto mais perto do valor correcto estiver a predi√ß√£o, menor ser√° a perda. A perda √© calculada comparando a probabilidade predita com a palavra original (no nosso caso, "cachorro") e √© usada para ajustar os par√¢metros do modelo. Este √© um exemplo simplificado e os valores reais seriam diferentes.

A arquitetura de treinamento envolve a tokeniza√ß√£o da sequ√™ncia de entrada usando um modelo de subpalavra, como WordPiece ou SentencePiece [^3]. Os embeddings de palavras para todos os tokens s√£o ent√£o recuperados e combinados com embeddings posicionais, e ent√£o passados atrav√©s de uma pilha de blocos transformer. A sa√≠da do √∫ltimo bloco transformer √© ent√£o passada para a linguagem head modeling (LM head), que gera as probabilidades sobre o vocabul√°rio [^5].

As equa√ß√µes para calcular as probabilidades sobre o vocabul√°rio para cada token mascarado s√£o:
$$u_i = h_i E^T$$
$$y_i = \text{softmax}(u_i)$$ [^5]

Onde $h_i$ √© a sa√≠da do √∫ltimo transformer layer para o token mascarado $i$, $E^T$ √© a matriz de unembedding, $u_i$ s√£o os logits, e $y_i$ s√£o as probabilidades sobre o vocabul√°rio [^5].

##### Predi√ß√£o da Pr√≥xima Senten√ßa (Next Sentence Prediction)
Al√©m do objetivo de mascaramento, alguns modelos BERT tamb√©m incluem um objetivo de **Next Sentence Prediction (NSP)** [^6]. O objetivo √© aprender rela√ß√µes entre pares de frases [^6]. Durante o treinamento, o modelo recebe pares de frases que s√£o ou adjacentes ou aleat√≥rias, e o modelo deve prever se as frases s√£o adjacentes ou n√£o [^6]. Para isto, √© adicionado um token `[CLS]` no in√≠cio da sequ√™ncia e um token `[SEP]` entre as frases [^6]. A sa√≠da correspondente ao token `[CLS]` √© passada atrav√©s de um classificador para realizar a classifica√ß√£o da rela√ß√£o da senten√ßa [^6].

**Teorema 1** (Rela√ß√£o entre NSP e Compreens√£o Textual) A tarefa de Next Sentence Prediction (NSP) auxilia o modelo a capturar rela√ß√µes inter-sentenciais, aprimorando sua capacidade de compreender o fluxo l√≥gico de um texto. Modelos treinados com NSP tendem a exibir um desempenho melhor em tarefas de compreens√£o que exigem racioc√≠nio sobre m√∫ltiplas senten√ßas.

*Prova:*
I. O objetivo do NSP √© treinar o modelo para classificar se dois segmentos de texto apresentados s√£o consecutivos em um documento original.
II. Para alcan√ßar esse objetivo, o modelo recebe pares de senten√ßas que podem ser cont√≠guas (seguindo uma √† outra) ou n√£o (vindo de diferentes partes do corpus).
III. Ao treinar com este objetivo, o modelo √© for√ßado a aprender a identificar rela√ß√µes inter-sentenciais, em vez de apenas rela√ß√µes intra-sentenciais.
IV. O token `[CLS]` no in√≠cio da sequ√™ncia resume as duas senten√ßas e a sua rela√ß√£o. Este token `[CLS]` √© passado para uma camada de classifica√ß√£o para prever se as duas senten√ßas est√£o relacionadas ou n√£o.
V. Esta aprendizagem de rela√ß√µes inter-sentenciais permite que o modelo entenda melhor o fluxo l√≥gico de um texto, que melhora o desempenho em tarefas de compreens√£o que envolvem m√∫ltiplas senten√ßas.
VI. Portanto, a tarefa de Next Sentence Prediction (NSP) auxilia o modelo a capturar rela√ß√µes inter-sentenciais, aprimorando sua capacidade de compreender o fluxo l√≥gico de um texto, resultando em um melhor desempenho em tarefas de compreens√£o que exigem racioc√≠nio sobre m√∫ltiplas senten√ßas.
‚ñ†
> üí° **Exemplo Num√©rico:**
>
> Considere as seguintes frases:
>
>   - Frase A: "O sol est√° brilhando hoje."
>   - Frase B: "Os p√°ssaros cantam alegremente."
>   - Frase C: "A noite caiu rapidamente."
>
> Para o treinamento NSP, dois pares de frases seriam constru√≠dos:
>
>   - Par 1: Frase A e Frase B (pares adjacentes - label: 1)
>   - Par 2: Frase A e Frase C (pares n√£o-adjacentes - label: 0)
>
> Os dados de entrada para o modelo seriam tokenizados e combinados da seguinte forma:
>
>   - Input Par 1: `[CLS]` "O sol est√° brilhando hoje." `[SEP]` "Os p√°ssaros cantam alegremente."
>   - Input Par 2: `[CLS]` "O sol est√° brilhando hoje." `[SEP]` "A noite caiu rapidamente."
>
> O modelo passaria esses inputs por sua arquitetura e geraria um vetor de sa√≠da para o token `[CLS]`. Esse vetor seria usado por um classificador para prever se as frases s√£o adjacentes (label 1) ou n√£o (label 0).
>
>   Se o modelo predisser, por exemplo, que a probabilidade de Par 1 ser adjacente √© de 0.8 e a probabilidade de Par 2 ser adjacente √© de 0.1, isso indicaria um resultado relativamente bom, considerando que o modelo corretamente associou as frases adjacentes e n√£o associou as n√£o adjacentes. A perda seria ent√£o calculada com base na diferen√ßa entre as predi√ß√µes do modelo e as labels reais.

####  Contextual Embeddings
Uma das caracter√≠sticas chave de MLMs s√£o os **contextual embeddings** [^8]. Diferentemente dos embeddings est√°ticos, que atribuem um √∫nico vetor a cada palavra no vocabul√°rio, contextual embeddings representam cada palavra com um vetor diferente, que depende do contexto em que a palavra aparece [^8]. Cada vetor de sa√≠da $z_i$ do modelo, correspondente a um token de entrada $x_i$, representa o significado da palavra em seu contexto [^8]. Estes embeddings podem ser usados para medir a similaridade sem√¢ntica entre palavras em contexto e s√£o √∫teis para tarefas que requerem um modelo de compreens√£o do significado de palavras [^9].

**Corol√°rio 1** (Vantagem dos Contextual Embeddings) A capacidade de gerar representa√ß√µes contextuais por meio de MLMs resulta em uma compreens√£o mais precisa das nuances sem√¢nticas e da polissemia das palavras, em contraste com os embeddings est√°ticos que atribuem um √∫nico significado a cada palavra.

*Prova:*
I. Embeddings est√°ticos associam um vetor fixo a cada palavra do vocabul√°rio, independentemente do contexto em que a palavra aparece.
II. MLMs, atrav√©s da arquitetura transformer, geram representa√ß√µes contextuais, onde cada vetor √© dependente dos tokens vizinhos na sequ√™ncia.
III. Isto permite que MLMs representem diferentes significados da mesma palavra em contextos distintos.
IV. Portanto, a capacidade de gerar representa√ß√µes contextuais por meio de MLMs resulta em uma compreens√£o mais precisa das nuances sem√¢nticas e da polissemia das palavras, em contraste com os embeddings est√°ticos que atribuem um √∫nico significado a cada palavra.
‚ñ†
> üí° **Exemplo Num√©rico:**
>
> Considere a palavra "banco" em duas frases:
>
>   1. "Eu fui ao banco para sacar dinheiro."
>   2. "Sentei no banco do jardim para relaxar."
>
> Um modelo de embedding est√°tico, como Word2Vec, atribuiria o mesmo vetor para a palavra "banco" em ambas as frases. No entanto, um MLM geraria dois vetores distintos, um para cada contexto.
>
> Vamos supor que o embedding contextualizado para "banco" na primeira frase seja o vetor $z_1 = [0.2, 0.5, 0.1, 0.7]$ e na segunda frase seja $z_2 = [0.8, 0.3, 0.9, 0.2]$.  Um c√°lculo de similaridade de cosseno entre esses vetores mostraria uma baixa similaridade, refletindo as diferen√ßas no significado contextual:
>
> $$\text{cosine\_similarity}(z_1, z_2) = \frac{z_1 \cdot z_2}{||z_1|| \cdot ||z_2||} = \frac{(0.2 \cdot 0.8) + (0.5 \cdot 0.3) + (0.1 \cdot 0.9) + (0.7 \cdot 0.2)}{\sqrt{0.2^2 + 0.5^2 + 0.1^2 + 0.7^2} \cdot \sqrt{0.8^2 + 0.3^2 + 0.9^2 + 0.2^2}} \approx \frac{0.42}{\sqrt{0.79} \cdot \sqrt{1.82}} \approx \frac{0.42}{0.89 \cdot 1.35} \approx 0.35$$
>
> Uma similaridade de cosseno de 0.35 indica uma baixa similaridade entre os dois vetores, o que √© desej√°vel neste caso pois a palavra "banco" possui significados distintos em cada frase. Esta baixa similaridade demonstra como os MLMs conseguem capturar diferentes nuances sem√¢nticas das palavras, gerando embeddings contextuais.
### Conclus√£o
Os Modelos de Linguagem Mascarada representam um avan√ßo significativo no campo do processamento de linguagem natural, possibilitando uma compreens√£o mais profunda do contexto textual. Ao empregar uma arquitetura transformer bidirecional e um objetivo de treinamento baseado em predi√ß√£o de palavras mascaradas, MLMs geram representa√ß√µes contextuais de alta qualidade, que s√£o fundamentais para uma variedade de tarefas de compreens√£o e infer√™ncia. Apesar de sua limita√ß√£o em gera√ß√£o de texto comparado com modelos causais, a capacidade de entender o significado no contexto faz dos MLMs uma ferramenta essencial para o processamento de linguagem natural. A combina√ß√£o de modelos transformer bidirecionais e abordagens de treinamento de denoising fornece uma forma poderosa de aprender representa√ß√µes contextuais, que se baseiam em outras √°reas como classifica√ß√£o, infer√™ncia, e outras tarefas de compreens√£o de linguagem natural.

### Refer√™ncias
[^1]: Cap√≠tulo 9, 10 e 11 do livro texto.
[^2]: Se√ß√£o 11.1 do livro texto.
[^3]: Se√ß√£o 11.1.1 do livro texto.
[^4]: Se√ß√£o 11.2 do livro texto.
[^5]: Se√ß√£o 11.2.1 do livro texto.
[^6]: Se√ß√£o 11.2.2 do livro texto.
[^8]: Se√ß√£o 11.3 do livro texto.
[^9]: Se√ß√£o 11.3.1 do livro texto.
<!-- END -->
