## Fine-Tuning para Classifica√ß√£o: Treinamento e Ajuste de Par√¢metros

### Introdu√ß√£o
Como abordamos no cap√≠tulo anterior, o *fine-tuning* √© um processo crucial para adaptar modelos de linguagem pr√©-treinados a tarefas espec√≠ficas [^1]. Este processo envolve a adi√ß√£o de *heads* espec√≠ficos √† aplica√ß√£o sobre o modelo pr√©-treinado e o treinamento desses *heads* com dados rotulados para a tarefa alvo [^1]. Este cap√≠tulo aprofunda o processo de treinamento e ajuste de par√¢metros durante o *fine-tuning*, focando nas sa√≠das de transformadores bidirecionais como entradas para os classificadores. Expandindo os conceitos introduzidos anteriormente sobre classifica√ß√£o de sequ√™ncias, pares de sequ√™ncias e rotula√ß√£o de sequ√™ncias, aqui exploraremos como a fun√ß√£o de perda guia o treinamento e como os par√¢metros s√£o ajustados para obter resultados √≥timos.

### Conceitos Fundamentais

O processo de *fine-tuning* tem como objetivo ajustar os par√¢metros do modelo, em particular os par√¢metros da camada de classifica√ß√£o (o *head*), para que o modelo se adapte √† tarefa espec√≠fica para a qual foi designado [^1].  O treinamento √© supervisionado, o que significa que dados rotulados s√£o necess√°rios para ajustar os par√¢metros do modelo [^1].

**O Papel da Fun√ß√£o de Perda**

Durante o treinamento, a diferen√ßa entre as previs√µes do modelo e os r√≥tulos verdadeiros (ground truth) √© medida atrav√©s de uma **fun√ß√£o de perda** [^1]. A fun√ß√£o de perda quantifica o qu√£o errado o modelo est√°, e o objetivo do treinamento √© minimizar essa perda [^1]. Em tarefas de classifica√ß√£o, a fun√ß√£o de perda mais comumente usada √© a **entropia cruzada (cross-entropy)**, que compara a distribui√ß√£o de probabilidade prevista com a distribui√ß√£o de probabilidade real [^1].

**Ajuste dos Par√¢metros**

O ajuste dos par√¢metros √© feito usando um algoritmo de otimiza√ß√£o, como o **descida do gradiente** (gradient descent) [^1]. Este algoritmo calcula o gradiente da fun√ß√£o de perda em rela√ß√£o aos par√¢metros do modelo e atualiza esses par√¢metros na dire√ß√£o oposta ao gradiente, de forma a reduzir a perda [^1]. A **retropropaga√ß√£o (backpropagation)** √© usada para calcular os gradientes atrav√©s do modelo, desde a camada de sa√≠da (o *head* do classificador) at√© as camadas de entrada (o modelo pr√©-treinado) [^1].

Em geral, durante o *fine-tuning*, os pesos do modelo pr√©-treinado s√£o mantidos fixos (congelados) ou s√£o ajustados de forma m√≠nima, enquanto os pesos das camadas de classifica√ß√£o s√£o treinados completamente [^1]. Isso √© feito para aproveitar o conhecimento generalizado da linguagem que o modelo pr√©-treinado j√° possui, e focar o aprendizado na tarefa espec√≠fica [^1]. No entanto, em algumas aplica√ß√µes, pode ser vantajoso ajustar algumas camadas do modelo pr√©-treinado, o que √© conhecido como *fine-tuning* completo, o que pode levar a melhorias de desempenho, embora tamb√©m possa levar a *overfitting*.

**Observa√ß√£o 1** √â importante notar que a escolha do otimizador e sua configura√ß√£o (como taxa de aprendizado e momentum) podem influenciar significativamente a velocidade e a qualidade da converg√™ncia do treinamento. O otimizador Adam, por exemplo, √© frequentemente utilizado por sua capacidade de adaptar as taxas de aprendizado para par√¢metros individuais, o que pode levar a uma converg√™ncia mais r√°pida e est√°vel.

#### Treinamento em Classifica√ß√£o de Sequ√™ncias
No contexto da classifica√ß√£o de sequ√™ncias, discutido previamente, o *classifier head* √© adicionado sobre a representa√ß√£o do token [CLS], e as probabilidades das classes s√£o calculadas por meio da equa√ß√£o (11.11) [^1]:
$$
\mathbf{y} = \text{softmax}(\mathbf{h}_{CLS}\mathbf{W}_C) \quad (11.11)
$$
Durante o treinamento, para cada exemplo, calculamos a perda de entropia cruzada entre a distribui√ß√£o de probabilidade prevista $\mathbf{y}$ e a distribui√ß√£o one-hot correspondente ao r√≥tulo verdadeiro. O gradiente dessa perda √© ent√£o calculado usando retropropaga√ß√£o, e os pesos $\mathbf{W}_C$ s√£o ajustados para reduzir a perda.

<br>

> üí° **Exemplo Num√©rico (Classifica√ß√£o de Sentimento):**
>
> Considere um modelo de classifica√ß√£o de sentimento com tr√™s classes: "positivo", "negativo" e "neutro". Suponha que a representa√ß√£o do token `[CLS]` para a frase "Este filme √© √≥timo" seja um vetor  $\mathbf{h}_{CLS} = [0.5, -0.2, 0.8, 0.1]$, e que a matriz de pesos do classificador $\mathbf{W}_C$ inicialmente seja uma matriz aleat√≥ria de dimens√£o $4 \times 3$, digamos:
> $$
> \mathbf{W}_C = \begin{bmatrix}
> 0.1 & -0.2 & 0.3 \\
> -0.3 & 0.4 & -0.1 \\
> 0.2 & -0.1 & 0.4 \\
> -0.1 & 0.3 & -0.2
> \end{bmatrix}
> $$
>
>  Ent√£o, $\mathbf{h}_{CLS} \mathbf{W}_C$ √©:
>
> $$
> \begin{bmatrix} 0.5 & -0.2 & 0.8 & 0.1 \end{bmatrix} \begin{bmatrix} 0.1 & -0.2 & 0.3 \\ -0.3 & 0.4 & -0.1 \\ 0.2 & -0.1 & 0.4 \\ -0.1 & 0.3 & -0.2 \end{bmatrix} = \begin{bmatrix} 0.25 & -0.13 & 0.49 \end{bmatrix}
> $$
>
> Aplicando a fun√ß√£o softmax obtemos as probabilidades $\mathbf{y}$:
>
> $$
> \mathbf{y} = \text{softmax}([0.25, -0.13, 0.49]) \approx [0.34, 0.22, 0.44]
> $$
>
> Isso significa que o modelo inicialmente prev√™ a frase como tendo 34% de chance de ser "positivo", 22% de ser "negativo" e 44% de ser "neutro". O r√≥tulo verdadeiro √© "positivo", representado por um vetor *one-hot* $[1, 0, 0]$. A perda de entropia cruzada √© calculada como:
>
> $$
> L = - (1 \cdot \log(0.34) + 0 \cdot \log(0.22) + 0 \cdot \log(0.44)) \approx 1.08
> $$
>
> O objetivo do treinamento √© reduzir essa perda. A retropropaga√ß√£o calcula o gradiente da perda em rela√ß√£o a $\mathbf{W}_C$, e o otimizador ajusta os valores de  $\mathbf{W}_C$ para que a probabilidade prevista para "positivo" aumente, e as outras diminuam. Por exemplo, ap√≥s uma atualiza√ß√£o, $\mathbf{y}$ poderia se tornar $[0.75, 0.06, 0.19]$, o que diminui a perda e aproxima a previs√£o do r√≥tulo correto.
>
> Durante o processo de treinamento, este processo √© repetido iterativamente para todos os dados de treinamento, e os pesos do classificador s√£o ajustados a cada passo para minimizar a perda global sobre o conjunto de treinamento.

*Prova:*
I. Para cada sequ√™ncia de entrada, o modelo gera uma sa√≠da de probabilidade $\mathbf{y}$ para cada classe atrav√©s da equa√ß√£o 11.11, que √© resultado da multiplica√ß√£o da representa√ß√£o $h_{CLS}$ com os pesos do classificador $W_C$ seguido por uma fun√ß√£o softmax [^1].
II. Seja $y_{true}$ o r√≥tulo verdadeiro (em formato one-hot). A perda de entropia cruzada $L$ √© definida como
$$L = -\sum_i y_{true, i} \log(y_i)$$,
onde a soma √© sobre todas as classes [^1].
III. Durante o treinamento, o objetivo √© minimizar $L$. O otimizador calcula os gradientes da fun√ß√£o de perda $L$ com respeito aos pesos $W_C$ atrav√©s da retropropaga√ß√£o.
IV. Os pesos $W_C$ s√£o ent√£o atualizados para reduzir a perda, movendo-se na dire√ß√£o oposta ao gradiente
V. Este processo √© repetido iterativamente at√© que a perda convirja para um m√≠nimo, resultando em pesos $W_C$ que est√£o ajustados para classificar corretamente as sequ√™ncias de entrada. ‚ñ†

**Lema 1.1**  Em problemas de classifica√ß√£o de sequ√™ncia com *K* classes, a matriz de pesos do classificador $\mathbf{W}_C$ tem dimens√£o $d \times K$, onde $d$ √© a dimens√£o do vetor de sa√≠da $h_{CLS}$ do modelo de linguagem pr√©-treinado.
*Prova:*
A sa√≠da do modelo pr√©-treinado, $h_{CLS}$, tem dimens√£o $d$. A matriz de pesos $\mathbf{W}_C$ deve multiplicar $h_{CLS}$ para produzir um vetor de scores, de dimens√£o *K* (o n√∫mero de classes). Assim, para que a multiplica√ß√£o de matrizes seja v√°lida e para que a sa√≠da tenha dimens√£o K, $\mathbf{W}_C$ deve ter dimens√£o $d \times K$. ‚ñ†

#### Treinamento em Classifica√ß√£o de Pares de Sequ√™ncias
Como abordado anteriormente, na classifica√ß√£o de pares de sequ√™ncias, a concatena√ß√£o dos embeddings do token [CLS] √© utilizada para modelar a rela√ß√£o entre as duas sequ√™ncias [^1]:
$$
h_{pair} = \text{concat}(h_{CLS}^{(1)}, h_{CLS}^{(2)})
$$
e a probabilidade √© calculada com um classificador adicional:
$$
\mathbf{y} = \text{softmax}(h_{pair} \mathbf{W}_P)
$$
O processo de treinamento segue a mesma l√≥gica da classifica√ß√£o de sequ√™ncias. A perda de entropia cruzada √© calculada comparando as probabilidades previstas com os r√≥tulos verdadeiros e usada para ajustar os pesos $W_P$.

> üí° **Exemplo Num√©rico (Classifica√ß√£o de Par√°frase):**
>
> Considere um problema de classifica√ß√£o de par√°frase, com duas classes: "par√°frase" e "n√£o par√°frase". Suponha que os embeddings `[CLS]` para as senten√ßas ‚ÄúO carro √© vermelho‚Äù e ‚ÄúO ve√≠culo √© da cor vermelha‚Äù sejam  $\mathbf{h}_{CLS}^{(1)} = [0.2, 0.5, -0.1, 0.3]$ e $\mathbf{h}_{CLS}^{(2)} = [0.1, 0.4, 0.2, 0.6]$, respectivamente. A concatena√ß√£o desses vetores resulta em:
>
> $$
> h_{pair} = \text{concat}([0.2, 0.5, -0.1, 0.3], [0.1, 0.4, 0.2, 0.6]) = [0.2, 0.5, -0.1, 0.3, 0.1, 0.4, 0.2, 0.6]
> $$
>
> A matriz de pesos $\mathbf{W}_P$  √© uma matriz de dimens√£o $8 \times 2$. Digamos que inicialmente:
>
> $$
> \mathbf{W}_P = \begin{bmatrix}
> 0.1 & -0.2 \\
> -0.3 & 0.4 \\
> 0.2 & -0.1 \\
> -0.1 & 0.3 \\
> 0.2 & -0.1 \\
> -0.4 & 0.2 \\
> 0.1 & -0.3 \\
> -0.2 & 0.4
> \end{bmatrix}
> $$
>
>
> Ent√£o,  $h_{pair} \mathbf{W}_P$ √©:
>
> $$
> \begin{bmatrix} 0.2 & 0.5 & -0.1 & 0.3 & 0.1 & 0.4 & 0.2 & 0.6 \end{bmatrix} \begin{bmatrix}
> 0.1 & -0.2 \\
> -0.3 & 0.4 \\
> 0.2 & -0.1 \\
> -0.1 & 0.3 \\
> 0.2 & -0.1 \\
> -0.4 & 0.2 \\
> 0.1 & -0.3 \\
> -0.2 & 0.4
> \end{bmatrix} = \begin{bmatrix} -0.19 & 0.92 \end{bmatrix}
> $$
> Aplicando a fun√ß√£o softmax obtemos as probabilidades $\mathbf{y}$:
>
> $$
> \mathbf{y} = \text{softmax}([-0.19, 0.92]) \approx [0.27, 0.73]
> $$
>
> Isso significa que o modelo inicialmente prev√™ o par de senten√ßas como tendo 27% de chance de ser "par√°frase" e 73% de ser "n√£o par√°frase".  O r√≥tulo verdadeiro √© "par√°frase", representado por um vetor *one-hot* $[1, 0]$.  A perda de entropia cruzada ser√°:
> $$
> L = - (1 \cdot \log(0.27) + 0 \cdot \log(0.73)) \approx 1.31
> $$
>
> O treinamento visa reduzir essa perda. Por meio da retropropaga√ß√£o, o otimizador ajusta os pesos $\mathbf{W}_P$ para que a probabilidade para "par√°frase" aumente. Ap√≥s uma atualiza√ß√£o, $\mathbf{y}$ poderia se tornar $[0.84, 0.16]$, o que reduz a perda e aproxima a previs√£o do r√≥tulo correto. Durante o treinamento, esse processo √© repetido por todos os dados rotulados do conjunto de treinamento.

*Prova:*
I. Os embeddings $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$ dos tokens [CLS] das duas sequ√™ncias s√£o concatenados para criar $h_{pair}$, que captura informa√ß√µes de ambas as sequ√™ncias [^1].
II. O classificador linear, com pesos $W_P$, produz uma pontua√ß√£o bruta que √© passada pela fun√ß√£o softmax para obter a distribui√ß√£o de probabilidade sobre as classes (par√°frase, n√£o par√°frase) [^1].
III. A perda de entropia cruzada, definida como
$$L = -\sum_i y_{true, i} \log(y_i)$$,
compara as probabilidades previstas com os r√≥tulos verdadeiros.
IV. Atrav√©s da retropropaga√ß√£o, o gradiente da perda √© calculado em rela√ß√£o aos pesos $W_P$, que s√£o ent√£o atualizados para minimizar a perda, adaptando o classificador √† tarefa de classifica√ß√£o de pares de sequ√™ncias. ‚ñ†

**Lema 2.1**  Em problemas de classifica√ß√£o de pares de sequ√™ncias, se a dimens√£o da sa√≠da $h_{CLS}$ do modelo pr√©-treinado √© $d$, ent√£o a dimens√£o do vetor $h_{pair}$ resultante da concatena√ß√£o ser√° $2d$. Al√©m disso, a matriz de pesos do classificador $\mathbf{W}_P$ ter√° dimens√£o $2d \times K$, onde K √© o n√∫mero de classes.
*Prova:*
Cada $h_{CLS}$ tem dimens√£o $d$. Portanto, ao concatenar os dois vetores, o vetor resultante $h_{pair}$ ter√° dimens√£o $2d$. De forma similar ao Lema 1.1, $\mathbf{W}_P$ deve ter dimens√£o $2d \times K$ para que a multiplica√ß√£o $h_{pair} \mathbf{W}_P$ resulte num vetor de scores de dimens√£o K. ‚ñ†

#### Treinamento em Rotula√ß√£o de Sequ√™ncias
Na rotula√ß√£o de sequ√™ncias, a sa√≠da de cada token, $h_i$, √© passada para um classificador que gera uma probabilidade sobre o conjunto de etiquetas, atrav√©s das equa√ß√µes (11.12) e (11.13) [^1]:
$$
\mathbf{y}_i = \text{softmax}(\mathbf{h}_i\mathbf{W}_K) \quad (11.12)
$$
$$
t_i = \text{argmax}(\mathbf{y}_i) \quad (11.13)
$$

A fun√ß√£o de perda de entropia cruzada √© calculada para cada token, comparando a distribui√ß√£o de probabilidade prevista com o r√≥tulo verdadeiro [^1]. Os pesos $\mathbf{W}_K$ s√£o ent√£o atualizados por retropropaga√ß√£o para minimizar a perda global, que √© a m√©dia das perdas de cada token na sequ√™ncia.

> üí° **Exemplo Num√©rico (Rotula√ß√£o de Entidades Nomeadas - NER):**
>
> Considere um problema de rotula√ß√£o de entidades nomeadas (NER), com as etiquetas: "ORG" (organiza√ß√£o), "LOC" (localiza√ß√£o) e "O" (outros). Suponha que, para a frase "Apple is planning to open a new store in London.",  a representa√ß√£o do token "Apple" seja  $\mathbf{h}_{\text{Apple}} = [0.3, -0.1, 0.5, 0.2]$, e que a matriz de pesos do classificador $\mathbf{W}_K$ inicialmente seja:
> $$
> \mathbf{W}_K = \begin{bmatrix}
> 0.1 & -0.2 & 0.3 \\
> -0.3 & 0.4 & -0.1 \\
> 0.2 & -0.1 & 0.4 \\
> -0.1 & 0.3 & -0.2
> \end{bmatrix}
> $$
>
> Ent√£o, $\mathbf{h}_{\text{Apple}} \mathbf{W}_K$ √©:
>
> $$
> \begin{bmatrix} 0.3 & -0.1 & 0.5 & 0.2 \end{bmatrix} \begin{bmatrix} 0.1 & -0.2 & 0.3 \\ -0.3 & 0.4 & -0.1 \\ 0.2 & -0.1 & 0.4 \\ -0.1 & 0.3 & -0.2 \end{bmatrix} = \begin{bmatrix} 0.16 & -0.08 & 0.31 \end{bmatrix}
> $$
>
> Aplicando a fun√ß√£o softmax obtemos as probabilidades $\mathbf{y}_{\text{Apple}}$:
>
> $$
> \mathbf{y}_{\text{Apple}} = \text{softmax}([0.16, -0.08, 0.31]) \approx [0.36, 0.27, 0.37]
> $$
>
> Isso significa que o modelo inicialmente prev√™ o token "Apple" como tendo 36% de chance de ser "ORG", 27% de ser "LOC" e 37% de ser "O". O r√≥tulo verdadeiro para "Apple" √© "ORG", com vetor *one-hot* $[1, 0, 0]$.  A perda de entropia cruzada √© ent√£o:
>
> $$
> L_{\text{Apple}} = - (1 \cdot \log(0.36) + 0 \cdot \log(0.27) + 0 \cdot \log(0.37)) \approx 1.02
> $$
>
> O treinamento visa reduzir essa perda. Os pesos $\mathbf{W}_K$ s√£o ajustados pelo otimizador,  por retropropaga√ß√£o, para que a probabilidade prevista para "ORG" aumente e as outras diminuam. Ap√≥s uma atualiza√ß√£o,  $\mathbf{y}_{\text{Apple}}$ poderia se tornar, por exemplo,  $[0.89, 0.01, 0.10]$, o que reduz a perda.
>
> Esse processo √© repetido para cada token da frase, e os pesos $W_K$ s√£o ajustados a cada passo para diminuir a perda no conjunto de treinamento.
>

*Prova:*
I. Para cada token $i$ na sequ√™ncia de entrada, o modelo gera uma distribui√ß√£o de probabilidade $\mathbf{y}_i$ atrav√©s da aplica√ß√£o do classificador linear com pesos $W_K$ seguida da fun√ß√£o softmax [^1].
II. A perda de entropia cruzada para cada token, dada por
$$L_i = -\sum_j y_{true, i, j} \log(y_{i, j})$$,
√© calculada usando o r√≥tulo verdadeiro $y_{true, i}$ [^1].
III. O objetivo √© minimizar a perda m√©dia sobre todos os tokens da sequ√™ncia $L = \frac{1}{n} \sum_i L_i$ , onde $n$ √© o n√∫mero de tokens.
IV. Otimizadores como descida do gradiente calculam os gradientes da perda em rela√ß√£o aos pesos $W_K$ atrav√©s da retropropaga√ß√£o e atualizam os pesos para reduzir a perda.
V. Este processo √© repetido iterativamente at√© que a perda convirja, resultando em pesos $W_K$ que est√£o ajustados para rotular corretamente as sequ√™ncias de entrada. ‚ñ†

**Lema 3.1** Em problemas de rotula√ß√£o de sequ√™ncias, se a dimens√£o da sa√≠da $h_i$ do modelo pr√©-treinado para cada token √© $d$, ent√£o a matriz de pesos do classificador $\mathbf{W}_K$ ter√° dimens√£o $d \times K$, onde K √© o n√∫mero de etiquetas poss√≠veis.
*Prova:*
A sa√≠da $h_i$ do modelo para cada token tem dimens√£o $d$. O classificador linear $\mathbf{W}_K$ deve, ao multiplicar $h_i$, gerar um vetor de scores de dimens√£o $K$ (o n√∫mero de etiquetas). Portanto, $\mathbf{W}_K$ deve ter dimens√£o $d \times K$. ‚ñ†

### Conclus√£o
Este cap√≠tulo detalhou como o processo de *fine-tuning* utiliza dados rotulados para treinar os *heads* classificadores adicionados sobre modelos de linguagem pr√©-treinados, e como as sa√≠das dos transformadores bidirecionais s√£o utilizadas como entradas para esses classificadores [^1]. A fun√ß√£o de perda, geralmente a entropia cruzada, guia o processo de treinamento, e os par√¢metros do modelo, em particular as camadas de classifica√ß√£o, s√£o ajustados por retropropaga√ß√£o para minimizar a perda [^1]. O ajuste correto dos par√¢metros permite que modelos pr√©-treinados se adaptem a tarefas espec√≠ficas, mostrando a import√¢ncia da t√©cnica para aplica√ß√µes de processamento de linguagem natural. Al√©m disso,  o m√©todo de concatena√ß√£o apresentado para classifica√ß√£o de pares de sequ√™ncias (Proposi√ß√£o 1.1)  mostra como diferentes abordagens podem ser utilizadas para  melhor modelar cada tipo de problema [^1]. As provas e exemplos num√©ricos fornecem a intui√ß√£o necess√°ria para o entendimento deste processo.

**Teorema 1** (Converg√™ncia do Fine-Tuning): Sob certas condi√ß√µes de regularidade da fun√ß√£o de perda e da escolha adequada do otimizador, o processo de fine-tuning, usando descida do gradiente (ou variantes), converge para um m√≠nimo local da fun√ß√£o de perda.

*Prova:*
A prova deste teorema envolve argumentos de otimiza√ß√£o n√£o convexa e √© um resultado conhecido na literatura de aprendizado de m√°quina. A converg√™ncia √© geralmente garantida se:
(i) a fun√ß√£o de perda √© diferenci√°vel e limitada inferiormente;
(ii) a taxa de aprendizado do otimizador √© adequadamente ajustada (e.g., seguindo um esquema de decaimento);
(iii) o otimizador utilizado garante que o gradiente da fun√ß√£o de perda seja usado de maneira correta para a atualiza√ß√£o dos pesos do modelo.
Sob estas condi√ß√µes, a sequ√™ncia de pesos obtida pelo algoritmo de descida do gradiente converge para um ponto onde o gradiente da fun√ß√£o de perda √© zero ou pr√≥ximo de zero, que √© um m√≠nimo local.  √â importante notar que, em problemas n√£o convexos, como o treinamento de redes neurais, n√£o √© garantido que a converg√™ncia ser√° para um m√≠nimo global, mas, em geral, um m√≠nimo local √© suficiente para um bom desempenho do modelo. ‚ñ†

### Refer√™ncias
[^1]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ¬© 2024. All rights reserved. Draft of August 20, 2024.
<!-- END -->
