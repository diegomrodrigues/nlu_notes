## Fine-Tuning para Classifica√ß√£o: Camada de Sa√≠da e Otimiza√ß√£o da Entropia Cruzada

### Introdu√ß√£o
Este cap√≠tulo aprofunda o processo de *fine-tuning* para tarefas de classifica√ß√£o, focando especificamente na substitui√ß√£o da camada de sa√≠da do modelo de linguagem por um classificador e na otimiza√ß√£o da fun√ß√£o de perda de entropia cruzada. Este tema √© fundamental para adaptar modelos pr√©-treinados, como os discutidos nos cap√≠tulos anteriores, a tarefas espec√≠ficas de classifica√ß√£o. Exploraremos em detalhes como essa adapta√ß√£o √© realizada, utilizando as sa√≠das dos transformadores bidirecionais, e como a entropia cruzada √© utilizada para treinar esses classificadores [^1]. Expandindo os conceitos previamente introduzidos, analisaremos a arquitetura da camada de sa√≠da, o treinamento supervisionado e abordagens avan√ßadas de otimiza√ß√£o, com o objetivo de alcan√ßar desempenho √≥timo em tarefas de classifica√ß√£o de texto.

### Classificadores e Camada de Sa√≠da

Em tarefas de classifica√ß√£o, o objetivo principal √© mapear uma entrada (um texto, par de textos ou sequ√™ncia de tokens) para uma de v√°rias classes predefinidas [^1]. Para isso, a camada de sa√≠da do modelo de linguagem pr√©-treinado √© substitu√≠da por um classificador, tamb√©m chamado de *head* [^1]. Este classificador tem como fun√ß√£o mapear as representa√ß√µes geradas pelo modelo pr√©-treinado para um vetor de pontua√ß√µes, que representa a probabilidade de cada classe.

#### Arquitetura da Camada de Classifica√ß√£o
A arquitetura da camada de classifica√ß√£o varia dependendo do tipo de tarefa [^1]. Em geral, a camada de classifica√ß√£o consiste em:

1.  **Camada Linear:** Uma camada linear, que aplica uma transforma√ß√£o linear √† representa√ß√£o de entrada, utilizando uma matriz de pesos $\mathbf{W}$ e um vetor de bias $\mathbf{b}$. Esta camada transforma a representa√ß√£o de entrada, normalmente denotada por $\mathbf{h}$, para um espa√ßo onde as classes s√£o mais separ√°veis.
2.  **Fun√ß√£o de Ativa√ß√£o (Opcional):** Uma fun√ß√£o de ativa√ß√£o n√£o linear, como ReLU, pode ser aplicada ap√≥s a camada linear para aumentar a capacidade do modelo de modelar rela√ß√µes complexas entre as classes. A adi√ß√£o da camada n√£o linear √© opcional mas pode auxiliar na modelagem de problemas complexos, como foi visto no cap√≠tulo anterior.
3.  **Softmax:** Uma fun√ß√£o softmax, que transforma o vetor de pontua√ß√µes em uma distribui√ß√£o de probabilidade sobre as classes, normalizando os valores para que a soma das probabilidades seja igual a 1 [^1].

A dimens√£o da matriz $\mathbf{W}$ varia de acordo com a dimens√£o da representa√ß√£o de entrada e o n√∫mero de classes de sa√≠da, e a sua estrutura foi definida nos lemas apresentados nos cap√≠tulos anteriores, para cada tipo de tarefa de classifica√ß√£o (Lema 1.1, Lema 2.1, Lema 3.1).

**Proposi√ß√£o 1:** A aplica√ß√£o de m√∫ltiplas camadas lineares, intercaladas com fun√ß√µes de ativa√ß√£o n√£o lineares, pode aumentar a capacidade do classificador de modelar rela√ß√µes complexas entre as classes. Esta √© uma abordagem comum em classificadores mais profundos.
*Prova:*
I. Uma √∫nica camada linear, seguida por uma fun√ß√£o de ativa√ß√£o, pode modelar rela√ß√µes n√£o lineares entre as classes.
II. Ao empilhar m√∫ltiplas camadas lineares, cada uma seguida por uma fun√ß√£o de ativa√ß√£o, o classificador pode aprender hierarquias de representa√ß√µes e modelar rela√ß√µes mais complexas.
III. As fun√ß√µes de ativa√ß√£o introduzem n√£o linearidade, o que √© essencial para modelar dados complexos.
IV. A combina√ß√£o de m√∫ltiplas camadas e fun√ß√µes de ativa√ß√£o permite que o classificador se adapte a padr√µes de dados mais intrincados e, portanto, aumente a sua capacidade de classifica√ß√£o. ‚ñ†

#### Fun√ß√µes de Ativa√ß√£o
A escolha da fun√ß√£o de ativa√ß√£o √© importante para o desempenho do modelo. A fun√ß√£o ReLU, por exemplo, ajuda a introduzir n√£o linearidade ao modelo [^1]. Outras fun√ß√µes, como Sigmoid ou Tanh, podem ser usadas dependendo da tarefa e das caracter√≠sticas dos dados. A utiliza√ß√£o de camadas n√£o lineares ap√≥s a camada linear tem o objetivo de aprender rela√ß√µes mais complexas, como visto no Teorema 1.1 do cap√≠tulo anterior.

> üí° **Exemplo Num√©rico (Camada de Classifica√ß√£o):**
>
> Suponha que, em uma tarefa de classifica√ß√£o de sentimento, a representa√ß√£o de entrada $\mathbf{h}$ seja um vetor de dimens√£o 768, proveniente da sa√≠da do token `[CLS]` de um modelo BERT. A tarefa de classifica√ß√£o possui 3 classes: positivo, negativo e neutro.
>
> A camada de classifica√ß√£o linear possui uma matriz de pesos $\mathbf{W}$ de dimens√£o $768 \times 3$ e um vetor de bias $\mathbf{b}$ de dimens√£o 3. Ap√≥s o c√°lculo de $z = \mathbf{h}\mathbf{W} + \mathbf{b}$, podemos aplicar a fun√ß√£o ReLU $a = ReLU(z)$ (onde a ReLU zera os valores negativos e mant√©m os valores positivos) e a softmax para obter a distribui√ß√£o de probabilidade sobre as classes:
>
> $$
> \mathbf{y} = \text{softmax}(a)
> $$
>
> Onde $\mathbf{y}$ √© um vetor de dimens√£o 3, onde cada elemento representa a probabilidade de a entrada pertencer a cada classe. Por exemplo, se $\mathbf{y} = [0.8, 0.1, 0.1]$, a entrada seria classificada como "positivo".
>
>  Vamos supor valores num√©ricos para ilustrar o processo:
>
>   - $\mathbf{h} = [0.1, 0.2, ..., 0.768]$ (um vetor de 768 dimens√µes, apenas os dois primeiros elementos s√£o mostrados por brevidade).
>   - $\mathbf{W}$ √© uma matriz de $768 \times 3$, que inicializamos aleatoriamente com valores pequenos.
>   - $\mathbf{b} = [0.01, -0.02, 0.03]$ (vetor de bias de 3 dimens√µes).
>
>  Calculando $z = \mathbf{h}\mathbf{W} + \mathbf{b}$, obteremos um vetor de 3 dimens√µes. Vamos supor que $z = [-0.5, 1.2, 0.3]$. Aplicando a ReLU, obtemos $a = [0, 1.2, 0.3]$. Aplicando a fun√ß√£o softmax:
>
> $$
> y_i = \frac{e^{a_i}}{\sum_{j=1}^{3} e^{a_j}}
> $$
>
> $$
> y_1 = \frac{e^0}{e^0 + e^{1.2} + e^{0.3}} \approx \frac{1}{1 + 3.32 + 1.35} \approx 0.17 \\
> y_2 = \frac{e^{1.2}}{e^0 + e^{1.2} + e^{0.3}} \approx \frac{3.32}{1 + 3.32 + 1.35} \approx 0.58 \\
> y_3 = \frac{e^{0.3}}{e^0 + e^{1.2} + e^{0.3}} \approx \frac{1.35}{1 + 3.32 + 1.35} \approx 0.25
> $$
>
> Portanto,  $\mathbf{y} \approx [0.17, 0.58, 0.25]$. Este vetor representa a probabilidade de cada classe, e a classe com maior probabilidade (neste caso, a segunda classe com 0.58) √© a classe predita.

**Lema 1:** O n√∫mero de par√¢metros da camada linear na classifica√ß√£o √© dado por $(d \times K) + K$, onde $d$ √© a dimens√£o do vetor de entrada e $K$ √© o n√∫mero de classes, onde $d \times K$ representa os par√¢metros da matriz de peso e $K$ os par√¢metros do vetor de bias.
*Prova:*
I. A camada linear de um classificador utiliza uma matriz de peso $\mathbf{W}$ de dimens√£o $d \times K$, que cont√©m $d \times K$ par√¢metros.
II. A camada linear tamb√©m utiliza um vetor de bias $\mathbf{b}$ de dimens√£o $K$, que cont√©m $K$ par√¢metros.
III. O n√∫mero total de par√¢metros da camada linear, ent√£o, √© a soma dos par√¢metros da matriz e do vetor, que √© igual a $d \times K + K$. ‚ñ†

**Lema 1.1:** Se a camada de classifica√ß√£o for composta por duas camadas lineares, com dimens√µes intermedi√°rias $d_1$, $d_2$, e $K$ para a sa√≠da, o n√∫mero de par√¢metros da camada linear √© dado por $(d \times d_1) + d_1 + (d_1 \times d_2) + d_2 + (d_2 \times K) + K$.
*Prova:*
I. A primeira camada linear possui uma matriz de peso $\mathbf{W_1}$ de dimens√£o $d \times d_1$ e um bias $\mathbf{b_1}$ de dimens√£o $d_1$, totalizando $d \times d_1 + d_1$ par√¢metros.
II. A segunda camada linear possui uma matriz de peso $\mathbf{W_2}$ de dimens√£o $d_1 \times d_2$ e um bias $\mathbf{b_2}$ de dimens√£o $d_2$, totalizando $d_1 \times d_2 + d_2$ par√¢metros.
III. A terceira camada linear possui uma matriz de peso $\mathbf{W_3}$ de dimens√£o $d_2 \times K$ e um bias $\mathbf{b_3}$ de dimens√£o $K$, totalizando $d_2 \times K + K$ par√¢metros.
IV. O n√∫mero total de par√¢metros das camadas lineares √© a soma dos par√¢metros de cada camada, que √© igual a $(d \times d_1) + d_1 + (d_1 \times d_2) + d_2 + (d_2 \times K) + K$. ‚ñ†

### Otimiza√ß√£o da Entropia Cruzada

A fun√ß√£o de perda de **entropia cruzada (cross-entropy)** √© utilizada para treinar os par√¢metros do classificador, quantificando a diferen√ßa entre a distribui√ß√£o de probabilidade prevista e a distribui√ß√£o de probabilidade verdadeira (one-hot) correspondente ao r√≥tulo verdadeiro [^1]. O objetivo do treinamento √© minimizar essa diferen√ßa [^1].

#### Defini√ß√£o da Entropia Cruzada
A fun√ß√£o de perda de entropia cruzada para um exemplo de treinamento √© definida como:
$$
L = - \sum_{i=1}^{K} y_{true_i} \log(y_{pred_i})
$$
Onde:
*   $K$ √© o n√∫mero de classes.
*   $y_{true_i}$ √© a probabilidade do r√≥tulo verdadeiro para a classe $i$ (que √© 1 para a classe correta e 0 para as demais).
*   $y_{pred_i}$ √© a probabilidade prevista pelo modelo para a classe $i$.

A perda de entropia cruzada mede a diferen√ßa entre a distribui√ß√£o prevista e a verdadeira, e a retropropaga√ß√£o ajusta os par√¢metros do classificador (matriz de pesos $\mathbf{W}$ e vetor de bias $\mathbf{b}$) para que a perda diminua a cada itera√ß√£o. A perda √© calculada para todos os exemplos de treinamento, e o objetivo √© minimizar a perda m√©dia sobre o conjunto de treinamento.

#### Otimiza√ß√£o do Modelo

O processo de otimiza√ß√£o dos par√¢metros do classificador √© tipicamente realizado usando um otimizador baseado em descida do gradiente (gradient descent), como o Adam ou SGD [^1]. O otimizador usa o gradiente da fun√ß√£o de perda em rela√ß√£o aos par√¢metros do modelo para ajustar os par√¢metros na dire√ß√£o que minimiza a perda.

1.  **Propaga√ß√£o Direta (Forward Pass):** A entrada √© passada pelo modelo pr√©-treinado e pelo classificador, gerando o vetor de probabilidades $\mathbf{y}$.
2.  **C√°lculo da Perda:** A perda de entropia cruzada √© calculada usando $\mathbf{y}$ e o r√≥tulo verdadeiro.
3.  **Retropropaga√ß√£o (Backward Pass):** O gradiente da perda √© calculado em rela√ß√£o aos par√¢metros do classificador usando retropropaga√ß√£o.
4.  **Otimiza√ß√£o:** Os par√¢metros do classificador s√£o atualizados na dire√ß√£o oposta ao gradiente, usando o otimizador.

Esse processo √© repetido iterativamente para todos os exemplos do conjunto de treinamento, ajustando os par√¢metros para minimizar a perda m√©dia ao longo do tempo.

> üí° **Exemplo Num√©rico (Otimiza√ß√£o da Entropia Cruzada):**
>
> Suponha que a probabilidade prevista para uma entrada seja $\mathbf{y}_{pred} = [0.2, 0.7, 0.1]$, representando as probabilidades para tr√™s classes, e que o r√≥tulo verdadeiro seja a classe 2, representado pelo vetor *one-hot* $\mathbf{y}_{true} = [0, 1, 0]$.
>
> A perda de entropia cruzada √© calculada como:
>
> $$
> L = - (0 \cdot \log(0.2) + 1 \cdot \log(0.7) + 0 \cdot \log(0.1)) = -\log(0.7) \approx 0.356
> $$
>
> Ap√≥s calcular o gradiente da perda em rela√ß√£o aos par√¢metros do classificador (matriz de pesos $\mathbf{W}$ e vetor de bias $\mathbf{b}$), o otimizador utiliza esses gradientes para ajustar os par√¢metros na dire√ß√£o que diminui a perda. Por exemplo, se a taxa de aprendizado (learning rate) for 0.001, o otimizador ajustaria os pesos e o bias para que, no pr√≥ximo passo de treinamento, a probabilidade da classe 2 aumentasse, por exemplo, para 0.8, e as demais diminu√≠ssem, o que diminuiria a perda e aproximaria o modelo do resultado desejado.
>
> O otimizador Adam (e outros) utiliza um mecanismo adaptativo, que ajusta a taxa de aprendizado para cada par√¢metro individualmente durante o treinamento. A utiliza√ß√£o de *schedulers* para taxa de aprendizado ajuda a estabilizar o treinamento e evita que ele oscile, com uma taxa de aprendizado menor nos passos mais avan√ßados, como visto no Corol√°rio 1.1 do cap√≠tulo anterior.
>
> Vamos detalhar como a entropia cruzada funciona na pr√°tica, com um exemplo simplificado.
>
> | Passo |  Predi√ß√£o $\mathbf{y}_{pred}$  | R√≥tulo Verdadeiro $\mathbf{y}_{true}$ | Loss (entropia cruzada)  | Atualiza√ß√£o |
> |----------|-------------|--------------------|-----------------------|--------------|
> |  1 | \[0.2, 0.7, 0.1] | \[0, 1, 0]       | 0.356 | Ajuste de pesos e bias |
> |  2  | \[0.1, 0.8, 0.1] | \[0, 1, 0]  | 0.223 | Ajuste de pesos e bias|
> | 3  | \[0.05, 0.9, 0.05] | \[0, 1, 0] | 0.105 | Ajuste de pesos e bias|
>
>  A tabela mostra como a perda diminui a cada passo, com as probabilidades previstas se aproximando do r√≥tulo verdadeiro. A retropropaga√ß√£o e o otimizador ajustam os pesos do classificador para que as previs√µes se aproximem dos r√≥tulos.
>
> Vamos agora considerar um exemplo com valores espec√≠ficos para $\mathbf{y}_{pred}$ e $\mathbf{y}_{true}$ durante algumas itera√ß√µes, e calcular a perda para cada passo:
>
> **Itera√ß√£o 1:**
>
> - $\mathbf{y}_{pred} = [0.2, 0.3, 0.5]$ (Probabilidades previstas)
> - $\mathbf{y}_{true} = [0, 1, 0]$ (R√≥tulo verdadeiro: Classe 2)
> - $L = - (0 \cdot \log(0.2) + 1 \cdot \log(0.3) + 0 \cdot \log(0.5)) = - \log(0.3) \approx 1.204$
>
> **Itera√ß√£o 2 (Ap√≥s ajuste dos pesos):**
>
> - $\mathbf{y}_{pred} = [0.1, 0.6, 0.3]$
> - $\mathbf{y}_{true} = [0, 1, 0]$
> - $L = - (0 \cdot \log(0.1) + 1 \cdot \log(0.6) + 0 \cdot \log(0.3)) = - \log(0.6) \approx 0.511$
>
> **Itera√ß√£o 3 (Ap√≥s mais ajustes):**
>
> - $\mathbf{y}_{pred} = [0.05, 0.8, 0.15]$
> - $\mathbf{y}_{true} = [0, 1, 0]$
> - $L = - (0 \cdot \log(0.05) + 1 \cdot \log(0.8) + 0 \cdot \log(0.15)) = - \log(0.8) \approx 0.223$
>
> Podemos ver que a perda diminui a cada itera√ß√£o, √† medida que as probabilidades previstas se aproximam do r√≥tulo verdadeiro.

**Teorema 1:** A otimiza√ß√£o da fun√ß√£o de perda de entropia cruzada, quando utilizada com um algoritmo de descida do gradiente e dados de treinamento suficientes, permite que o classificador aprenda a classificar as entradas corretamente, mapeando as representa√ß√µes do modelo pr√©-treinado para as classes correspondentes.
*Prova:*
I. A fun√ß√£o de perda de entropia cruzada quantifica a discrep√¢ncia entre a distribui√ß√£o de probabilidade prevista e a distribui√ß√£o de probabilidade verdadeira (one-hot).
II. O otimizador ajusta os par√¢metros do classificador na dire√ß√£o que diminui a perda, aumentando a probabilidade da classe correta e diminuindo as probabilidades das classes incorretas.
III.  Com dados de treinamento suficientes e um n√∫mero adequado de itera√ß√µes, o modelo converge para uma solu√ß√£o onde a perda √© minimizada.
IV.  Nesta solu√ß√£o, o classificador mapeia as entradas para classes corretas, atingindo o objetivo do *fine-tuning*. Portanto, a minimiza√ß√£o da entropia cruzada leva a um classificador mais eficiente. ‚ñ†

**Corol√°rio 1.1:**  Em problemas de classifica√ß√£o com um n√∫mero muito grande de classes, a entropia cruzada pode se tornar computacionalmente cara. A utiliza√ß√£o de *hierarchical softmax* ou *negative sampling* pode otimizar o c√°lculo da perda, permitindo o treinamento em cen√°rios de alta dimensionalidade.
*Prova:*
I. Em classifica√ß√µes com um grande n√∫mero de classes, o c√°lculo da soma na entropia cruzada torna-se computacionalmente caro, pois envolve a avalia√ß√£o de probabilidades para todas as classes.
II. *Hierarchical softmax* organiza as classes em uma estrutura hier√°rquica (como uma √°rvore), transformando o problema de classificar em $K$ classes para classificar em sucessivas √°rvores bin√°rias, diminuindo a complexidade computacional.
III. *Negative sampling* aproxima a entropia cruzada, treinando o modelo para distinguir apenas entre o r√≥tulo correto e um conjunto de r√≥tulos aleat√≥rios (negativos), em vez de todas as classes.
IV. Estas t√©cnicas reduzem a complexidade computacional sem comprometer significativamente a qualidade do modelo, tornando o treinamento mais eficiente em problemas de classifica√ß√£o com muitas classes. Portanto, a utiliza√ß√£o destas t√©cnicas otimiza o c√°lculo da perda em problemas de alta dimensionalidade. ‚ñ†

### Abordagens Avan√ßadas de Otimiza√ß√£o

Al√©m do processo b√°sico de otimiza√ß√£o da entropia cruzada, v√°rias t√©cnicas podem melhorar o desempenho do modelo e a estabilidade do treinamento:

#### Regulariza√ß√£o
T√©cnicas de regulariza√ß√£o, como *dropout*, *weight decay* e *early stopping*, s√£o essenciais para evitar o *overfitting* e aumentar a capacidade de generaliza√ß√£o do modelo, como vimos nos cap√≠tulos anteriores [^1]. *Dropout* desativa aleatoriamente neur√¥nios durante o treinamento, *weight decay* adiciona uma penalidade aos pesos grandes e *early stopping* interrompe o treinamento quando o desempenho no conjunto de valida√ß√£o come√ßa a piorar.

#### Otimizadores Adaptativos
Otimizadores adaptativos, como o Adam e o AdaGrad, ajustam a taxa de aprendizado de cada par√¢metro individualmente durante o treinamento, o que pode acelerar a converg√™ncia e melhorar o desempenho [^1]. Otimizadores adaptativos levam em conta o hist√≥rico dos gradientes, permitindo ajustar a taxa de aprendizado de forma mais inteligente do que otimizadores de taxa fixa.

#### Schedulers de Taxa de Aprendizado
*Schedulers* de taxa de aprendizado ajustam dinamicamente a taxa de aprendizado ao longo do treinamento, como *warmup*, que aumenta a taxa de aprendizado no in√≠cio, e *decay*, que a diminui ao longo do tempo, auxiliando no processo de converg√™ncia, como visto no Corol√°rio 1.1 e 1.2 do cap√≠tulo anterior [^1].

#### Fine-Tuning Multi-Task
A abordagem de *fine-tuning* multi-tarefa, como discutido anteriormente, pode ser utilizada para que o modelo generalize melhor em diversas tarefas e obtenha representa√ß√µes mais robustas, com a combina√ß√£o das perdas individuais de cada tarefa [^1].

> üí° **Exemplo Num√©rico (Regulariza√ß√£o):**
>
> Vamos detalhar como o dropout afeta os c√°lculos na camada de classifica√ß√£o, usando o exemplo num√©rico anterior.
>
> Ap√≥s o modelo pr√©-treinado gerar a representa√ß√£o $\mathbf{h}$, aplicamos uma camada de dropout, que desativa aleatoriamente um n√∫mero de elementos de $\mathbf{h}$, por exemplo, 20%.
>
> Suponha que o vetor $\mathbf{h} = [0.1, 0.2, 0.3, 0.4, 0.5, \ldots, 0.768]$, de dimens√£o 768. Aplicando dropout, poder√≠amos ter:
>
> $\mathbf{h}^{dropout} = [0, 0.2, 0, 0.4, 0, \ldots, 0.768]$.
>
> Note que os elementos 1, 3 e 5 foram zerados. O restante do processo segue igual, com a matriz de pesos $\mathbf{W}$ mapeando $\mathbf{h}^{dropout}$ para a distribui√ß√£o de probabilidade final. O dropout tem o efeito de regularizar o modelo, for√ßando-o a aprender representa√ß√µes mais robustas.
>
>  Em rela√ß√£o ao weight decay, suponha que a perda sem regulariza√ß√£o seja:
>
> $$
> Loss = -\sum_{i=1}^{K} y_{true_i} \log(y_{pred_i})
> $$
>
> Com o weight decay, uma penalidade √© adicionada √† perda:
>
> $$
> Loss_{decay} = Loss + \lambda \sum_w ||w||^2
> $$
>
> Onde $\lambda$ √© o fator de weight decay, e a soma √© sobre todos os pesos do modelo. A penalidade for√ßa os pesos a serem menores.
>
> Por exemplo, suponha que $\lambda = 0.01$ e $\sum_w ||w||^2 = 100$, ent√£o $Loss_{decay} = Loss + 0.01 * 100 = Loss + 1$. Essa penalidade √© adicionada √† perda original para que o modelo tenda a gerar pesos menores, generalizando melhor.
>
> Na pr√°tica, esses c√°lculos s√£o computados de forma eficiente por frameworks de *deep learning*. Este exemplo tem como objetivo ilustrar como o dropout e o *weight decay* atuam no modelo.
>
> Vamos agora analisar um exemplo num√©rico da aplica√ß√£o de *early stopping*. Suponha que temos um conjunto de valida√ß√£o e observamos a perda durante o treinamento:
>
> | √âpoca | Perda no Conjunto de Valida√ß√£o |
> |-------|-----------------------------|
> | 1     | 0.85                        |
> | 2     | 0.72                        |
> | 3     | 0.65                        |
> | 4     | 0.58                        |
> | 5     | 0.55                        |
> | 6     | 0.53                        |
> | 7     | 0.52                        |
> | 8     | 0.53                        |
> | 9     | 0.55                        |
>
> Observamos que a perda no conjunto de valida√ß√£o diminui at√© a √©poca 7 e come√ßa a aumentar a partir da √©poca 8. O *early stopping* interromperia o treinamento na √©poca 7, pois a partir desse ponto o modelo come√ßaria a se ajustar demais aos dados de treinamento (overfitting).

**Teorema 1.1:** A combina√ß√£o de t√©cnicas de regulariza√ß√£o, otimizadores adaptativos e *schedulers* de taxa de aprendizado pode levar a uma melhor converg√™ncia e a um melhor desempenho dos modelos de classifica√ß√£o, especialmente quando utilizados em conjunto.
*Prova:*
I. As t√©cnicas de regulariza√ß√£o, como *dropout* e *weight decay*, previnem o *overfitting* e ajudam o modelo a generalizar melhor, como vimos anteriormente.
II. Otimizadores adaptativos, como Adam, ajustam a taxa de aprendizado para cada par√¢metro individualmente, o que leva a uma converg√™ncia mais r√°pida e eficiente.
III. Os *schedulers* de taxa de aprendizado ajustam a taxa de aprendizado durante o treinamento, melhorando a estabilidade e a precis√£o do aprendizado.
IV. A combina√ß√£o dessas abordagens permite explorar o espa√ßo de par√¢metros de forma mais eficiente e aprender modelos que generalizam melhor para dados n√£o vistos. Portanto, a combina√ß√£o de diferentes abordagens leva a modelos mais robustos. ‚ñ†

**Lema 1.2:** O uso de *batch normalization* ap√≥s as camadas lineares pode acelerar o treinamento, normalizando as ativa√ß√µes e reduzindo a depend√™ncia da inicializa√ß√£o dos par√¢metros.
*Prova:*
I. A *batch normalization* normaliza as ativa√ß√µes de cada camada em um *batch* de dados, garantindo que as ativa√ß√µes tenham m√©dia pr√≥xima de zero e desvio padr√£o pr√≥ximo de um.
II. Esta normaliza√ß√£o reduz o problema de *covariate shift*, onde a distribui√ß√£o das ativa√ß√µes muda durante o treinamento, dificultando a converg√™ncia.
III. Ao estabilizar as ativa√ß√µes, a *batch normalization* permite que o modelo use taxas de aprendizado maiores, acelerando a converg√™ncia.
IV. A *batch normalization* reduz a depend√™ncia da inicializa√ß√£o dos par√¢metros, tornando o treinamento mais robusto. Portanto, a utiliza√ß√£o da *batch normalization* melhora a velocidade e estabilidade do treinamento. ‚ñ†

### Conclus√£o
Este cap√≠tulo detalhou o processo de *fine-tuning* para tarefas de classifica√ß√£o, focando na substitui√ß√£o da camada de sa√≠da do modelo de linguagem por um classificador e na otimiza√ß√£o da fun√ß√£o de perda de entropia cruzada [^1]. Vimos como o classificador transforma a representa√ß√£o do modelo pr√©-treinado em um vetor de probabilidades sobre as classes alvo e como a fun√ß√£o de entropia cruzada guia o processo de treinamento [^1]. As abordagens de otimiza√ß√£o, juntamente com t√©cnicas de regulariza√ß√£o e otimizadores adaptativos, ajudam a melhorar a estabilidade e o desempenho do treinamento. Compreender esses conceitos e t√©cnicas √© fundamental para o desenvolvimento de modelos de classifica√ß√£o de alto desempenho, adaptados para tarefas espec√≠ficas de processamento de linguagem natural. As provas, lemas, e exemplos num√©ricos servem para elucidar o processo de *fine-tuning* para tarefas de classifica√ß√£o.

### Refer√™ncias
[^1]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ¬© 2024. All rights reserved. Draft of August 20, 2024.
<!-- END -->
