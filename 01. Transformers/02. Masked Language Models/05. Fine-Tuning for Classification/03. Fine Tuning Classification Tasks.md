## Fine-Tuning para ClassificaÃ§Ã£o: Tipos de Tarefas e Abordagens EspecÃ­ficas

### IntroduÃ§Ã£o
Como vimos nos capÃ­tulos anteriores, o *fine-tuning* Ã© um processo essencial para adaptar modelos de linguagem prÃ©-treinados a tarefas especÃ­ficas, e como o processo de treinamento se utiliza das saÃ­das dos transformadores bidirecionais [^1]. Nesta seÃ§Ã£o, aprofundaremos a discussÃ£o explorando os tipos de tarefas de classificaÃ§Ã£o para *fine-tuning*, que incluem a classificaÃ§Ã£o de sequÃªncias, a classificaÃ§Ã£o de pares de sequÃªncias e a rotulaÃ§Ã£o de sequÃªncias [^1]. Cada tipo de tarefa demanda uma abordagem especÃ­fica de *fine-tuning*, embora a lÃ³gica geral do processo seja similar. Analisaremos detalhadamente como a arquitetura e os parÃ¢metros sÃ£o adaptados para cada cenÃ¡rio, oferecendo exemplos prÃ¡ticos e provas que sustentam a compreensÃ£o dos conceitos [^1].

### ClassificaÃ§Ã£o de SequÃªncias: AdaptaÃ§Ãµes e Especificidades

A **classificaÃ§Ã£o de sequÃªncias** Ã© uma tarefa fundamental em NLP que envolve a atribuiÃ§Ã£o de um Ãºnico rÃ³tulo a um texto completo [^1]. Exemplos comuns incluem anÃ¡lise de sentimento, detecÃ§Ã£o de spam e classificaÃ§Ã£o de tÃ³picos de documentos [^1]. No processo de *fine-tuning* para essa tarefa, um *classifier head* Ã© adicionado sobre a saÃ­da do modelo prÃ©-treinado. O token especial `[CLS]` desempenha um papel crucial na representaÃ§Ã£o de toda a sequÃªncia, como visto nas seÃ§Ãµes anteriores [^1].

#### AdaptaÃ§Ã£o da Arquitetura
A arquitetura para classificaÃ§Ã£o de sequÃªncias Ã© ajustada para que o vetor de saÃ­da correspondente ao token `[CLS]`, $h_{CLS}$, seja usado como representaÃ§Ã£o da sequÃªncia [^1]. Esse vetor Ã© entÃ£o passado para um classificador, como uma regressÃ£o logÃ­stica ou uma rede neural, cuja funÃ§Ã£o Ã© mapear a representaÃ§Ã£o da sequÃªncia para um conjunto de pontuaÃ§Ãµes sobre as possÃ­veis classes. A equaÃ§Ã£o (11.11), como jÃ¡ visto anteriormente, formaliza este processo [^1]:
$$
\mathbf{y} = \text{softmax}(\mathbf{h}_{CLS}\mathbf{W}_C) \quad (11.11)
$$

Durante o *fine-tuning*, a matriz de pesos $\mathbf{W}_C$ Ã© treinada usando dados rotulados [^1]. A retropropagaÃ§Ã£o ajusta os pesos para minimizar a perda de entropia cruzada entre a distribuiÃ§Ã£o de probabilidade prevista $\mathbf{y}$ e o rÃ³tulo verdadeiro.

#### Especificidades do Fine-Tuning
Uma especificidade notÃ¡vel do *fine-tuning* para classificaÃ§Ã£o de sequÃªncias Ã© que apenas o vetor $h_{CLS}$ Ã© usado para a classificaÃ§Ã£o, enquanto as demais saÃ­das do modelo prÃ©-treinado sÃ£o ignoradas diretamente pelo *classifier head*, embora estas saÃ­das tenham influÃªncia no resultado via os mecanismos de *self-attention* [^1]. Isso faz com que o modelo aprenda a codificar informaÃ§Ãµes relevantes de toda a sequÃªncia no vetor $h_{CLS}$ para realizar a tarefa de classificaÃ§Ã£o.

> ğŸ’¡ **Exemplo NumÃ©rico (ClassificaÃ§Ã£o de Sentimento):**
>
> Suponha que temos um modelo prÃ©-treinado e queremos realizar a classificaÃ§Ã£o de sentimento em um texto. O texto de entrada Ã© "Este filme Ã© incrÃ­vel!". ApÃ³s tokenizaÃ§Ã£o e passagem pelo modelo, obtemos um vetor $h_{CLS}$ de dimensÃ£o, por exemplo, 768. A matriz de pesos $\mathbf{W}_C$ terÃ¡ a dimensÃ£o $768 \times 2$, considerando duas classes de saÃ­da: positivo e negativo.
>
> Seja $h_{CLS} = [0.1, -0.2, 0.5, \ldots, 0.3]$ e a matriz $\mathbf{W}_C$ inicializada aleatoriamente. O resultado da operaÃ§Ã£o $\mathbf{h}_{CLS}\mathbf{W}_C$ serÃ¡ um vetor de dimensÃ£o 2.
>
> Digamos que apÃ³s o cÃ¡lculo de $\mathbf{h}_{CLS}\mathbf{W}_C$ obtemos o vetor $[2.5, -1.2]$. Aplicamos a funÃ§Ã£o softmax para obter uma distribuiÃ§Ã£o de probabilidade:
>
> $\mathbf{y} = \text{softmax}([2.5, -1.2]) \approx [0.97, 0.03]$
>
> A probabilidade de a frase ser classificada como positiva Ã© 0.97 e como negativa Ã© 0.03. Durante o treinamento, a matriz $\mathbf{W}_C$ Ã© ajustada por retropropagaÃ§Ã£o para que a probabilidade da classe correta aumente.

**ObservaÃ§Ã£o 1:** Ã‰ crucial observar que a escolha do otimizador, como Adam, e a taxa de aprendizado sÃ£o parÃ¢metros cruciais que afetam a convergÃªncia e o desempenho do modelo. Uma taxa de aprendizado muito alta pode levar a instabilidade e *overshooting*, enquanto uma taxa muito baixa pode tornar o treinamento muito lento. AlÃ©m disso, mÃ©todos de regularizaÃ§Ã£o, como *dropout* e *weight decay*, sÃ£o frequentemente usados para evitar *overfitting*, especialmente quando o nÃºmero de parÃ¢metros a serem treinados Ã© grande.

**Teorema 1:** A utilizaÃ§Ã£o de uma camada *dropout* apÃ³s a representaÃ§Ã£o $h_{CLS}$ e antes da multiplicaÃ§Ã£o pela matriz $\mathbf{W}_C$ na classificaÃ§Ã£o de sequÃªncias pode melhorar a generalizaÃ§Ã£o do modelo, reduzindo o *overfitting*.

*Prova:*
I. A camada *dropout* desativa aleatoriamente uma proporÃ§Ã£o dos neurÃ´nios durante o treinamento [^1].
II. Essa desativaÃ§Ã£o forÃ§ada impede que o modelo se torne excessivamente dependente de determinados neurÃ´nios ou caracterÃ­sticas.
III. A aplicaÃ§Ã£o do *dropout* apÃ³s a representaÃ§Ã£o $h_{CLS}$ impede que o modelo memorize os padrÃµes exatos dos dados de treinamento.
IV. Isso forÃ§a o modelo a aprender representaÃ§Ãµes mais robustas e generalizÃ¡veis, levando a um melhor desempenho em dados nÃ£o vistos.
V. Portanto, a adiÃ§Ã£o de uma camada *dropout* ajuda a regularizar o modelo, melhorando sua capacidade de generalizaÃ§Ã£o. â– 

> ğŸ’¡ **Exemplo NumÃ©rico (Dropout):**
>
> Continuando o exemplo anterior, antes de realizar a multiplicaÃ§Ã£o por $\mathbf{W}_C$, aplicamos uma camada dropout com probabilidade 0.2, por exemplo. Isto significa que 20% dos elementos do vetor $h_{CLS}$ sÃ£o zerados aleatoriamente a cada iteraÃ§Ã£o durante o treinamento.
>
> Se $h_{CLS} = [0.1, -0.2, 0.5, \ldots, 0.3]$, apÃ³s o dropout poderÃ­amos ter, por exemplo, $h_{CLS}^{dropout} = [0, -0.2, 0, \ldots, 0.3]$, com os valores 0 representando os neurÃ´nios desativados. O modelo, entÃ£o, irÃ¡ aprender a classificar a sequÃªncia com essa representaÃ§Ã£o parcialmente zerada, forÃ§ando-o a nÃ£o depender de neurÃ´nios especÃ­ficos, generalizando mais.

### ClassificaÃ§Ã£o de Pares de SequÃªncias: Concatenando RepresentaÃ§Ãµes

A **classificaÃ§Ã£o de pares de sequÃªncias** envolve a classificaÃ§Ã£o da relaÃ§Ã£o semÃ¢ntica entre dois segmentos de texto [^1]. Tarefas comuns incluem detecÃ§Ã£o de parÃ¡frases, reconhecimento de inferÃªncia textual (NLI) e determinaÃ§Ã£o da coerÃªncia discursiva [^1]. Para realizar o *fine-tuning* para essa tarefa, uma abordagem comum Ã© concatenar as representaÃ§Ãµes do token `[CLS]` de cada sequÃªncia e passar o resultado para um classificador [^1].

#### AdaptaÃ§Ã£o da Arquitetura
Como vimos na ProposiÃ§Ã£o 1.1 do capÃ­tulo anterior,  a arquitetura para classificaÃ§Ã£o de pares de sequÃªncias Ã© adaptada concatenando os vetores de saÃ­da $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$  correspondentes ao token `[CLS]` de cada sequÃªncia [^1]:
$$
h_{pair} = \text{concat}(h_{CLS}^{(1)}, h_{CLS}^{(2)})
$$
Em seguida, um *classifier head* linear Ã© adicionado sobre $h_{pair}$, mapeando a representaÃ§Ã£o concatenada para um vetor de pontuaÃ§Ãµes sobre as classes. A saÃ­da do classificador Ã© dada por:
$$
\mathbf{y} = \text{softmax}(h_{pair} \mathbf{W}_P)
$$

Durante o *fine-tuning*, a matriz de pesos $\mathbf{W}_P$ Ã© treinada usando pares de sequÃªncias rotuladas, e o objetivo Ã© minimizar a perda de entropia cruzada entre a distribuiÃ§Ã£o de probabilidade prevista $\mathbf{y}$ e o rÃ³tulo verdadeiro [^1].

#### Especificidades do Fine-Tuning
Uma especificidade da classificaÃ§Ã£o de pares de sequÃªncias Ã© a necessidade de modelar a relaÃ§Ã£o entre as duas sequÃªncias de entrada, ao invÃ©s de tratar cada uma de forma independente [^1]. A concatenaÃ§Ã£o dos embeddings `[CLS]` permite que o classificador capture informaÃ§Ãµes conjuntas das duas sequÃªncias. Entretanto, outras abordagens podem ser utilizadas para melhor capturar a relaÃ§Ã£o entre as sentenÃ§as.

> ğŸ’¡ **Exemplo NumÃ©rico (NLI):**
>
> Considere as sentenÃ§as "Um gato estÃ¡ dormindo no tapete." e "HÃ¡ um felino descansando no tapete.". O modelo prÃ©-treinado gera os vetores $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$, ambos de dimensÃ£o 768. ApÃ³s a concatenaÃ§Ã£o, $h_{pair}$ terÃ¡ dimensÃ£o 1536. A matriz $\mathbf{W}_P$ terÃ¡ a dimensÃ£o $1536 \times 3$, considerando trÃªs classes de saÃ­da: *entailment*, *contradiction* e *neutral*.
>
>  Digamos que $h_{pair}$ = $[0.2, -0.1, 0.4, \ldots, 0.3]$. O resultado da operaÃ§Ã£o  $h_{pair} \mathbf{W}_P$ Ã© um vetor de tamanho 3, por exemplo, $[2.1, -0.8, 0.3]$. A funÃ§Ã£o softmax gera uma distribuiÃ§Ã£o de probabilidade:
>
>  $\mathbf{y} = \text{softmax}([2.1, -0.8, 0.3]) \approx [0.8, 0.1, 0.1]$.
>
>  A probabilidade de *entailment* Ã© 0.8, *contradiction* Ã© 0.1 e *neutral* Ã© 0.1. O modelo, durante o treinamento, ajustarÃ¡ os pesos da matriz $\mathbf{W}_P$ para aumentar a probabilidade da classe correta, neste caso, *entailment*.

**Lema 1.2:** MÃ©todos alternativos para representar pares de sequÃªncias podem envolver a utilizaÃ§Ã£o da diferenÃ§a ou da multiplicaÃ§Ã£o ponto a ponto dos vetores $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$, ou a adiÃ§Ã£o de uma camada de *attention* sobre a concatenaÃ§Ã£o para permitir que o modelo aprenda quais partes de cada vetor sÃ£o mais importantes para a classificaÃ§Ã£o.

*Prova:*
I. A concatenaÃ§Ã£o, embora eficaz, nÃ£o Ã© a Ãºnica forma de combinar as informaÃ§Ãµes de duas sequÃªncias.
II. A diferenÃ§a dos vetores $h_{CLS}^{(1)} - h_{CLS}^{(2)}$ captura as relaÃ§Ãµes diferenciais entre as duas sequÃªncias, que podem ser relevantes para a tarefa.
III. A multiplicaÃ§Ã£o ponto a ponto $h_{CLS}^{(1)} \odot h_{CLS}^{(2)}$ pode dar Ãªnfase a caracterÃ­sticas comuns Ã s duas sequÃªncias.
IV. A adiÃ§Ã£o de uma camada de atenÃ§Ã£o sobre a concatenaÃ§Ã£o permite que o modelo determine quais partes de cada sequÃªncia sÃ£o mais relevantes para a classificaÃ§Ã£o.
V. Cada uma dessas abordagens representa uma forma alternativa de modelar a relaÃ§Ã£o entre as sequÃªncias. Portanto, todas elas sÃ£o alternativas vÃ¡lidas. â– 

> ğŸ’¡ **Exemplo NumÃ©rico (DiferenÃ§a):**
>
> Usando o mesmo exemplo NLI, podemos calcular a diferenÃ§a dos vetores: $h_{diff} = h_{CLS}^{(1)} - h_{CLS}^{(2)}$.  Assumindo que  $h_{CLS}^{(1)} = [0.1, 0.2, 0.3, \ldots, 0.4]$ e $h_{CLS}^{(2)} = [0.2, 0.1, 0.2, \ldots, 0.5]$, entÃ£o $h_{diff} = [-0.1, 0.1, 0.1, \ldots, -0.1]$. Este vetor de diferenÃ§a $h_{diff}$ pode ser usado para classificar a relaÃ§Ã£o entre as sentenÃ§as. O classificador usaria uma matriz $\mathbf{W}_{diff}$ para mapear $h_{diff}$ para as classes.
>
> Similarmente, a multiplicaÃ§Ã£o ponto a ponto seria $h_{mult} = h_{CLS}^{(1)} \odot h_{CLS}^{(2)}$, resultando em um vetor onde cada elemento Ã© a multiplicaÃ§Ã£o dos elementos correspondentes em $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$.

**Teorema 1.1:** A inclusÃ£o de uma camada nÃ£o-linear, como uma camada ReLU, entre a concatenaÃ§Ã£o $h_{pair}$ e a matriz de pesos $\mathbf{W}_P$ pode melhorar a capacidade do modelo de aprender relaÃ§Ãµes complexas entre os pares de sequÃªncias.

*Prova:*
I. A concatenaÃ§Ã£o $h_{pair}$ cria uma representaÃ§Ã£o linear da relaÃ§Ã£o entre as duas sequÃªncias.
II. Uma camada nÃ£o-linear, como a ReLU, adiciona complexidade Ã  representaÃ§Ã£o, permitindo ao modelo aprender relaÃ§Ãµes mais abstratas.
III. Sem uma camada nÃ£o-linear, o modelo estaria limitado a aprender apenas relaÃ§Ãµes lineares, o que pode nÃ£o ser suficiente para tarefas complexas.
IV. Portanto, a adiÃ§Ã£o de uma camada nÃ£o-linear aumenta a capacidade do modelo de representar relaÃ§Ãµes mais intrincadas, o que pode melhorar o desempenho em tarefas de classificaÃ§Ã£o de pares de sequÃªncias. â– 

> ğŸ’¡ **Exemplo NumÃ©rico (ReLU):**
>
> ApÃ³s concatenar os vetores $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$ e obter $h_{pair}$, aplicamos uma camada ReLU, que zera os valores negativos do vetor. Por exemplo, se $h_{pair}$ = $[0.2, -0.1, 0.4, \ldots, -0.3]$, entÃ£o apÃ³s a ReLU teremos $h_{pair}^{ReLU}$ = $[0.2, 0, 0.4, \ldots, 0]$. Este vetor $h_{pair}^{ReLU}$ Ã© entÃ£o usado para a classificaÃ§Ã£o. A ReLU introduz nÃ£o-linearidade, permitindo que o modelo aprenda relaÃ§Ãµes mais complexas entre as sequÃªncias.

### RotulaÃ§Ã£o de SequÃªncias: Classificando Tokens Individuais

A **rotulaÃ§Ã£o de sequÃªncias**, tambÃ©m conhecida como classificaÃ§Ã£o *token-level*, envolve a atribuiÃ§Ã£o de um rÃ³tulo a cada token em uma sequÃªncia de texto [^1]. Uma tarefa comum nessa categoria Ã© o **reconhecimento de entidades nomeadas (NER)**, que identifica e classifica entidades como pessoas, organizaÃ§Ãµes e locais em um texto [^1]. O *fine-tuning* para rotulaÃ§Ã£o de sequÃªncias requer um classificador que processe cada token independentemente.

#### AdaptaÃ§Ã£o da Arquitetura

Nesse caso, a arquitetura do *fine-tuning* Ã© adaptada para que cada vetor de saÃ­da $h_i$ do modelo prÃ©-treinado, correspondente a cada token $i$, seja passado para um classificador individual [^1]. Este classificador gera uma distribuiÃ§Ã£o de probabilidade sobre o conjunto de etiquetas possÃ­veis para aquele token, como definido nas equaÃ§Ãµes (11.12) e (11.13):
$$
\mathbf{y}_i = \text{softmax}(\mathbf{h}_i\mathbf{W}_K) \quad (11.12)
$$
$$
t_i = \text{argmax}(\mathbf{y}_i) \quad (11.13)
$$

Durante o *fine-tuning*, a matriz de pesos $\mathbf{W}_K$ Ã© treinada com dados de sequÃªncia rotulados, e o objetivo Ã© minimizar a perda de entropia cruzada mÃ©dia sobre todos os tokens da sequÃªncia. Em algumas abordagens, uma camada de *Conditional Random Field* (CRF) pode ser adicionada apÃ³s a softmax para modelar transiÃ§Ãµes entre as etiquetas [^1], como serÃ¡ discutido no capÃ­tulo 17.

#### Especificidades do Fine-Tuning
Uma especificidade notÃ¡vel da rotulaÃ§Ã£o de sequÃªncias Ã© que a classificaÃ§Ã£o Ã© realizada em cada token individualmente [^1]. A retropropagaÃ§Ã£o Ã© utilizada para ajustar os pesos $\mathbf{W}_K$ com base na perda calculada para cada token. AlÃ©m disso, abordagens como o uso de CRF ajudam a modelar dependÃªncias entre as etiquetas, melhorando a qualidade dos resultados [^1].

> ğŸ’¡ **Exemplo NumÃ©rico (NER):**
>
> Considere a frase "Elon Musk trabalha na Tesla.". ApÃ³s a tokenizaÃ§Ã£o, o modelo gera os vetores $h_i$ para cada token. Assumindo que temos 3 rÃ³tulos: *PER* (pessoa), *ORG* (organizaÃ§Ã£o) e *O* (outro). Para cada token, a matriz $\mathbf{W}_K$ realiza a operaÃ§Ã£o $\mathbf{h}_i\mathbf{W}_K$ mapeando $h_i$ para um vetor de tamanho 3, por exemplo.
>
> Para o token "Elon", suponha que $\mathbf{h}_{\text{Elon}} \mathbf{W}_K = [2.0, -0.5, 0.1]$, e apÃ³s a softmax $\mathbf{y}_{\text{Elon}} = [0.9, 0.05, 0.05]$. Assim, "Elon" seria classificado como *PER*. Para o token "Tesla", suponha que $\mathbf{h}_{\text{Tesla}} \mathbf{W}_K = [-0.2, 1.8, 0.1]$, resultando em $\mathbf{y}_{\text{Tesla}} = [0.05, 0.9, 0.05]$. "Tesla" seria classificado como *ORG*.
>
> A saÃ­da final seria: "Elon"*PER* "Musk"*PER* "trabalha"*O* "na"*O* "Tesla"*ORG* ".". *O*. A matriz $\mathbf{W}_K$ Ã© treinada de forma que cada token seja classificado corretamente de acordo com seu rÃ³tulo.

> ğŸ’¡ **Exemplo NumÃ©rico (NER com CRF):**
>
> Considere uma sequÃªncia de texto com os tokens  `[â€œAppleâ€, â€œisâ€, â€œplanningâ€, â€œtoâ€, â€œopenâ€, â€œaâ€, â€œnewâ€, â€œstoreâ€, â€œinâ€, â€œLondonâ€]` e seus respectivos embeddings $h_i$. ApÃ³s a aplicaÃ§Ã£o da equaÃ§Ã£o (11.12), obtemos probabilidades para as etiquetas *ORG*, *LOC*, *O* para cada token, representadas por  $\mathbf{y}_i$. Suponha que para os tokens "Apple" e "London" tenhamos:
>
> $$
> \mathbf{y}_{\text{Apple}} = [0.89, 0.01, 0.10]
> $$
> $$
> \mathbf{y}_{\text{London}} = [0.05, 0.94, 0.01]
> $$
>
> Usando argmax (equaÃ§Ã£o 11.13), sem considerar o CRF, "Apple" seria rotulado como *ORG* e "London" como *LOC*.
>
> Ao adicionar uma camada CRF, o modelo considera as transiÃ§Ãµes entre as etiquetas. Por exemplo, a transiÃ§Ã£o de *ORG* para *LOC* Ã© menos provÃ¡vel do que de *ORG* para *O* ou de *O* para *LOC*, mas em casos como este, pode ser mais provÃ¡vel se houver uma entidade do tipo *LOC* apÃ³s *ORG*, como em "Apple em London".
>
> A camada CRF aprende a probabilidade de transiÃ§Ã£o entre as etiquetas, ajustando os pesos para capturar as dependÃªncias entre as etiquetas de forma global, considerando toda a sequÃªncia de saÃ­da. Suponha que o CRF atribua uma probabilidade maior para a sequÃªncia completa  *ORG*, *O*, *O*, *O*, *O*, *O*, *O*, *O*, *O*, *LOC* do que para a sequÃªncia *ORG*, *LOC*, *O*, *O*, *O*, *O*, *O*, *O*, *O*, *LOC*, jÃ¡ que a primeira segue a ordem correta de nome de organizaÃ§Ã£o seguida por uma localizaÃ§Ã£o no texto.
>
> Embora a camada softmax seja aplicada token por token, o CRF considera as dependÃªncias e a distribuiÃ§Ã£o global das etiquetas, ajustando os pesos para minimizar a perda considerando transiÃ§Ãµes mais apropriadas.

*Prova:*
I. Sem CRF, cada token $i$ Ã© rotulado independentemente, utilizando a funÃ§Ã£o softmax e a funÃ§Ã£o argmax, com base em $h_i$ e $\mathbf{W}_K$ [^1].
II. Com CRF, a rotulaÃ§Ã£o Ã© um processo global, considerando todas as etiquetas de forma conjunta [^1].
III.  A camada CRF aprende matrizes de transiÃ§Ã£o entre as etiquetas, que indicam a probabilidade de uma etiqueta seguida pela outra.
IV. Para uma sequÃªncia de tokens, o modelo avalia a probabilidade de cada sequÃªncia de etiquetas possÃ­veis, considerando a pontuaÃ§Ã£o gerada pelo modelo, as probabilidades da camada softmax e as matrizes de transiÃ§Ã£o.
V. O objetivo do treinamento com CRF Ã© maximizar a probabilidade das etiquetas corretas para cada sequÃªncia, em vez de rotular tokens individualmente.
VI. A utilizaÃ§Ã£o de CRF, por meio das matrizes de transiÃ§Ã£o, leva a melhores resultados em tarefas de rotulaÃ§Ã£o de sequÃªncia, quando as dependÃªncias entre as etiquetas sÃ£o importantes.
Portanto, o uso do CRF Ã© uma melhoria na modelagem de dependÃªncias entre rÃ³tulos. â– 

**Lema 1.3:** A adiÃ§Ã£o de uma camada de *attention* antes da camada softmax na rotulaÃ§Ã£o de sequÃªncias pode permitir que o modelo aprenda quais partes da sequÃªncia sÃ£o mais relevantes para a rotulaÃ§Ã£o de cada token especÃ­fico.

*Prova:*
I. Cada token $h_i$ Ã© processado individualmente pela camada softmax.
II. Uma camada de atenÃ§Ã£o pode aprender a ponderar as representaÃ§Ãµes $h_j$ dos outros tokens, criando uma representaÃ§Ã£o contextualizada para cada token $h_i$.
III. Essa representaÃ§Ã£o contextualizada $h_i^{att}$ pode ser obtida por meio de uma combinaÃ§Ã£o linear dos demais $h_j$ ponderados por um score de atenÃ§Ã£o, que depende de $h_i$ e $h_j$ [^1].
IV. A camada softmax, ao usar $h_i^{att}$ como entrada, passa a considerar o contexto do token $i$ e nÃ£o apenas a sua representaÃ§Ã£o isolada.
V. Essa representaÃ§Ã£o contextualizada permite que o modelo capture dependÃªncias entre tokens que podem ser relevantes para a tarefa de rotulaÃ§Ã£o, melhorando o desempenho do modelo.
VI. Portanto, a adiÃ§Ã£o de atenÃ§Ã£o Ã© uma forma de aumentar o desempenho, considerando a influÃªncia do contexto para a tarefa de rotulaÃ§Ã£o. â– 

> ğŸ’¡ **Exemplo NumÃ©rico (Attention):**
>
> No exemplo NER anterior, antes de aplicar a softmax, uma camada de *attention* Ã© adicionada. Para o token "Musk", por exemplo, a camada de atenÃ§Ã£o calcularia um peso para cada token da sentenÃ§a, dando maior importÃ¢ncia para os tokens "Elon" e "Tesla", jÃ¡ que eles fazem parte da mesma entidade nomeada. O vetor de saÃ­da contextualizado, $h_{\text{Musk}}^{att}$,  seria calculado ponderando os outros vetores $h_i$ pela atenÃ§Ã£o, fazendo com que a classificaÃ§Ã£o de "Musk" tenha mais informaÃ§Ãµes contextuais.
>  A ideia principal Ã© que alguns tokens da sequÃªncia sÃ£o mais importantes para o contexto de outros, e a camada de *attention* aprende a determinar essa importÃ¢ncia.

### ConclusÃ£o
Este capÃ­tulo explorou os trÃªs tipos principais de tarefas de classificaÃ§Ã£o para *fine-tuning*: classificaÃ§Ã£o de sequÃªncias, classificaÃ§Ã£o de pares de sequÃªncias e rotulaÃ§Ã£o de sequÃªncias [^1]. Para cada tarefa, abordamos as adaptaÃ§Ãµes necessÃ¡rias na arquitetura do modelo e as especificidades do *fine-tuning* [^1]. Enquanto a classificaÃ§Ã£o de sequÃªncia utiliza o vetor de saÃ­da do token `[CLS]` como representaÃ§Ã£o de todo o texto, a classificaÃ§Ã£o de pares de sequÃªncia usa a concatenaÃ§Ã£o de dois vetores `[CLS]`. JÃ¡ a rotulaÃ§Ã£o de sequÃªncias classifica cada token individualmente [^1]. Cada tipo de tarefa exige uma abordagem especÃ­fica, mas todos compartilham a lÃ³gica geral de usar um classificador sobre a saÃ­da do modelo prÃ©-treinado [^1]. As abordagens especÃ­ficas, como o uso de camadas CRF e *attention*, demonstram a flexibilidade e adaptabilidade dos mÃ©todos de *fine-tuning* e a sua capacidade de modelar diferentes tipos de problemas de NLP. Os exemplos numÃ©ricos, o Lema 1.2, a prova do funcionamento do CRF e a demonstraÃ§Ã£o das vantagens de *dropout*, camada nÃ£o linear e *attention* ajudam a consolidar o conhecimento sobre cada abordagem.

### ReferÃªncias
[^1]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright Â© 2024. All rights reserved. Draft of August 20, 2024.
<!-- END -->
