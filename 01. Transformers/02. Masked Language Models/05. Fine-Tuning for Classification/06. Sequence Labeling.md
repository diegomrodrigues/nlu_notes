## Fine-Tuning para RotulaÃ§Ã£o de SequÃªncias: Detalhes e o Uso de CRF

### IntroduÃ§Ã£o

Nos capÃ­tulos anteriores, discutimos o processo de *fine-tuning* para classificaÃ§Ã£o de sequÃªncias e pares de sequÃªncias, que envolvem a atribuiÃ§Ã£o de rÃ³tulos a textos completos ou Ã s relaÃ§Ãµes entre eles [^1]. Este capÃ­tulo aborda um outro tipo de tarefa, a **rotulaÃ§Ã£o de sequÃªncias**, na qual o objetivo Ã© atribuir um rÃ³tulo a cada token em uma sequÃªncia de texto [^1]. Essa tarefa Ã© essencial em diversas aplicaÃ§Ãµes de Processamento de Linguagem Natural (PLN), como reconhecimento de entidades nomeadas (NER), marcaÃ§Ã£o morfossintÃ¡tica (POS tagging) e extraÃ§Ã£o de informaÃ§Ãµes. Aprofundaremos a compreensÃ£o sobre como o *fine-tuning* Ã© aplicado para essa tarefa, com particular foco na utilizaÃ§Ã£o do *Conditional Random Field* (CRF) para modelar as dependÃªncias entre os rÃ³tulos.

### RotulaÃ§Ã£o de SequÃªncias: Conceitos e Objetivos

A **rotulaÃ§Ã£o de sequÃªncias**, tambÃ©m conhecida como classificaÃ§Ã£o *token-level*, consiste em atribuir um rÃ³tulo a cada token individual em uma sequÃªncia de texto [^1]. Essa tarefa difere da classificaÃ§Ã£o de sequÃªncias, que atribui um Ãºnico rÃ³tulo a toda a sequÃªncia, e da classificaÃ§Ã£o de pares de sequÃªncias, que rotula a relaÃ§Ã£o entre dois segmentos de texto [^1].

#### AplicaÃ§Ãµes da RotulaÃ§Ã£o de SequÃªncias
A rotulaÃ§Ã£o de sequÃªncias Ã© utilizada em diversas aplicaÃ§Ãµes de PLN, como:

1.  **Reconhecimento de Entidades Nomeadas (NER):** Identificar e classificar entidades como nomes de pessoas, organizaÃ§Ãµes e locais em um texto.
2.  **MarcaÃ§Ã£o MorfossintÃ¡tica (POS Tagging):** Atribuir rÃ³tulos gramaticais a cada palavra, como substantivo, verbo, adjetivo, etc.
3.  **ExtraÃ§Ã£o de InformaÃ§Ãµes:** Identificar e classificar informaÃ§Ãµes relevantes em um texto, como relaÃ§Ãµes entre entidades e eventos.
4.  **AnÃ¡lise de Sentimento Fina-Granularidade:** Atribuir rÃ³tulos de sentimento a cada palavra ou frase em uma sentenÃ§a.

#### Fine-Tuning para RotulaÃ§Ã£o de SequÃªncias
No processo de *fine-tuning* para rotulaÃ§Ã£o de sequÃªncias, o modelo prÃ©-treinado recebe uma sequÃªncia de texto como entrada e gera uma representaÃ§Ã£o para cada token na sequÃªncia, atravÃ©s dos vetores $h_i$, onde $i$ representa o Ã­ndice do token na sequÃªncia [^1]. Em seguida, cada vetor $h_i$ Ã© passado para um classificador que gera uma distribuiÃ§Ã£o de probabilidade sobre o conjunto de rÃ³tulos possÃ­veis para aquele token,  como visto na equaÃ§Ã£o (11.12):
$$
\mathbf{y}_i = \text{softmax}(\mathbf{h}_i\mathbf{W}_K) \quad (11.12)
$$
Onde $\mathbf{W}_K$ Ã© a matriz de pesos do classificador, e $\mathbf{y}_i$ Ã© o vetor de probabilidades para cada token. ApÃ³s a camada softmax, o rÃ³tulo predito Ã© o rÃ³tulo com a maior probabilidade, usando a funÃ§Ã£o argmax, como visto na equaÃ§Ã£o (11.13):
$$
t_i = \text{argmax}(\mathbf{y}_i) \quad (11.13)
$$
O objetivo do treinamento Ã© ajustar os parÃ¢metros $\mathbf{W}_K$ (e possivelmente os parÃ¢metros do modelo prÃ©-treinado) para que os rÃ³tulos previstos correspondam aos rÃ³tulos verdadeiros nos dados de treinamento.

> ğŸ’¡ **Exemplo NumÃ©rico (Softmax):**
>
>  Considere que temos um modelo prÃ©-treinado que gera embeddings de dimensÃ£o $d=100$ para cada token, ou seja, cada $h_i$ Ã© um vetor de 100 dimensÃµes. Para uma tarefa de POS tagging, temos $K=10$ rÃ³tulos possÃ­veis (e.g., substantivo, verbo, adjetivo, etc). Portanto, a matriz de pesos $\mathbf{W}_K$ terÃ¡ dimensÃ£o $100 \times 10$.
>
>  Suponha que para um token especÃ­fico, apÃ³s o cÃ¡lculo de $\mathbf{h}_i\mathbf{W}_K$, obtemos o vetor de scores $[2.1, 0.8, -0.5, 1.2, 0.1, -1.0, 1.5, 0.3, -0.2, 0.7]$.  Aplicamos a funÃ§Ã£o softmax (equaÃ§Ã£o 11.12) para obter probabilidades:
>
> ```python
> import numpy as np
>
> scores = np.array([2.1, 0.8, -0.5, 1.2, 0.1, -1.0, 1.5, 0.3, -0.2, 0.7])
> probabilities = np.exp(scores) / np.sum(np.exp(scores))
> print(probabilities)
> ```
>
>  A saÃ­da serÃ¡ um vetor de probabilidades, por exemplo, `[0.29, 0.12, 0.03, 0.17, 0.07, 0.02, 0.21, 0.08, 0.05, 0.06]`.  O rÃ³tulo predito (equaÃ§Ã£o 11.13) seria o Ã­ndice do maior valor, que neste caso Ã© o Ã­ndice 0, correspondendo ao primeiro rÃ³tulo. O processo Ã© repetido para cada token na sequÃªncia.
>
>  Este exemplo ilustra como a camada softmax converte scores brutos em probabilidades e como a funÃ§Ã£o argmax seleciona o rÃ³tulo com a maior probabilidade. O objetivo do fine-tuning Ã© ajustar $\mathbf{W}_K$ para que os rÃ³tulos corretos tenham sempre a maior probabilidade apÃ³s o softmax.

**Lema 1:** A dimensÃ£o da matriz de pesos $\mathbf{W}_K$ Ã© $d \times K$, onde $d$ Ã© a dimensÃ£o do vetor $h_i$ e $K$ Ã© o nÃºmero de rÃ³tulos possÃ­veis para a tarefa de rotulaÃ§Ã£o.
*Prova:*
I.  O vetor $h_i$, correspondente ao embedding do token $i$, possui dimensÃ£o $d$, resultado da saÃ­da do modelo prÃ©-treinado.
II. O objetivo da camada linear de classificaÃ§Ã£o (representada pela matriz $\mathbf{W}_K$) Ã© mapear o vetor $h_i$ para um vetor de probabilidades, onde cada elemento do vetor represente a probabilidade de cada um dos $K$ rÃ³tulos possÃ­veis para a tarefa de classificaÃ§Ã£o.
III. A matriz $\mathbf{W}_K$ deve multiplicar o vetor $h_i$ de dimensÃ£o $d$ para gerar um vetor de dimensÃ£o $K$, o que ocorre quando $\mathbf{W}_K$ possui dimensÃ£o $d \times K$.
IV.  Portanto, para que a operaÃ§Ã£o seja vÃ¡lida e que a saÃ­da do classificador tenha dimensÃ£o $K$, a matriz de pesos $\mathbf{W}_K$ deve ter dimensÃµes $d \times K$. â– 

**ProposiÃ§Ã£o 1:** A complexidade computacional da etapa de softmax para uma sequÃªncia de $n$ tokens Ã© $O(n \cdot d \cdot K)$, onde $d$ Ã© a dimensÃ£o de $h_i$ e $K$ Ã© o nÃºmero de rÃ³tulos.
*Prova:*
I. Para cada um dos $n$ tokens, a operaÃ§Ã£o $\mathbf{h}_i \mathbf{W}_K$ requer $d \cdot K$ multiplicaÃ§Ãµes e adiÃ§Ãµes.
II. O cÃ¡lculo do softmax para cada token envolve operaÃ§Ãµes que sÃ£o $O(K)$.
III. Portanto, o custo para cada token Ã© $O(d \cdot K)$, e para todos os $n$ tokens Ã© $O(n \cdot d \cdot K)$. â– 

### Conditional Random Fields (CRF): Modelando DependÃªncias entre RÃ³tulos

Embora a camada softmax, como descrito nas equaÃ§Ãµes (11.12) e (11.13), permita prever o rÃ³tulo mais provÃ¡vel para cada token individualmente, ela ignora a relaÃ§Ã£o entre os rÃ³tulos dos tokens adjacentes [^1]. Em muitas tarefas de rotulaÃ§Ã£o de sequÃªncia, como NER e POS Tagging, os rÃ³tulos dos tokens adjacentes sÃ£o altamente dependentes [^1]. Por exemplo, no NER, um nome de pessoa Ã© geralmente seguido por outro nome de pessoa ou por um nome de organizaÃ§Ã£o. Ã‰ nesse cenÃ¡rio que um modelo CRF Ã© Ãºtil.

#### Funcionamento do CRF
Um *Conditional Random Field* (CRF) Ã© um modelo probabilÃ­stico que considera a dependÃªncia entre os rÃ³tulos dos tokens adjacentes, modelando a probabilidade de uma sequÃªncia de rÃ³tulos como um todo, em vez de rÃ³tulos individuais [^1]. O CRF aprende matrizes de transiÃ§Ã£o entre os rÃ³tulos, o que permite que o modelo capture as dependÃªncias entre os rÃ³tulos em uma sequÃªncia.

A probabilidade de uma sequÃªncia de rÃ³tulos $t = [t_1, t_2, \ldots, t_n]$ para uma sequÃªncia de entrada $x = [x_1, x_2, \ldots, x_n]$  Ã© dada por:

$$ P(t|x) = \frac{exp(score(t, x))}{\sum_{t' \in T} exp(score(t',x))} $$

Onde $T$ Ã© o conjunto de todas as sequÃªncias de rÃ³tulos possÃ­veis e $score(t,x)$ Ã© uma pontuaÃ§Ã£o que mede a adequaÃ§Ã£o da sequÃªncia de rÃ³tulos $t$ para a sequÃªncia de entrada $x$. O score pode ser definido como:

$$ score(t, x) = \sum_{i=1}^{n} \mathbf{W}_K[t_i] \cdot h_i + \sum_{i=2}^{n} \mathbf{A}[t_{i-1}, t_{i}] $$

O primeiro termo $\sum_{i=1}^{n} \mathbf{W}_K[t_i] \cdot h_i$ representa a pontuaÃ§Ã£o de cada rÃ³tulo de token de forma independente (de forma similar ao que fazÃ­amos com o softmax), onde $\mathbf{W}_K[t_i]$ corresponde Ã  linha da matriz $\mathbf{W}_K$ correspondente ao rÃ³tulo $t_i$ e $h_i$ Ã© o embedding daquele token [^1]. O segundo termo $\sum_{i=2}^{n} \mathbf{A}[t_{i-1}, t_{i}]$ representa a pontuaÃ§Ã£o de transiÃ§Ã£o entre dois rÃ³tulos consecutivos, onde $\mathbf{A}$ Ã© a matriz de transiÃ§Ã£o e $\mathbf{A}[t_{i-1}, t_i]$ corresponde Ã  pontuaÃ§Ã£o de transiÃ§Ã£o do rÃ³tulo $t_{i-1}$ para o rÃ³tulo $t_i$. A matriz $\mathbf{A}$ de transiÃ§Ã£o entre rÃ³tulos Ã© um parÃ¢metro aprendÃ­vel que o modelo ajusta durante o treinamento.

Durante o treinamento, o CRF ajusta seus parÃ¢metros (as matrizes $\mathbf{W}_K$ e $\mathbf{A}$) para maximizar a probabilidade dos rÃ³tulos verdadeiros nas sequÃªncias de treinamento. Na inferÃªncia, o CRF encontra a sequÃªncia de rÃ³tulos mais provÃ¡vel para cada sequÃªncia de entrada, usando algoritmos como o algoritmo de Viterbi [^1].

> ğŸ’¡ **Exemplo NumÃ©rico (CRF):**
>
> Considere a frase "Elon Musk trabalha na Tesla.", para a qual temos os embeddings dos tokens, $h_i$, gerados por um modelo prÃ©-treinado e as probabilidades para cada token para as classes *PER* (pessoa), *ORG* (organizaÃ§Ã£o) e *O* (outros), calculadas usando a equaÃ§Ã£o (11.12). Para o token "Elon", a probabilidade usando softmax poderia ser $[0.9, 0.05, 0.05]$. Para o token "Tesla", a probabilidade seria $[0.1, 0.8, 0.1]$. Entretanto, vamos considerar agora o CRF, e para isso vamos simplificar o problema e usar apenas 2 tokens e 2 rÃ³tulos (PER e O).
>
> Suponha que as pontuaÃ§Ãµes da camada softmax ($\mathbf{W}_K[t_i] \cdot h_i$) e as matrizes de transiÃ§Ã£o ($\mathbf{A}[t_{i-1}, t_i]$)  produzem os seguintes scores:
>
> |             |   PER    |   O    |
> |:------------|:--------:|:------:|
> | **Elon**    |   2.1    |  -0.1  |
> | **Musk**    |  1.8    |  -0.3  |
>
>   E a matriz de transiÃ§Ã£o:
>
> |    |   PER    |   O    |
> |:---|:--------:|:------:|
> | PER |   1.0    | -0.5   |
> | O | -0.2   | 0.8   |
>
> Para a sequÃªncia "Elon Musk", temos quatro possÃ­veis sequÃªncias de rÃ³tulos:
>
> 1.  PER, PER:  score = 2.1 + 1.8 + 1.0 = 4.9
> 2.  PER, O: score = 2.1 + (-0.3) + (-0.5) = 1.3
> 3.  O, PER: score = -0.1 + 1.8 + (-0.2) = 1.5
> 4.  O, O: score = -0.1 + (-0.3) + 0.8 = 0.4
>
> Aplicamos a fÃ³rmula do CRF para normalizar as pontuaÃ§Ãµes e criar probabilidades. A sequÃªncia mais provÃ¡vel Ã© a sequÃªncia com maior score: PER, PER. Embora cada rÃ³tulo, individualmente, pudesse ter uma maior probabilidade de ser do tipo *O* (i.e., o softmax, sem o CRF, poderia classificar *Musk* como *O*), a probabilidade da sequÃªncia como um todo (PER, PER) Ã© maior utilizando a matriz de transiÃ§Ã£o.

**Lema 2:** A adiÃ§Ã£o de uma camada de CRF apÃ³s a camada softmax pode melhorar o desempenho da rotulaÃ§Ã£o de sequÃªncias em tarefas onde hÃ¡ dependÃªncias entre os rÃ³tulos, como NER e POS tagging.
*Prova:*
I.  A camada softmax rotula cada token individualmente, ignorando as dependÃªncias contextuais entre os rÃ³tulos [^1].
II. A camada CRF aprende as matrizes de transiÃ§Ã£o entre os rÃ³tulos, modelando explicitamente as dependÃªncias contextuais [^1].
III.  A probabilidade da sequÃªncia de rÃ³tulos Ã© calculada considerando tanto as probabilidades das etiquetas individuais como as transiÃ§Ãµes entre elas.
IV. Portanto, a camada CRF captura as dependÃªncias entre rÃ³tulos, levando a melhores resultados em problemas onde essas dependÃªncias sÃ£o importantes. â– 

**Lema 2.1:** A escolha dos hiperparÃ¢metros do CRF, como a estrutura da matriz de transiÃ§Ã£o e a forÃ§a das regularizaÃ§Ãµes aplicadas, Ã© essencial para o desempenho do modelo e depende da tarefa especÃ­fica.
*Prova:*
I. A complexidade da matriz de transiÃ§Ã£o e a necessidade de regularizaÃ§Ã£o sÃ£o especÃ­ficas para cada tarefa, dado que diferentes tarefas tÃªm diferentes nÃ­veis de dependÃªncia entre rÃ³tulos.
II.  Se a tarefa tiver um nÃºmero elevado de rÃ³tulos com transiÃ§Ãµes complexas, o modelo CRF poderÃ¡ necessitar de uma matriz de transiÃ§Ã£o mais complexa, ou entÃ£o, com mais regularizaÃ§Ã£o.
III. Em tarefas com poucas dependÃªncias, o uso de uma matriz de transiÃ§Ã£o simples ou sem CRF pode apresentar bons resultados.
IV. A escolha adequada de hiperparÃ¢metros para cada tarefa melhora o desempenho do CRF.
V. Portanto, os hiperparÃ¢metros do CRF dependem da tarefa especÃ­fica. â– 

**ObservaÃ§Ã£o 1:** A matriz de transiÃ§Ã£o $\mathbf{A}$ tem dimensÃµes $K \times K$, onde $K$ Ã© o nÃºmero de rÃ³tulos possÃ­veis. Cada elemento $\mathbf{A}[i,j]$ representa a pontuaÃ§Ã£o da transiÃ§Ã£o do rÃ³tulo $i$ para o rÃ³tulo $j$.
*Justificativa:* A matriz de transiÃ§Ã£o modela a transiÃ§Ã£o entre todos os possÃ­veis rÃ³tulos, necessitando portanto de uma linha e coluna para cada um deles.

**ProposiÃ§Ã£o 2:** O nÃºmero de parÃ¢metros adicionais introduzidos pelo uso de um CRF Ã© $K^2$, correspondente ao nÃºmero de elementos na matriz de transiÃ§Ã£o $\mathbf{A}$, onde $K$ Ã© o nÃºmero de rÃ³tulos.
*Prova:* A matriz de transiÃ§Ã£o $\mathbf{A}$ tem dimensÃµes $K \times K$, e cada elemento Ã© um parÃ¢metro a ser aprendido. Portanto, o nÃºmero total de parÃ¢metros Ã© $K \times K = K^2$. â– 

### Fine-Tuning com CRF

O *fine-tuning* para rotulaÃ§Ã£o de sequÃªncia com CRF envolve as seguintes etapas:

1.  **PropagaÃ§Ã£o Direta:** A sequÃªncia de entrada Ã© passada pelo modelo prÃ©-treinado, gerando as representaÃ§Ãµes $h_i$ para cada token, e em seguida, as pontuaÃ§Ãµes da camada softmax $\mathbf{y_i} = \text{softmax}(\mathbf{h}_i\mathbf{W}_K)$.
2. **CÃ¡lculo da PontuaÃ§Ã£o CRF:** As pontuaÃ§Ãµes da camada softmax, as matrizes de transiÃ§Ã£o $\mathbf{A}$ e as pontuaÃ§Ãµes dos rÃ³tulos $\mathbf{W}_K[t_i]$  sÃ£o usadas para calcular a pontuaÃ§Ã£o da sequÃªncia de rÃ³tulos $score(t,x)$ para todas as sequÃªncias de rÃ³tulos possÃ­veis.
3. **CÃ¡lculo da Perda CRF:**  As pontuaÃ§Ãµes $score(t,x)$ sÃ£o usadas para calcular a probabilidade da sequÃªncia de rÃ³tulos verdadeira $P(t|x)$. A perda Ã© a entropia cruzada negativa $\text{Loss} = -log(P(t|x))$, que visa maximizar a probabilidade da sequÃªncia de rÃ³tulos verdadeira.
4. **RetropropagaÃ§Ã£o:** O gradiente da perda Ã© calculado em relaÃ§Ã£o aos parÃ¢metros do modelo, e os pesos da matriz de transiÃ§Ã£o $\mathbf{A}$, da matriz do classificador $\mathbf{W}_K$ e, opcionalmente, as camadas do modelo prÃ©-treinado, sÃ£o ajustados com retropropagaÃ§Ã£o.
5. **OtimizaÃ§Ã£o:** Os parÃ¢metros sÃ£o atualizados utilizando um otimizador, como Adam, com o objetivo de minimizar a perda e maximizar a probabilidade da sequÃªncia de rÃ³tulos correta.

#### Inferencia com o Algoritmo de Viterbi

Durante a inferÃªncia, o modelo deve encontrar a sequÃªncia de rÃ³tulos mais provÃ¡vel para uma dada sequÃªncia de entrada [^1]. Essa busca Ã© realizada utilizando o algoritmo de Viterbi, um algoritmo de programaÃ§Ã£o dinÃ¢mica que encontra a sequÃªncia de rÃ³tulos com o maior score possÃ­vel dentre todas as sequÃªncias. O algoritmo de Viterbi explora o espaÃ§o de todas as sequÃªncias de rÃ³tulos possÃ­veis e retorna a sequÃªncia Ã³tima que maximiza a probabilidade $P(t|x)$, o que se resume a maximizar a soma dos scores de rÃ³tulo $\mathbf{W}_K[t_i] \cdot h_i$ e a pontuaÃ§Ã£o de transiÃ§Ã£o $\mathbf{A}[t_{i-1}, t_i]$.

> ğŸ’¡ **Exemplo NumÃ©rico (Fine-Tuning com CRF):**
>
> Vamos detalhar um passo de *fine-tuning* com CRF, usando um problema de NER. Considere novamente a frase â€œElon Musk trabalha na Tesla.â€. ApÃ³s a tokenizaÃ§Ã£o e a passagem pelo modelo, obtemos as representaÃ§Ãµes $h_i$ para cada token.
>
> Usando a equaÃ§Ã£o (11.12), calculamos as probabilidades para os rÃ³tulos PER, ORG e O para cada token:
>
> **Token "Elon":** $\mathbf{y}_{\text{Elon}} = [0.9, 0.05, 0.05]$ (PER, ORG, O)
> **Token "Musk":** $\mathbf{y}_{\text{Musk}} = [0.8, 0.1, 0.1]$
> **Token "trabalha":** $\mathbf{y}_{\text{trabalha}} = [0.1, 0.1, 0.8]$
> **Token "na":** $\mathbf{y}_{\text{na}} =  [0.05, 0.05, 0.9]$
> **Token "Tesla":** $\mathbf{y}_{\text{Tesla}} = [0.1, 0.8, 0.1]$
>
> O CRF Ã© usado para modelar as transiÃ§Ãµes entre os rÃ³tulos. O CRF aprende as pontuaÃ§Ãµes de transiÃ§Ã£o entre todos os rÃ³tulos (matriz $\mathbf{A}$). Por exemplo:
>
> **TransiÃ§Ã£o de O para O:** +0.8
> **TransiÃ§Ã£o de O para PER:** -0.2
> **TransiÃ§Ã£o de O para ORG:** -0.2
> **TransiÃ§Ã£o de PER para PER:** +0.9
> **TransiÃ§Ã£o de PER para O:** -0.5
> **TransiÃ§Ã£o de PER para ORG:** -0.5
> **TransiÃ§Ã£o de ORG para PER:** -0.5
> **TransiÃ§Ã£o de ORG para O:** -0.5
> **TransiÃ§Ã£o de ORG para ORG:** +0.9
>
> Para cada sequÃªncia de rÃ³tulos, calculamos a pontuaÃ§Ã£o usando a equaÃ§Ã£o de score mencionada anteriormente, que considera as probabilidades de cada token e as transiÃ§Ãµes entre os rÃ³tulos. Por exemplo, uma sequÃªncia possÃ­vel seria  PER, PER, O, O, ORG:
>
> $$ score(PER, PER, O, O, ORG) = score(PER|\text{Elon}) + score(PER|\text{Musk}) + score(O|\text{trabalha}) + score(O|\text{na}) + score(ORG|\text{Tesla}) + score(PER\rightarrow PER) + score(PER \rightarrow O) + score(O \rightarrow O) + score(O \rightarrow ORG) $$
>
> As probabilidades $score(X|token)$ representam a pontuaÃ§Ã£o dada pela camada softmax para a etiqueta $X$ e o token. As transiÃ§Ãµes $score(X \rightarrow Y)$ representam a pontuaÃ§Ã£o para a transiÃ§Ã£o do rÃ³tulo $X$ para o rÃ³tulo $Y$.  Utilizando nÃºmeros fictÃ­cios para este exemplo, poderÃ­amos obter:
>
> $$ score(PER, PER, O, O, ORG) = 0.9 + 0.8 + 0.8 + 0.9 + 0.8 + 0.9 + (-0.5) + 0.8 + (-0.5) = 4.9$$
>
> E para outra sequÃªncia possÃ­vel, PER, O, O, O, ORG :
>
> $$ score(PER, O, O, O, ORG) =  0.9 + 0.1 + 0.8 + 0.9 + 0.8 + (-0.5) + 0.8 + 0.8 + (-0.5) = 3.3 $$
>
> Essas pontuaÃ§Ãµes sÃ£o usadas para calcular a probabilidade da sequÃªncia de rÃ³tulos, e na inferÃªncia o modelo usa o algoritmo de Viterbi para encontrar a sequÃªncia de rÃ³tulos que maximiza a probabilidade.
>
> Durante o treinamento, a retropropagaÃ§Ã£o ajustarÃ¡ as matrizes $\mathbf{W}_K$ e  $\mathbf{A}$ para aumentar a probabilidade dos rÃ³tulos verdadeiros e diminuir a probabilidade de rÃ³tulos incorretos. Por exemplo, o CRF aprende que as transiÃ§Ãµes de O para PER ou ORG sÃ£o menos provÃ¡veis, enquanto as transiÃ§Ãµes de PER para PER e ORG para ORG sÃ£o mais provÃ¡veis em uma tarefa de NER.
>
>  Para ilustrar melhor, vamos considerar um passo de otimizaÃ§Ã£o. Suponha que, durante a retropropagaÃ§Ã£o, o gradiente da perda em relaÃ§Ã£o Ã  transiÃ§Ã£o $\mathbf{A}[O, PER]$ seja de 0.2. Isso significa que aumentar o valor de $\mathbf{A}[O, PER]$ em uma pequena quantidade aumentaria a probabilidade da sequÃªncia correta. O otimizador, como Adam, entÃ£o atualizaria $\mathbf{A}[O, PER]$ usando um learning rate, por exemplo, 0.01. O novo valor de $\mathbf{A}[O, PER]$ seria $\mathbf{A}[O, PER] + 0.01 * 0.2$. Este processo Ã© repetido iterativamente, ajustando todos os parÃ¢metros de $\mathbf{A}$ e $\mathbf{W}_K$ para que as sequÃªncias de rÃ³tulos corretas tenham as maiores pontuaÃ§Ãµes possÃ­veis.

**Teorema 1:** O treinamento de modelos de rotulaÃ§Ã£o de sequÃªncia com CRF garante que o modelo aprenda a modelar as dependÃªncias entre rÃ³tulos, utilizando tanto as informaÃ§Ãµes de cada token quanto a influÃªncia dos rÃ³tulos adjacentes na probabilidade global da sequÃªncia.
*Prova:*
I. A funÃ§Ã£o de perda do CRF considera a sequÃªncia de rÃ³tulos como um todo, calculando a probabilidade conjunta da sequÃªncia de rÃ³tulos corretos.
II. As matrizes de transiÃ§Ã£o $\mathbf{A}$  aprendem explicitamente as probabilidades de transiÃ§Ã£o entre rÃ³tulos adjacentes, incorporando dependÃªncias contextuais entre os rÃ³tulos.
III. O processo de treinamento ajusta os parÃ¢metros para maximizar a probabilidade dos rÃ³tulos corretos dada a sequÃªncia de entrada, levando o modelo a modelar as dependÃªncias entre rÃ³tulos.
IV. Portanto, o modelo CRF aprende a modelar as dependÃªncias entre os rÃ³tulos de uma sequÃªncia de forma eficaz, melhorando os resultados em comparaÃ§Ã£o com abordagens que tratam cada token individualmente. â– 

**Teorema 1.1:** O algoritmo de Viterbi garante que a sequÃªncia de rÃ³tulos mais provÃ¡vel seja encontrada durante a inferÃªncia com CRF, ao explorar todas as possÃ­veis sequÃªncias de rÃ³tulos e retornar a sequÃªncia com a maior probabilidade.
*Prova:*
I. O algoritmo de Viterbi usa programaÃ§Ã£o dinÃ¢mica para calcular a sequÃªncia de rÃ³tulos com maior probabilidade atravÃ©s de caminhos em um grafo de estados, onde cada nÃ³ corresponde a um rÃ³tulo em cada posiÃ§Ã£o da sequÃªncia.
II. Ele armazena os melhores caminhos parciais atÃ© cada posiÃ§Ã£o, usando resultados parciais para calcular a probabilidade total da sequÃªncia de rÃ³tulos.
III. Essa abordagem garante a exploraÃ§Ã£o de todas as sequÃªncias de rÃ³tulos possÃ­veis, ao invÃ©s de uma exploraÃ§Ã£o parcial.
IV. Portanto, o algoritmo de Viterbi encontra a sequÃªncia de rÃ³tulos mais provÃ¡vel em tempo polinomial, em contraste com uma busca exaustiva, que Ã© exponencial. â– 

**Lema 3:** A complexidade computacional do algoritmo de Viterbi para uma sequÃªncia de $n$ tokens e $K$ rÃ³tulos Ã© $O(nK^2)$.
*Prova:*
I. Para cada token na sequÃªncia de entrada, o algoritmo Viterbi itera sobre todos os $K$ possÃ­veis rÃ³tulos.
II. Em cada iteraÃ§Ã£o, o algoritmo considera a transiÃ§Ã£o de todos os $K$ rÃ³tulos anteriores.
III. Isso resulta em uma complexidade de $O(K^2)$ para cada token.
IV. Como isso Ã© repetido para todos os $n$ tokens, a complexidade total Ã© $O(nK^2)$. â– 

### ConclusÃ£o

Este capÃ­tulo abordou em detalhes o processo de *fine-tuning* para rotulaÃ§Ã£o de sequÃªncias, com particular foco na utilizaÃ§Ã£o do *Conditional Random Field* (CRF) [^1]. Exploramos como as saÃ­das dos modelos prÃ©-treinados sÃ£o usadas para gerar as probabilidades dos rÃ³tulos individuais e como o CRF modela as dependÃªncias entre esses rÃ³tulos [^1]. O processo de treinamento supervisionado com CRF, juntamente com o algoritmo de Viterbi na inferÃªncia, garante a atribuiÃ§Ã£o de rÃ³tulos consistentes e de alta qualidade. O CRF Ã© uma ferramenta poderosa para melhorar o desempenho em tarefas de rotulaÃ§Ã£o de sequÃªncia e, junto com as abordagens discutidas nos capÃ­tulos anteriores, demonstra a flexibilidade e o poder dos modelos de linguagem prÃ©-treinados e a sua capacidade de adaptaÃ§Ã£o a uma variedade de tarefas no campo do Processamento de Linguagem Natural [^1].

### ReferÃªncias

[^1]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright Â© 2024. All rights reserved. Draft of August 20, 2024.
<!-- END -->
