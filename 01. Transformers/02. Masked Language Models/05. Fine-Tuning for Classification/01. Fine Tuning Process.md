## Fine-Tuning para ClassificaÃ§Ã£o
### IntroduÃ§Ã£o
Como vimos anteriormente, modelos de linguagem prÃ©-treinados, como os modelos transformadores causais e bidirecionais, aprendem representaÃ§Ãµes ricas e generalizadas da linguagem a partir de grandes quantidades de texto nÃ£o rotulado [^1, ^4]. Para aplicar esses modelos a tarefas especÃ­ficas, como classificaÃ§Ã£o de textos, Ã© necessÃ¡rio um processo de adaptaÃ§Ã£o conhecido como **fine-tuning** [^1]. Este capÃ­tulo explorarÃ¡ o processo de fine-tuning para tarefas de classificaÃ§Ã£o, detalhando como o conhecimento prÃ©-treinado pode ser transferido para aplicaÃ§Ãµes especÃ­ficas [^1].

### Conceitos Fundamentais
O fine-tuning envolve a adiÃ§Ã£o de camadas especÃ­ficas da aplicaÃ§Ã£o, frequentemente chamadas de *heads*, sobre o modelo prÃ©-treinado [^1]. Essas camadas sÃ£o projetadas para realizar uma tarefa especÃ­fica, como classificar um texto em categorias predefinidas ou identificar entidades nomeadas [^1]. O processo de fine-tuning consiste em treinar os parÃ¢metros dessas camadas adicionais usando dados rotulados especÃ­ficos para a tarefa-alvo [^1]. Em geral, os parÃ¢metros do modelo prÃ©-treinado sÃ£o mantidos fixos ou ajustados minimamente durante esse processo, de forma a aproveitar o conhecimento generalizado jÃ¡ aprendido [^1].

No contexto dos modelos de linguagem mascarados (MLM), o fine-tuning Ã© usado para adaptar modelos como o BERT a tarefas especÃ­ficas [^1]. ApÃ³s o prÃ©-treinamento com MLM, que aprende representaÃ§Ãµes contextuais de palavras atravÃ©s de tarefas de preenchimento de lacunas, a rede Ã© adaptada para classificar dados de sequÃªncias, pares de sequÃªncias ou ainda para rotular cada token de uma sequÃªncia [^1].

#### ClassificaÃ§Ã£o de SequÃªncias
A tarefa de **classificaÃ§Ã£o de sequÃªncias** consiste em classificar um texto completo com um Ãºnico rÃ³tulo [^1]. Exemplos incluem anÃ¡lise de sentimento, detecÃ§Ã£o de spam ou classificaÃ§Ã£o de tÃ³picos de documentos [^1]. Para realizar o fine-tuning para classificaÃ§Ã£o de sequÃªncia, adicionamos um *classifier head* sobre a saÃ­da do modelo prÃ©-treinado [^1].

Em modelos como BERT, um token especial, [CLS], Ã© adicionado ao inÃ­cio da sequÃªncia [^1]. O vetor de saÃ­da correspondente a este token, $h_{CLS}$, Ã© considerado uma representaÃ§Ã£o de toda a sequÃªncia de entrada [^1]. Este vetor Ã© entÃ£o passado para um classificador, seja uma regressÃ£o logÃ­stica ou uma rede neural, que mapeia a representaÃ§Ã£o para um conjunto de pontuaÃ§Ãµes sobre as possÃ­veis classes de sentimento [^1].
Matematicamente, a saÃ­da do classificador, $\mathbf{y}$, Ã© dada por:

$$
\mathbf{y} = \text{softmax}(\mathbf{h}_{CLS}\mathbf{W}_C) \quad (11.11)
$$

Onde $\mathbf{W}_C$ representa os pesos do classificador, que sÃ£o aprendidos durante o fine-tuning usando dados rotulados [^1]. A funÃ§Ã£o softmax transforma as pontuaÃ§Ãµes em probabilidades sobre as classes, e a perda de entropia cruzada Ã© utilizada para treinar os parÃ¢metros adicionais [^1].

> ğŸ’¡ **Exemplo NumÃ©rico:** Suponha que temos um modelo BERT e queremos classificar o sentimento de uma frase em trÃªs categorias: "positivo", "negativo" e "neutro". ApÃ³s passar a frase pelo modelo, obtemos um vetor $h_{CLS}$ de tamanho 768 (tamanho tÃ­pico para BERT-base). A matriz de pesos do classificador, $W_C$, terÃ¡ dimensÃµes 768x3 (768 entradas e 3 saÃ­das, uma para cada classe). Suponha que apÃ³s a multiplicaÃ§Ã£o, antes do softmax, tenhamos o vetor de pontuaÃ§Ãµes brutas:
>
> $\mathbf{h}_{CLS}\mathbf{W}_C = [2.1, -0.5, 0.8]$.
>
> Aplicando a funÃ§Ã£o softmax:
>
> $\text{softmax}([2.1, -0.5, 0.8]) = [\frac{e^{2.1}}{e^{2.1}+e^{-0.5}+e^{0.8}}, \frac{e^{-0.5}}{e^{2.1}+e^{-0.5}+e^{0.8}}, \frac{e^{0.8}}{e^{2.1}+e^{-0.5}+e^{0.8}}] \approx [0.75, 0.06, 0.19]$
>
> Isso significa que o modelo estima que a frase tem 75% de chance de ser positiva, 6% de chance de ser negativa e 19% de chance de ser neutra. Durante o fine-tuning, os pesos $\mathbf{W}_C$ serÃ£o ajustados para que as probabilidades preditas se aproximem das classes verdadeiras dos dados de treinamento.
>
> ```python
> import numpy as np
>
> # Vetor h_CLS (representaÃ§Ã£o da sequÃªncia)
> h_cls = np.random.rand(768)
>
> # Matriz de pesos W_C (768x3)
> w_c = np.random.rand(768, 3)
>
> # Calculando as pontuaÃ§Ãµes brutas
> scores = np.dot(h_cls, w_c)
>
> # FunÃ§Ã£o softmax
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> # Aplicando a funÃ§Ã£o softmax
> probabilities = softmax(scores)
> print("Probabilidades:", probabilities)
> # SaÃ­da esperada: Probabilidades: [0.4745, 0.290, 0.234] (valores aproximados)
> ```

**ObservaÃ§Ã£o 1:** Ã‰ importante notar que, alÃ©m da regressÃ£o logÃ­stica, outras arquiteturas de classificaÃ§Ã£o, como redes neurais com mÃºltiplas camadas, podem ser usadas como o *classifier head*. A escolha da arquitetura pode impactar o desempenho do modelo e deve ser ajustada para cada tarefa.

#### ClassificaÃ§Ã£o de Pares de SequÃªncias
A **classificaÃ§Ã£o de pares de sequÃªncias** envolve a classificaÃ§Ã£o da relaÃ§Ã£o entre dois segmentos de texto [^1]. Exemplos incluem a detecÃ§Ã£o de parÃ¡frase, o reconhecimento de inferÃªncia textual (NLI) e a determinaÃ§Ã£o da coerÃªncia discursiva [^1]. Para realizar o fine-tuning para essa tarefa, usamos o vetor de saÃ­da correspondente ao token [CLS] como representaÃ§Ã£o do par de sequÃªncias, semelhante Ã  classificaÃ§Ã£o de sequÃªncia [^1]. O processo de treinamento ocorre com pares de sentenÃ§as rotuladas.

**ProposiÃ§Ã£o 1.1** Uma alternativa para representar pares de sequÃªncias Ã© concatenar as representaÃ§Ãµes do [CLS] token de cada sequÃªncia e posteriormente aplicar um classificador. Mais especificamente, se temos $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$ representando o embedding do token [CLS] para a primeira e a segunda sequÃªncia, respectivamente, podemos obter:
$$
h_{pair} = \text{concat}(h_{CLS}^{(1)}, h_{CLS}^{(2)}),
$$
e entÃ£o a saÃ­da do classificador seria calculada como:
$$
\mathbf{y} = \text{softmax}(h_{pair} \mathbf{W}_P)
$$
onde $\mathbf{W}_P$ sÃ£o os pesos treinÃ¡veis especÃ­ficos para classificaÃ§Ã£o de pares.

> ğŸ’¡ **Exemplo NumÃ©rico:** Suponha que tenhamos duas sentenÃ§as e seus respectivos embeddings  $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$, ambos com dimensÃ£o 768. Queremos classificar a relaÃ§Ã£o entre elas como "parÃ¡frase" ou "nÃ£o parÃ¡frase". Ao concatenar, obtemos $h_{pair}$ com dimensÃ£o 1536 (768 + 768). A matriz de pesos  $W_P$ terÃ¡ dimensÃ£o 1536x2 (1536 entradas e 2 saÃ­das para as duas classes).
>
> Digamos que apÃ³s a multiplicaÃ§Ã£o tenhamos:
>
> $\mathbf{h}_{pair}\mathbf{W}_P = [1.5, -0.3]$
>
> Aplicando softmax:
>
> $\text{softmax}([1.5, -0.3]) = [\frac{e^{1.5}}{e^{1.5}+e^{-0.3}}, \frac{e^{-0.3}}{e^{1.5}+e^{-0.3}}] \approx [0.84, 0.16]$
>
> O modelo estima 84% de chance de ser parÃ¡frase e 16% de nÃ£o ser parÃ¡frase. Durante o treinamento, $W_P$ serÃ¡ ajustada para melhorar essa classificaÃ§Ã£o.
>
> ```python
> import numpy as np
>
> # Embeddings dos tokens CLS das duas sequÃªncias
> h_cls_1 = np.random.rand(768)
> h_cls_2 = np.random.rand(768)
>
> # Concatenando os embeddings
> h_pair = np.concatenate((h_cls_1, h_cls_2))
>
> # Matriz de pesos W_P
> w_p = np.random.rand(1536, 2)
>
> # Calculando as pontuaÃ§Ãµes brutas
> scores = np.dot(h_pair, w_p)
>
> # FunÃ§Ã£o softmax (definida no exemplo anterior)
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> # Aplicando a funÃ§Ã£o softmax
> probabilities = softmax(scores)
> print("Probabilidades:", probabilities)
> # SaÃ­da esperada: Probabilidades: [0.703, 0.296] (valores aproximados)
> ```

*   *Prova:*
    I.  Temos dois embeddings, $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$, correspondentes aos tokens [CLS] da primeira e da segunda sequÃªncia, respectivamente.
    II. A operaÃ§Ã£o de concatenaÃ§Ã£o, $\text{concat}(h_{CLS}^{(1)}, h_{CLS}^{(2)})$, junta esses dois vetores em um Ãºnico vetor $h_{pair}$.
    III. O vetor $h_{pair}$ resultante Ã© entÃ£o passado para um classificador linear com pesos $\mathbf{W}_P$.
    IV. A saÃ­da do classificador Ã© calculada como $h_{pair}\mathbf{W}_P$, resultando em um vetor de pontuaÃ§Ãµes brutas.
    V.  A funÃ§Ã£o softmax Ã© entÃ£o aplicada a esse vetor para transformÃ¡-lo em uma distribuiÃ§Ã£o de probabilidade sobre as possÃ­veis classes:
      $$\mathbf{y} = \text{softmax}(h_{pair} \mathbf{W}_P)$$
     VI. A concatenaÃ§Ã£o garante que o classificador receba informaÃ§Ãµes de ambas as sequÃªncias, permitindo modelar a relaÃ§Ã£o entre elas.
     Portanto, a concatenaÃ§Ã£o das representaÃ§Ãµes do token [CLS] seguida pela aplicaÃ§Ã£o de um classificador Ã© uma representaÃ§Ã£o vÃ¡lida para classificaÃ§Ã£o de pares de sequÃªncias. â– 

#### RotulaÃ§Ã£o de SequÃªncias
A **rotulaÃ§Ã£o de sequÃªncias** atribui um rÃ³tulo a cada token em uma sequÃªncia [^1]. Uma das tarefas mais comuns neste contexto Ã© o **reconhecimento de entidades nomeadas (NER)** [^1]. O fine-tuning para a rotulaÃ§Ã£o de sequÃªncias envolve passar o vetor de saÃ­da de cada token por um classificador para produzir uma distribuiÃ§Ã£o softmax sobre as etiquetas [^1]. O argmax de cada softmax representa a etiqueta atribuÃ­da ao token [^1].

Para um classificador de camada Ãºnica, as probabilidades sobre as etiquetas sÃ£o dadas por:
$$
\mathbf{y}_i = \text{softmax}(\mathbf{h}_i\mathbf{W}_K) \quad (11.12)
$$
Onde $h_i$ representa o vetor de saÃ­da do modelo para cada token $i$, $W_K$ Ã© o conjunto de pesos treinÃ¡veis, e o rÃ³tulo atribuÃ­do Ã© o argmax do vetor de probabilidade:
$$
t_i = \text{argmax}(\mathbf{y}_i) \quad (11.13)
$$
Um mÃ©todo mais complexo e robusto pode usar um *Conditional Random Field* (CRF) sobre as probabilidades da softmax para otimizar as transiÃ§Ãµes entre os rÃ³tulos, que Ã© abordado no capÃ­tulo 17 [^1].

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere a frase "Apple is planning to open a new store in London." Queremos realizar NER, com as seguintes etiquetas: "ORG" (OrganizaÃ§Ã£o), "LOC" (LocalizaÃ§Ã£o), "O" (Outro). ApÃ³s passar a frase no modelo, obtemos um vetor $h_i$ para cada token, cada vetor com dimensÃ£o 768. A matriz de pesos $W_K$ terÃ¡ dimensÃµes 768x3 (768 entradas e 3 saÃ­das para as 3 etiquetas).
>
> Suponha que para o token "Apple", apÃ³s a multiplicaÃ§Ã£o tenhamos:
>
>  $\mathbf{h}_{\text{Apple}}\mathbf{W}_K = [3.2, -1.1, 0.5]$
>
> Aplicando softmax:
>
> $\text{softmax}([3.2, -1.1, 0.5]) \approx [0.89, 0.01, 0.10]$
>
> O modelo estima 89% de chance de "Apple" ser "ORG", 1% de ser "LOC" e 10% de ser "O". O rÃ³tulo atribuÃ­do ao token seria "ORG" (o argmax da distribuiÃ§Ã£o). Similarmente, aplicamos para todos os tokens. Durante o treinamento, $W_K$ serÃ¡ ajustada para aumentar a probabilidade correta para cada token.
>
> ```python
> import numpy as np
>
> # Exemplo de embeddings h_i para cada token em uma sequÃªncia (ex: 5 tokens)
> h_i_tokens = [np.random.rand(768) for _ in range(5)]
>
> # Matriz de pesos W_K (768 x nÃºmero de etiquetas, ex: 3)
> w_k = np.random.rand(768, 3)
>
> # FunÃ§Ã£o softmax (definida anteriormente)
> def softmax(x):
>    e_x = np.exp(x - np.max(x))
>    return e_x / e_x.sum()
>
> # SimulaÃ§Ã£o de rotulaÃ§Ã£o de sequÃªncia
> for i, h_i in enumerate(h_i_tokens):
>    scores = np.dot(h_i, w_k)
>    probabilities = softmax(scores)
>    predicted_label = np.argmax(probabilities)
>    print(f"Token {i}: Probabilidades: {probabilities}, RÃ³tulo Predito: {predicted_label}")
> ```
>
>  ```mermaid
>  graph LR
>      A[Token] --> B(h_i)
>      B --> C{h_i * W_k}
>      C --> D[Softmax]
>      D --> E(y_i)
>      E --> F{argmax(y_i)}
>      F --> G[Label]
>  ```

**Lema 1:** A escolha da funÃ§Ã£o de ativaÃ§Ã£o para a camada de classificaÃ§Ã£o pode impactar a qualidade do treinamento. Embora a softmax seja apropriada para obter probabilidades, outras funÃ§Ãµes como ReLU podem ser consideradas para obter representaÃ§Ãµes intermediÃ¡rias ou em outras tarefas.

**CorolÃ¡rio 1.1:** Na rotulaÃ§Ã£o de sequÃªncia, a utilizaÃ§Ã£o de uma camada linear seguida por uma funÃ§Ã£o ReLU antes da camada softmax (ou CRF), pode permitir a modelagem de relaÃ§Ãµes nÃ£o lineares mais complexas entre os vetores de saÃ­da do modelo prÃ©-treinado e as etiquetas, potencialmente melhorando o desempenho em tarefas de rotulaÃ§Ã£o mais desafiadoras.
    *  *Prova:*
        I. Sejam $h_i$ os vetores de saÃ­da do modelo prÃ©-treinado para o token $i$.
        II. Aplica-se uma transformaÃ§Ã£o linear com pesos $W_L$, resultando em $z_i = h_iW_L$
        III. Uma funÃ§Ã£o ReLU Ã© entÃ£o aplicada a $z_i$, de onde obtemos $a_i = ReLU(z_i)$. ReLU adiciona nÃ£o linearidade ao modelo, permitindo modelar relaÃ§Ãµes complexas
        IV. Finalmente aplica-se a funÃ§Ã£o softmax: $\mathbf{y}_i = \text{softmax}(a_iW_K)$, onde $W_K$ sÃ£o os pesos da camada de classificaÃ§Ã£o que leva a distribuiÃ§Ã£o final.
        V. A sequÃªncia de uma camada linear, ReLU e softmax permite uma melhor adaptaÃ§Ã£o a dados complexos em comparaÃ§Ã£o com uma transformaÃ§Ã£o linear Ãºnica com softmax. Portanto, a utilizaÃ§Ã£o da funÃ§Ã£o ReLU pode levar a um melhor desempenho.
      â– 

### ConclusÃ£o
O fine-tuning Ã© um processo chave para adaptar modelos de linguagem prÃ©-treinados a tarefas especÃ­ficas de classificaÃ§Ã£o [^1]. AtravÃ©s da adiÃ§Ã£o de *heads* de classificaÃ§Ã£o e do treinamento com dados rotulados, os modelos prÃ©-treinados podem ser ajustados para realizar classificaÃ§Ãµes de sequÃªncia, pares de sequÃªncia e rotulaÃ§Ã£o de sequÃªncia [^1]. Este processo permite que os modelos aproveitem o conhecimento generalizado aprendido durante o prÃ©-treinamento e atinjam resultados de alta qualidade em diversas tarefas downstream [^1]. A capacidade de fine-tuning torna modelos de linguagem prÃ©-treinados ferramentas flexÃ­veis e poderosas para uma ampla gama de aplicaÃ§Ãµes de processamento de linguagem natural [^1].

### ReferÃªncias
[^1]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright Â© 2024. All rights reserved. Draft of August 20, 2024.
<!-- END -->
