## Fine-Tuning para Classifica√ß√£o
### Introdu√ß√£o
Como vimos anteriormente, modelos de linguagem pr√©-treinados, como os modelos transformadores causais e bidirecionais, aprendem representa√ß√µes ricas e generalizadas da linguagem a partir de grandes quantidades de texto n√£o rotulado [^1, ^4]. Para aplicar esses modelos a tarefas espec√≠ficas, como classifica√ß√£o de textos, √© necess√°rio um processo de adapta√ß√£o conhecido como **fine-tuning** [^1]. Este cap√≠tulo explorar√° o processo de fine-tuning para tarefas de classifica√ß√£o, detalhando como o conhecimento pr√©-treinado pode ser transferido para aplica√ß√µes espec√≠ficas [^1].

### Conceitos Fundamentais
O fine-tuning envolve a adi√ß√£o de camadas espec√≠ficas da aplica√ß√£o, frequentemente chamadas de *heads*, sobre o modelo pr√©-treinado [^1]. Essas camadas s√£o projetadas para realizar uma tarefa espec√≠fica, como classificar um texto em categorias predefinidas ou identificar entidades nomeadas [^1]. O processo de fine-tuning consiste em treinar os par√¢metros dessas camadas adicionais usando dados rotulados espec√≠ficos para a tarefa-alvo [^1]. Em geral, os par√¢metros do modelo pr√©-treinado s√£o mantidos fixos ou ajustados minimamente durante esse processo, de forma a aproveitar o conhecimento generalizado j√° aprendido [^1].

No contexto dos modelos de linguagem mascarados (MLM), o fine-tuning √© usado para adaptar modelos como o BERT a tarefas espec√≠ficas [^1]. Ap√≥s o pr√©-treinamento com MLM, que aprende representa√ß√µes contextuais de palavras atrav√©s de tarefas de preenchimento de lacunas, a rede √© adaptada para classificar dados de sequ√™ncias, pares de sequ√™ncias ou ainda para rotular cada token de uma sequ√™ncia [^1].

#### Classifica√ß√£o de Sequ√™ncias
A tarefa de **classifica√ß√£o de sequ√™ncias** consiste em classificar um texto completo com um √∫nico r√≥tulo [^1]. Exemplos incluem an√°lise de sentimento, detec√ß√£o de spam ou classifica√ß√£o de t√≥picos de documentos [^1]. Para realizar o fine-tuning para classifica√ß√£o de sequ√™ncia, adicionamos um *classifier head* sobre a sa√≠da do modelo pr√©-treinado [^1].

Em modelos como BERT, um token especial, [CLS], √© adicionado ao in√≠cio da sequ√™ncia [^1]. O vetor de sa√≠da correspondente a este token, $h_{CLS}$, √© considerado uma representa√ß√£o de toda a sequ√™ncia de entrada [^1]. Este vetor √© ent√£o passado para um classificador, seja uma regress√£o log√≠stica ou uma rede neural, que mapeia a representa√ß√£o para um conjunto de pontua√ß√µes sobre as poss√≠veis classes de sentimento [^1].
Matematicamente, a sa√≠da do classificador, $\mathbf{y}$, √© dada por:

$$
\mathbf{y} = \text{softmax}(\mathbf{h}_{CLS}\mathbf{W}_C) \quad (11.11)
$$

Onde $\mathbf{W}_C$ representa os pesos do classificador, que s√£o aprendidos durante o fine-tuning usando dados rotulados [^1]. A fun√ß√£o softmax transforma as pontua√ß√µes em probabilidades sobre as classes, e a perda de entropia cruzada √© utilizada para treinar os par√¢metros adicionais [^1].

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo BERT e queremos classificar o sentimento de uma frase em tr√™s categorias: "positivo", "negativo" e "neutro". Ap√≥s passar a frase pelo modelo, obtemos um vetor $h_{CLS}$ de tamanho 768 (tamanho t√≠pico para BERT-base). A matriz de pesos do classificador, $W_C$, ter√° dimens√µes 768x3 (768 entradas e 3 sa√≠das, uma para cada classe). Suponha que ap√≥s a multiplica√ß√£o, antes do softmax, tenhamos o vetor de pontua√ß√µes brutas:
>
> $\mathbf{h}_{CLS}\mathbf{W}_C = [2.1, -0.5, 0.8]$.
>
> Aplicando a fun√ß√£o softmax:
>
> $\text{softmax}([2.1, -0.5, 0.8]) = [\frac{e^{2.1}}{e^{2.1}+e^{-0.5}+e^{0.8}}, \frac{e^{-0.5}}{e^{2.1}+e^{-0.5}+e^{0.8}}, \frac{e^{0.8}}{e^{2.1}+e^{-0.5}+e^{0.8}}] \approx [0.75, 0.06, 0.19]$
>
> Isso significa que o modelo estima que a frase tem 75% de chance de ser positiva, 6% de chance de ser negativa e 19% de chance de ser neutra. Durante o fine-tuning, os pesos $\mathbf{W}_C$ ser√£o ajustados para que as probabilidades preditas se aproximem das classes verdadeiras dos dados de treinamento.
>
> ```python
> import numpy as np
>
> # Vetor h_CLS (representa√ß√£o da sequ√™ncia)
> h_cls = np.random.rand(768)
>
> # Matriz de pesos W_C (768x3)
> w_c = np.random.rand(768, 3)
>
> # Calculando as pontua√ß√µes brutas
> scores = np.dot(h_cls, w_c)
>
> # Fun√ß√£o softmax
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> # Aplicando a fun√ß√£o softmax
> probabilities = softmax(scores)
> print("Probabilidades:", probabilities)
> # Sa√≠da esperada: Probabilidades: [0.4745, 0.290, 0.234] (valores aproximados)
> ```

**Observa√ß√£o 1:** √â importante notar que, al√©m da regress√£o log√≠stica, outras arquiteturas de classifica√ß√£o, como redes neurais com m√∫ltiplas camadas, podem ser usadas como o *classifier head*. A escolha da arquitetura pode impactar o desempenho do modelo e deve ser ajustada para cada tarefa.

#### Classifica√ß√£o de Pares de Sequ√™ncias
A **classifica√ß√£o de pares de sequ√™ncias** envolve a classifica√ß√£o da rela√ß√£o entre dois segmentos de texto [^1]. Exemplos incluem a detec√ß√£o de par√°frase, o reconhecimento de infer√™ncia textual (NLI) e a determina√ß√£o da coer√™ncia discursiva [^1]. Para realizar o fine-tuning para essa tarefa, usamos o vetor de sa√≠da correspondente ao token [CLS] como representa√ß√£o do par de sequ√™ncias, semelhante √† classifica√ß√£o de sequ√™ncia [^1]. O processo de treinamento ocorre com pares de senten√ßas rotuladas.

**Proposi√ß√£o 1.1** Uma alternativa para representar pares de sequ√™ncias √© concatenar as representa√ß√µes do [CLS] token de cada sequ√™ncia e posteriormente aplicar um classificador. Mais especificamente, se temos $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$ representando o embedding do token [CLS] para a primeira e a segunda sequ√™ncia, respectivamente, podemos obter:
$$
h_{pair} = \text{concat}(h_{CLS}^{(1)}, h_{CLS}^{(2)}),
$$
e ent√£o a sa√≠da do classificador seria calculada como:
$$
\mathbf{y} = \text{softmax}(h_{pair} \mathbf{W}_P)
$$
onde $\mathbf{W}_P$ s√£o os pesos trein√°veis espec√≠ficos para classifica√ß√£o de pares.

> üí° **Exemplo Num√©rico:** Suponha que tenhamos duas senten√ßas e seus respectivos embeddings  $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$, ambos com dimens√£o 768. Queremos classificar a rela√ß√£o entre elas como "par√°frase" ou "n√£o par√°frase". Ao concatenar, obtemos $h_{pair}$ com dimens√£o 1536 (768 + 768). A matriz de pesos  $W_P$ ter√° dimens√£o 1536x2 (1536 entradas e 2 sa√≠das para as duas classes).
>
> Digamos que ap√≥s a multiplica√ß√£o tenhamos:
>
> $\mathbf{h}_{pair}\mathbf{W}_P = [1.5, -0.3]$
>
> Aplicando softmax:
>
> $\text{softmax}([1.5, -0.3]) = [\frac{e^{1.5}}{e^{1.5}+e^{-0.3}}, \frac{e^{-0.3}}{e^{1.5}+e^{-0.3}}] \approx [0.84, 0.16]$
>
> O modelo estima 84% de chance de ser par√°frase e 16% de n√£o ser par√°frase. Durante o treinamento, $W_P$ ser√° ajustada para melhorar essa classifica√ß√£o.
>
> ```python
> import numpy as np
>
> # Embeddings dos tokens CLS das duas sequ√™ncias
> h_cls_1 = np.random.rand(768)
> h_cls_2 = np.random.rand(768)
>
> # Concatenando os embeddings
> h_pair = np.concatenate((h_cls_1, h_cls_2))
>
> # Matriz de pesos W_P
> w_p = np.random.rand(1536, 2)
>
> # Calculando as pontua√ß√µes brutas
> scores = np.dot(h_pair, w_p)
>
> # Fun√ß√£o softmax (definida no exemplo anterior)
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> # Aplicando a fun√ß√£o softmax
> probabilities = softmax(scores)
> print("Probabilidades:", probabilities)
> # Sa√≠da esperada: Probabilidades: [0.703, 0.296] (valores aproximados)
> ```

*   *Prova:*
    I.  Temos dois embeddings, $h_{CLS}^{(1)}$ e $h_{CLS}^{(2)}$, correspondentes aos tokens [CLS] da primeira e da segunda sequ√™ncia, respectivamente.
    II. A opera√ß√£o de concatena√ß√£o, $\text{concat}(h_{CLS}^{(1)}, h_{CLS}^{(2)})$, junta esses dois vetores em um √∫nico vetor $h_{pair}$.
    III. O vetor $h_{pair}$ resultante √© ent√£o passado para um classificador linear com pesos $\mathbf{W}_P$.
    IV. A sa√≠da do classificador √© calculada como $h_{pair}\mathbf{W}_P$, resultando em um vetor de pontua√ß√µes brutas.
    V.  A fun√ß√£o softmax √© ent√£o aplicada a esse vetor para transform√°-lo em uma distribui√ß√£o de probabilidade sobre as poss√≠veis classes:
      $$\mathbf{y} = \text{softmax}(h_{pair} \mathbf{W}_P)$$
     VI. A concatena√ß√£o garante que o classificador receba informa√ß√µes de ambas as sequ√™ncias, permitindo modelar a rela√ß√£o entre elas.
     Portanto, a concatena√ß√£o das representa√ß√µes do token [CLS] seguida pela aplica√ß√£o de um classificador √© uma representa√ß√£o v√°lida para classifica√ß√£o de pares de sequ√™ncias. ‚ñ†

#### Rotula√ß√£o de Sequ√™ncias
A **rotula√ß√£o de sequ√™ncias** atribui um r√≥tulo a cada token em uma sequ√™ncia [^1]. Uma das tarefas mais comuns neste contexto √© o **reconhecimento de entidades nomeadas (NER)** [^1]. O fine-tuning para a rotula√ß√£o de sequ√™ncias envolve passar o vetor de sa√≠da de cada token por um classificador para produzir uma distribui√ß√£o softmax sobre as etiquetas [^1]. O argmax de cada softmax representa a etiqueta atribu√≠da ao token [^1].

Para um classificador de camada √∫nica, as probabilidades sobre as etiquetas s√£o dadas por:
$$
\mathbf{y}_i = \text{softmax}(\mathbf{h}_i\mathbf{W}_K) \quad (11.12)
$$
Onde $h_i$ representa o vetor de sa√≠da do modelo para cada token $i$, $W_K$ √© o conjunto de pesos trein√°veis, e o r√≥tulo atribu√≠do √© o argmax do vetor de probabilidade:
$$
t_i = \text{argmax}(\mathbf{y}_i) \quad (11.13)
$$
Um m√©todo mais complexo e robusto pode usar um *Conditional Random Field* (CRF) sobre as probabilidades da softmax para otimizar as transi√ß√µes entre os r√≥tulos, que √© abordado no cap√≠tulo 17 [^1].

> üí° **Exemplo Num√©rico:** Considere a frase "Apple is planning to open a new store in London." Queremos realizar NER, com as seguintes etiquetas: "ORG" (Organiza√ß√£o), "LOC" (Localiza√ß√£o), "O" (Outro). Ap√≥s passar a frase no modelo, obtemos um vetor $h_i$ para cada token, cada vetor com dimens√£o 768. A matriz de pesos $W_K$ ter√° dimens√µes 768x3 (768 entradas e 3 sa√≠das para as 3 etiquetas).
>
> Suponha que para o token "Apple", ap√≥s a multiplica√ß√£o tenhamos:
>
>  $\mathbf{h}_{\text{Apple}}\mathbf{W}_K = [3.2, -1.1, 0.5]$
>
> Aplicando softmax:
>
> $\text{softmax}([3.2, -1.1, 0.5]) \approx [0.89, 0.01, 0.10]$
>
> O modelo estima 89% de chance de "Apple" ser "ORG", 1% de ser "LOC" e 10% de ser "O". O r√≥tulo atribu√≠do ao token seria "ORG" (o argmax da distribui√ß√£o). Similarmente, aplicamos para todos os tokens. Durante o treinamento, $W_K$ ser√° ajustada para aumentar a probabilidade correta para cada token.
>
> ```python
> import numpy as np
>
> # Exemplo de embeddings h_i para cada token em uma sequ√™ncia (ex: 5 tokens)
> h_i_tokens = [np.random.rand(768) for _ in range(5)]
>
> # Matriz de pesos W_K (768 x n√∫mero de etiquetas, ex: 3)
> w_k = np.random.rand(768, 3)
>
> # Fun√ß√£o softmax (definida anteriormente)
> def softmax(x):
>    e_x = np.exp(x - np.max(x))
>    return e_x / e_x.sum()
>
> # Simula√ß√£o de rotula√ß√£o de sequ√™ncia
> for i, h_i in enumerate(h_i_tokens):
>    scores = np.dot(h_i, w_k)
>    probabilities = softmax(scores)
>    predicted_label = np.argmax(probabilities)
>    print(f"Token {i}: Probabilidades: {probabilities}, R√≥tulo Predito: {predicted_label}")
> ```
>
>  ```mermaid
>  graph LR
>      A[Token] --> B(h_i)
>      B --> C{h_i * W_k}
>      C --> D[Softmax]
>      D --> E(y_i)
>      E --> F{argmax(y_i)}
>      F --> G[Label]
>  ```

**Lema 1:** A escolha da fun√ß√£o de ativa√ß√£o para a camada de classifica√ß√£o pode impactar a qualidade do treinamento. Embora a softmax seja apropriada para obter probabilidades, outras fun√ß√µes como ReLU podem ser consideradas para obter representa√ß√µes intermedi√°rias ou em outras tarefas.

**Corol√°rio 1.1:** Na rotula√ß√£o de sequ√™ncia, a utiliza√ß√£o de uma camada linear seguida por uma fun√ß√£o ReLU antes da camada softmax (ou CRF), pode permitir a modelagem de rela√ß√µes n√£o lineares mais complexas entre os vetores de sa√≠da do modelo pr√©-treinado e as etiquetas, potencialmente melhorando o desempenho em tarefas de rotula√ß√£o mais desafiadoras.
    *  *Prova:*
        I. Sejam $h_i$ os vetores de sa√≠da do modelo pr√©-treinado para o token $i$.
        II. Aplica-se uma transforma√ß√£o linear com pesos $W_L$, resultando em $z_i = h_iW_L$
        III. Uma fun√ß√£o ReLU √© ent√£o aplicada a $z_i$, de onde obtemos $a_i = ReLU(z_i)$. ReLU adiciona n√£o linearidade ao modelo, permitindo modelar rela√ß√µes complexas
        IV. Finalmente aplica-se a fun√ß√£o softmax: $\mathbf{y}_i = \text{softmax}(a_iW_K)$, onde $W_K$ s√£o os pesos da camada de classifica√ß√£o que leva a distribui√ß√£o final.
        V. A sequ√™ncia de uma camada linear, ReLU e softmax permite uma melhor adapta√ß√£o a dados complexos em compara√ß√£o com uma transforma√ß√£o linear √∫nica com softmax. Portanto, a utiliza√ß√£o da fun√ß√£o ReLU pode levar a um melhor desempenho.
      ‚ñ†

### Conclus√£o
O fine-tuning √© um processo chave para adaptar modelos de linguagem pr√©-treinados a tarefas espec√≠ficas de classifica√ß√£o [^1]. Atrav√©s da adi√ß√£o de *heads* de classifica√ß√£o e do treinamento com dados rotulados, os modelos pr√©-treinados podem ser ajustados para realizar classifica√ß√µes de sequ√™ncia, pares de sequ√™ncia e rotula√ß√£o de sequ√™ncia [^1]. Este processo permite que os modelos aproveitem o conhecimento generalizado aprendido durante o pr√©-treinamento e atinjam resultados de alta qualidade em diversas tarefas downstream [^1]. A capacidade de fine-tuning torna modelos de linguagem pr√©-treinados ferramentas flex√≠veis e poderosas para uma ampla gama de aplica√ß√µes de processamento de linguagem natural [^1].

### Refer√™ncias
[^1]: Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ¬© 2024. All rights reserved. Draft of August 20, 2024.
<!-- END -->
