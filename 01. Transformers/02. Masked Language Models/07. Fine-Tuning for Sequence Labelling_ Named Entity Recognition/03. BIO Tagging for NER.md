## Fine-Tuning para Sequence Labeling: Named Entity Recognition

### Introdu√ß√£o
Em continuidade ao t√≥pico de **fine-tuning** apresentado no contexto anterior [^12], este cap√≠tulo se aprofunda em uma aplica√ß√£o espec√≠fica: **sequence labeling**, com foco no **Named Entity Recognition (NER)** [^15]. Como j√° discutido, o fine-tuning possibilita adaptar modelos de linguagem pr√©-treinados para tarefas espec√≠ficas, adicionando camadas especializadas (ou "heads") e utilizando dados rotulados para ajustar os par√¢metros [^13]. Em sequence labeling, o objetivo √© atribuir um r√≥tulo a cada token em uma sequ√™ncia de texto [^15], permitindo, por exemplo, identificar e classificar entidades nomeadas em um texto [^15]. O NER, portanto, √© um exemplo de sequence labeling que envolve a identifica√ß√£o de *spans* de texto que correspondem a nomes pr√≥prios e a classifica√ß√£o desses *spans* em categorias pr√©-definidas [^15]. Este cap√≠tulo explorar√° os detalhes do NER e como o fine-tuning de modelos de linguagem pr√©-treinados pode ser aplicado a esta tarefa [^15].

### Conceitos Fundamentais
O **Named Entity Recognition (NER)** √© uma tarefa fundamental em Natural Language Processing (NLP) que visa identificar e categorizar *named entities* em um texto [^15]. Uma *named entity* √©, em termos gerais, qualquer coisa que possa ser referida por um nome pr√≥prio, como pessoas, locais ou organiza√ß√µes [^15]. A tarefa de NER envolve a identifica√ß√£o de *spans* de texto que correspondem a nomes pr√≥prios e a classifica√ß√£o desses *spans* em categorias pr√©-definidas [^15].

Os tipos de *named entities* mais comuns incluem:
- **PER** (Pessoa): Nomes de pessoas.
- **LOC** (Localiza√ß√£o): Nomes de locais geogr√°ficos.
- **ORG** (Organiza√ß√£o): Nomes de empresas, institui√ß√µes, etc.
- **GPE** (Entidade Geopol√≠tica): Nomes de pa√≠ses, estados, etc. [^15]

Al√©m dessas categorias, o termo *named entity* √© frequentemente estendido para incluir express√µes temporais (datas e horas) e num√©ricas (pre√ßos) [^15].
√â importante ressaltar que o NER √© um problema desafiador devido √† ambiguidade de segmenta√ß√£o e tipo [^16]. Um mesmo *span* de texto pode n√£o ser uma *named entity* ou pode se referir a diferentes tipos, como o exemplo de "Washington" [^16].

Para lidar com essa complexidade, o NER √© frequentemente abordado como uma tarefa de **sequence labeling**, onde cada *token* na sequ√™ncia de entrada √© rotulado [^15]. Uma t√©cnica comum para sequence labeling em NER √© o **BIO tagging** [^16]. No BIO tagging, cada *token* √© rotulado com um dos seguintes tags:

- **B-Type**: Indica que o *token* inicia um *span* de uma entidade do tipo "Type".
- **I-Type**: Indica que o *token* est√° dentro de um *span* de uma entidade do tipo "Type".
- **O**: Indica que o *token* n√£o faz parte de nenhuma *named entity*. [^16]

O BIO tagging permite que o modelo capture a fronteira e o tipo de *named entities* [^16]. Existem variantes como o **IO tagging** e o **BIOES tagging**, sendo o BIOES o mais completo pois adiciona um tag E para o final de um *span* e o tag S para um *span* com apenas um *token* [^16].

> üí° **Exemplo Num√©rico:**
> Considere a frase: "Barack Obama visitou a Fran√ßa em 2015."
> Aplicando o BIO tagging para NER, obter√≠amos:
>
> | Token    | Tag     |
> |----------|---------|
> | Barack   | B-PER   |
> | Obama    | I-PER   |
> | visitou  | O       |
> | a        | O       |
> | Fran√ßa   | B-LOC   |
> | em       | O       |
> | 2015     | O       |
> | .        | O       |
>
> Neste exemplo, "Barack Obama" √© marcado como uma entidade do tipo `PER` (pessoa), e "Fran√ßa" como uma entidade do tipo `LOC` (localiza√ß√£o). Os demais tokens s√£o marcados como `O`, indicando que n√£o fazem parte de nenhuma entidade nomeada.
>
> Agora, vamos considerar o BIOES tagging. A frase "A Apple lan√ßou o iPhone" ficaria:
>
> | Token    | Tag     |
> |----------|---------|
> | A       | O      |
> | Apple   | S-ORG   |
> | lan√ßou   | O       |
> | o       | O      |
> | iPhone  | S-PROD    |
>
> Neste caso, Apple e iPhone, que s√£o entidades de um √∫nico token, s√£o marcadas com o tag S, representando um *span* √∫nico.

**Lema 1**
A escolha da estrat√©gia de tagging (BIO, IO, BIOES) pode impactar o desempenho do modelo NER, especialmente em casos de entidades aninhadas ou adjacentes. O BIOES tagging, por exemplo, oferece maior capacidade de expressar limites de entidades, o que pode levar a um desempenho superior em conjuntos de dados mais complexos.

**Prova:**
A prova √© emp√≠rica, baseada na observa√ß√£o do desempenho de modelos NER em diferentes configura√ß√µes de tagging. O BIOES, ao fornecer tags para o in√≠cio, continua√ß√£o, fim e entidades √∫nicas de um token, permite uma representa√ß√£o mais fina das fronteiras de entidades. Em contraste, o BIO tagging representa apenas o in√≠cio e a continua√ß√£o. IO tagging carece de informa√ß√µes sobre o in√≠cio da entidade, o que pode confundir modelos e diminuir a precis√£o. Portanto, em casos de entidades aninhadas ou adjacentes, o BIOES pode ter um desempenho superior.
$\blacksquare$

**Lema 1.1**
A complexidade da tarefa de NER, medida pelo n√∫mero de entidades e a sua complexidade de aninhamento, influencia o benef√≠cio relativo entre BIO, IO, e BIOES tagging. Em conjuntos de dados com muitas entidades aninhadas, ou com entidades de um √∫nico token, o BIOES tende a apresentar maior vantagem, enquanto em conjuntos de dados mais simples, os outros esquemas podem obter resultados compar√°veis.

**Prova:**
A prova decorre diretamente da natureza dos esquemas de tagging. O esquema BIOES, ao adicionar tags para o fim e entidades de um token, tem maior capacidade de modelar entidades aninhadas, ou entidades com apenas um token. Em conjuntos de dados com muitas dessas caracter√≠sticas, o BIOES demonstra sua vantagem. J√° em conjuntos de dados onde a grande maioria das entidades s√£o cont√≠nuas, o ganho em rela√ß√£o ao BIO ou IO pode ser pequeno.
$\blacksquare$

**Lema 1.2**
A escolha do esquema de tagging tamb√©m pode impactar a necessidade de regras de p√≥s-processamento para corre√ß√£o de sequ√™ncias inv√°lidas. O BIOES, ao explicitar os limites das entidades, pode reduzir a necessidade de corre√ß√£o manual, ao passo que o BIO pode necessitar de regras para impedir transi√ß√µes inv√°lidas, como `I-PER B-LOC`.

**Prova:**
A prova baseia-se na an√°lise das restri√ß√µes impl√≠citas em cada esquema de tagging. O BIOES, ao explicitar o fim das entidades com o tag 'E', evita a necessidade de um p√≥s-processamento para garantir que a sequ√™ncia termine. Por exemplo, o BIOES garante que, ap√≥s um tag 'E-PER', n√£o seja poss√≠vel ter um 'I-PER'. J√° no BIO, uma transi√ß√£o `I-PER B-LOC` √© inv√°lida, mas o modelo pode predize-la. Portanto, a necessidade de p√≥s-processamento √© maior no BIO que no BIOES.
$\blacksquare$

**Sequence Labeling com Modelos de Linguagem Pr√©-treinados**
Em sequence labeling para NER usando modelos de linguagem pr√©-treinados, cada *token* na sequ√™ncia de entrada √© processado pelo modelo, resultando em um vetor de sa√≠da correspondente [^17]. Este vetor de sa√≠da √© ent√£o passado para um classificador, que produz uma distribui√ß√£o de probabilidade sobre os poss√≠veis tags para aquele *token* [^17].

O classificador pode ser uma simples camada *feedforward*, onde o vetor de sa√≠da do modelo √© multiplicado por uma matriz de pesos $W_k$ de tamanho $[d \times k]$, onde $d$ √© a dimens√£o do vetor de sa√≠da do modelo e $k$ √© o n√∫mero de tags poss√≠veis [^17]. A sa√≠da do classificador √© ent√£o passada por uma fun√ß√£o *softmax* para gerar uma distribui√ß√£o de probabilidade sobre os tags [^17]:
$$
    y_i = \text{softmax}(h_i W_k)
$$
Onde $y_i$ √© o vetor de probabilidades sobre os tags, $h_i$ √© o vetor de sa√≠da do modelo para o *token* i, e $W_k$ √© a matriz de pesos do classificador [^17].

Alternativamente, a distribui√ß√£o sobre os r√≥tulos gerada pelo *softmax* pode ser passada para uma camada de **Conditional Random Field (CRF)** que pode modelar transi√ß√µes entre os r√≥tulos [^17]. Uma abordagem *greedy* pode ser usada para obter os r√≥tulos, utilizando o argmax de cada distribui√ß√£o [^17]:
$$
    t_i = \text{argmax}(y_i)
$$
onde $t_i$ √© o r√≥tulo predito para o token i [^17].

> üí° **Exemplo Num√©rico:**
>
> Suponha que a dimens√£o do vetor de sa√≠da do modelo ($h_i$) seja $d=768$ e temos $k=5$ tags poss√≠veis (B-PER, I-PER, B-LOC, I-LOC, O). A matriz de pesos $W_k$ ter√° dimens√£o $[768 \times 5]$.
>
> Vamos considerar o *token* "Obama". Ap√≥s passar pelo modelo, obtemos o vetor $h_i$ (um vetor de 768 dimens√µes):
> ```python
> import numpy as np
>
> h_i = np.random.rand(768)
> W_k = np.random.rand(768, 5)
>
> # Calcula a sa√≠da do classificador
> logits = np.dot(h_i, W_k)
>
> # Aplica softmax para obter a distribui√ß√£o de probabilidade
> def softmax(x):
>     e_x = np.exp(x - np.max(x))
>     return e_x / e_x.sum()
>
> y_i = softmax(logits)
> print("Probabilidades (y_i) para cada tag:", y_i)
>
> # Encontra o r√≥tulo predito usando argmax
> t_i = np.argmax(y_i)
> print("√çndice do tag predito (t_i):", t_i)
>
> tags = ["B-PER", "I-PER", "B-LOC", "I-LOC", "O"]
> print("Tag predito:", tags[t_i])
> ```
> Suponha que o resultado de `y_i` seja `[0.1, 0.7, 0.05, 0.05, 0.1]`.  O tag predito ser√° `I-PER` (√≠ndice 1).
>
>
> Se usarmos um CRF, o CRF leva em considera√ß√£o a probabilidade de transi√ß√£o entre as tags. Por exemplo, a sequ√™ncia `B-PER I-LOC` √© pouco prov√°vel de ocorrer. O CRF ajusta as probabilidades dos r√≥tulos, considerando a sequ√™ncia anterior, para garantir a coer√™ncia da sequ√™ncia de tags. Por exemplo, se um token √© precedido por `B-PER`, o CRF dar√° maior probabilidade para o token seguinte ser `I-PER` ou `O`, reduzindo a probabilidade de ser `B-LOC`.
>
>  > üí° **Exemplo Num√©rico:**
>  > Para ilustrar o efeito do CRF, considere um modelo sem CRF que prediz as seguintes probabilidades para dois tokens consecutivos, com 3 tags poss√≠veis (B-PER, I-PER, O):
>  >
>  > - Token 1 ("Barack"):  `y_1` = `[0.8, 0.1, 0.1]` (B-PER = 0.8, I-PER = 0.1, O = 0.1)
>  > - Token 2 ("Obama"): `y_2` = `[0.3, 0.6, 0.1]` (B-PER = 0.3, I-PER = 0.6, O = 0.1)
>  >
>  > Sem o CRF, um modelo *greedy* escolheria B-PER para o primeiro token e I-PER para o segundo token.
>  >
>  > Agora, vamos supor que o CRF tenha aprendido as seguintes probabilidades de transi√ß√£o:
>  >
>  > |            |  B-PER | I-PER | O    |
>  > |------------|-------|-------|------|
>  > | **B-PER**  | 0.1   | 0.8   | 0.1  |
>  > | **I-PER**  | 0.1   | 0.2   | 0.7  |
>  > | **O**      | 0.3   | 0.05  | 0.65 |
>  >
>  > Onde, por exemplo, a probabilidade de transi√ß√£o de B-PER para I-PER √© 0.8, e de I-PER para I-PER √© 0.2, e de B-PER para B-PER √© 0.1.
>  >
>  > Ao considerar essas probabilidades, o CRF calcularia a pontua√ß√£o de cada sequ√™ncia poss√≠vel:
>  >
>  > - B-PER -> B-PER : 0.8 * 0.1 = 0.08
>  > - B-PER -> I-PER: 0.8 * 0.8 = 0.64
>  > - B-PER -> O: 0.8 * 0.1 = 0.08
>  >
>  > A melhor sequ√™ncia seria B-PER -> I-PER, j√° que a transi√ß√£o de B-PER para I-PER √© mais prov√°vel.
>  >
>  > O CRF ajusta as probabilidades de forma a priorizar sequ√™ncias mais prov√°veis, levando em considera√ß√£o as depend√™ncias entre os r√≥tulos, o que resulta em um NER mais consistente.

**Teorema 1**
A utiliza√ß√£o de um CRF ap√≥s o softmax pode levar a um desempenho superior no NER quando comparada a uma abordagem puramente greedy.

**Prova:**
A prova baseia-se no fato de que o CRF, ao modelar as depend√™ncias entre as tags, captura as rela√ß√µes sequenciais que a abordagem greedy ignora.
I. Uma abordagem *greedy* analisa cada *token* individualmente, escolhendo o r√≥tulo com maior probabilidade independente dos r√≥tulos vizinhos.
II. O CRF, por sua vez, modela as probabilidades de transi√ß√£o entre r√≥tulos, garantindo que a sequ√™ncia de r√≥tulos seja coerente. Por exemplo, a sequ√™ncia de tags "I-PER B-ORG" √© inv√°lida em uma sequ√™ncia BIO.
III. Um modelo greedy pode prever tais sequ√™ncias ao analisar cada tag isoladamente, enquanto o CRF, ao modelar a probabilidade de transi√ß√µes entre tags (como B-PER seguido de I-PER e n√£o B-ORG), imp√µe restri√ß√µes na sa√≠da, garantindo a validade das sequ√™ncias de tags preditas.
IV. Portanto, um CRF pode levar a um desempenho superior em casos onde a consist√™ncia da sequ√™ncia √© importante.
$\blacksquare$

**Teorema 1.1**
O ganho de desempenho com o uso de um CRF sobre uma abordagem greedy √© mais pronunciado em tarefas com maior complexidade nas sequ√™ncias de r√≥tulos. Em tarefas onde as depend√™ncias entre os r√≥tulos s√£o mais fracas, a vantagem do CRF pode ser pequena ou inexistente.

**Prova:**
A prova decorre da natureza do CRF, que modela as depend√™ncias entre os r√≥tulos.
I. Em tarefas onde a sequ√™ncia de r√≥tulos tem pouca ou nenhuma restri√ß√£o, a capacidade do CRF de modelar transi√ß√µes se torna pouco relevante.
II. J√° em tarefas como NER, onde a sequ√™ncia de r√≥tulos segue um padr√£o, o CRF traz um grande ganho. Por exemplo, em uma sequ√™ncia BIO, a transi√ß√£o de B-LOC para I-LOC √© mais prov√°vel do que a transi√ß√£o para B-PER, e isso √© modelado pelo CRF.
III. Se os r√≥tulos fossem independentes, o ganho de usar CRF seria marginal.
$\blacksquare$

**Teorema 1.2**
A complexidade computacional introduzida pelo CRF √© maior que a da abordagem greedy, especialmente durante o treinamento, e isso deve ser levado em considera√ß√£o na escolha da arquitetura. A abordagem greedy pode ser mais adequada em contextos com restri√ß√µes de recursos computacionais.

**Prova:**
A prova baseia-se na compara√ß√£o da complexidade computacional das duas abordagens.
I. Enquanto a abordagem greedy faz a predi√ß√£o de cada r√≥tulo de forma independente, o CRF considera a probabilidade de transi√ß√£o entre as tags.
II. Isso implica em uma etapa de treinamento adicional para o CRF, onde a matriz de transi√ß√£o entre os r√≥tulos deve ser estimada.
III. Tamb√©m implica em um aumento no tempo de decodifica√ß√£o ao calcular o caminho mais prov√°vel.
IV. Em tarefas com restri√ß√µes de tempo ou recursos, essa complexidade pode tornar a abordagem greedy mais adequada.
$\blacksquare$

**Tokeniza√ß√£o e Alinhamento de R√≥tulos**
Um desafio surge quando se usa modelos baseados em *subwords* como o WordPiece [^17]. As *named entities* s√£o geralmente rotuladas no n√≠vel da palavra, enquanto os modelos de linguagem operam no n√≠vel do *subword*, o que causa um desalinhamento [^17].
Para lidar com esse desalinhamento, durante o treinamento, um r√≥tulo de n√≠vel de palavra √© atribu√≠do a todos os *subwords* derivados dessa palavra. Durante a decodifica√ß√£o, a abordagem mais simples √© usar o r√≥tulo associado ao primeiro *subword* da palavra [^18]. M√©todos mais complexos combinam as distribui√ß√µes de r√≥tulos de todos os *subwords* para gerar uma previs√£o de r√≥tulo de n√≠vel de palavra otimizada [^18].

> üí° **Exemplo Num√©rico:**
>
> Considere a palavra "Villanueva". Um tokenizador WordPiece pode dividir em "Villa", "##nue", "##va".
>
> Se a palavra "Villanueva" estiver rotulada como `I-PER`, no treinamento, os *subwords* "Villa", "##nue", "##va" ser√£o rotulados como `I-PER`.
>
> Durante a decodifica√ß√£o, usando a abordagem mais simples, o r√≥tulo `I-PER` associado ao primeiro *subword* "Villa" seria atribu√≠do √† palavra inteira "Villanueva".
>
> Uma abordagem mais complexa pode calcular a m√©dia das probabilidades dos r√≥tulos para cada *subword*, ou usar a probabilidade do r√≥tulo mais frequente.
>
> Por exemplo, vamos supor que o modelo gere as seguintes probabilidades para os *subwords*:
>
> - "Villa": `[0.1, 0.8, 0.05, 0.02, 0.03]` (correspondendo √†s probabilidades de `B-PER`, `I-PER`, `B-LOC`, `I-LOC`, `O`)
> - "##nue": `[0.05, 0.9, 0.02, 0.01, 0.02]`
> - "##va": `[0.03, 0.85, 0.04, 0.03, 0.05]`
>
> A m√©dia das probabilidades seria: `[0.06, 0.88, 0.04, 0.02, 0.03]`, ainda resultando em `I-PER` como o r√≥tulo mais prov√°vel.  A escolha do r√≥tulo mais frequente entre os *subwords* tamb√©m seria `I-PER` neste caso.
>
> ```python
> import numpy as np
>
> subword_probs = {
>    "Villa": np.array([0.1, 0.8, 0.05, 0.02, 0.03]),
>    "##nue": np.array([0.05, 0.9, 0.02, 0.01, 0.02]),
>    "##va": np.array([0.03, 0.85, 0.04, 0.03, 0.05])
> }
>
> # Calcula a m√©dia das probabilidades
> avg_probs = np.mean(list(subword_probs.values()), axis=0)
> print("M√©dia das probabilidades:", avg_probs)
>
> # Escolhe o tag com a maior probabilidade m√©dia
> predicted_tag_avg = np.argmax(avg_probs)
>
> tags = ["B-PER", "I-PER", "B-LOC", "I-LOC", "O"]
> print("Tag predito pela m√©dia:", tags[predicted_tag_avg])
>
> # Calcula o tag mais frequente
> predicted_tags = [np.argmax(probs) for probs in subword_probs.values()]
> most_frequent_tag = max(set(predicted_tags), key=predicted_tags.count)
> print("Tag predito pela frequ√™ncia:", tags[most_frequent_tag])
>
> ```

**Proposi√ß√£o 1**
A agrega√ß√£o das distribui√ß√µes de probabilidade dos r√≥tulos de *subwords* pode ser realizada por diferentes m√©todos, como a m√©dia das probabilidades, ou utilizando a probabilidade do r√≥tulo mais frequente ou com maior score. Cada m√©todo pode ter vantagens e desvantagens dependendo da distribui√ß√£o de *subwords* e da tarefa.

**Prova:**
A prova √© baseada na avalia√ß√£o emp√≠rica dos diferentes m√©todos de agrega√ß√£o.
I.  A m√©dia de probabilidades suaviza o ru√≠do na predi√ß√£o, j√° que cada *subword* contribui igualmente para a probabilidade final da palavra.
II. A escolha do r√≥tulo mais frequente aumenta a confian√ßa na predi√ß√£o, caso os *subwords* da palavra estejam consistentemente relacionados a um r√≥tulo.
III. Utilizar a probabilidade m√°xima pode levar a erros se a distribui√ß√£o dos *subwords* estiver ruidosa, uma vez que a probabilidade de um √∫nico *subword* √© selecionada, e ru√≠dos podem ser amplificados.
IV. A escolha do m√©todo ideal √© emp√≠rica e depende da distribui√ß√£o dos *subwords*, da tarefa e do modelo de linguagem, e cada m√©todo pode ser mais apropriado para diferentes cen√°rios.
V. M√©todos que levam em conta as particularidades da tokeniza√ß√£o e das distribui√ß√µes geradas pelo modelo podem levar a melhores resultados, como dar maior peso para o primeiro *subword* de uma palavra, por exemplo.
$\blacksquare$

**Proposi√ß√£o 1.1**
O m√©todo de agrega√ß√£o de r√≥tulos de *subwords* mais apropriado pode depender das caracter√≠sticas do tokenizador e do idioma. Por exemplo, para l√≠nguas com alta taxa de palavras compostas ou aglutina√ß√£o, m√©todos baseados na frequ√™ncia podem ser mais robustos.

**Prova:**
A prova √© baseada em resultados emp√≠ricos e na an√°lise das propriedades dos m√©todos de agrega√ß√£o e da estrutura da linguagem.
I. Em idiomas como o alem√£o, que possui muitas palavras compostas, a m√©dia das probabilidades pode ser inadequada pois, frequentemente, o primeiro *subword* de uma palavra composta √© muito mais representativo do que os demais. O mesmo acontece em idiomas com aglutina√ß√£o, onde os primeiros *subwords* carregam a maior parte do significado.
II. O uso da probabilidade do r√≥tulo mais frequente ou de maior score pode ser mais apropriado, pois d√° mais peso aos primeiros *subwords* da palavra.
III. Portanto, a melhor escolha do m√©todo de agrega√ß√£o deve ser determinada empiricamente, levando em considera√ß√£o a natureza da l√≠ngua e do tokenizador usado.
$\blacksquare$

**Proposi√ß√£o 1.2**
O m√©todo de agrega√ß√£o tamb√©m pode ser influenciado pelo tamanho do vocabul√°rio do tokenizador. Tokenizadores com vocabul√°rio maior tendem a ter *subwords* que representam palavras inteiras mais frequentemente, o que reduz a necessidade de agrega√ß√£o sofisticada.

**Prova:**
A prova √© baseada na rela√ß√£o entre o tamanho do vocabul√°rio do tokenizador e a frequ√™ncia com que palavras inteiras s√£o representadas por um √∫nico *subword*.
I. Tokenizadores com um vocabul√°rio menor tendem a dividir mais as palavras em *subwords*, aumentando a necessidade de uma agrega√ß√£o mais sofisticada das probabilidades, pois mais r√≥tulos precisam ser agregados.
II. Em contrapartida, um tokenizador com vocabul√°rio maior, ter√° menos palavras divididas, e muitos *subwords* corresponder√£o a palavras inteiras, diminuindo a complexidade da agrega√ß√£o, pois um *subword* j√° representar√° a palavra inteira.
III. Portanto, um tokenizador com um vocabul√°rio maior pode se beneficiar de uma agrega√ß√£o mais simples, como utilizar a probabilidade do primeiro *subword*, j√° que este pode ser a palavra completa.
$\blacksquare$

**Avalia√ß√£o de NER**
Os modelos de NER s√£o avaliados utilizando m√©tricas de **recall**, **precision** e **F1-measure** [^18]. O recall √© a propor√ß√£o de respostas corretamente rotuladas em rela√ß√£o ao total que deveria ter sido rotulado. A precis√£o √© a propor√ß√£o de respostas corretamente rotuladas em rela√ß√£o ao total rotulado e o F1-measure √© a m√©dia harm√¥nica dos dois [^18].

A avalia√ß√£o do NER se concentra em entidades, n√£o em palavras individuais, considerando cada entidade como uma unidade de resposta [^18]. Por exemplo, se o modelo rotular "Jane" como pessoa mas n√£o "Jane Villanueva", contar√° um falso negativo para I-PER e um falso positivo para O [^18]. Isso gera um desafio de avalia√ß√£o pois a unidade de treinamento e avalia√ß√£o n√£o s√£o iguais.

> üí° **Exemplo Num√©rico:**
>
> Vamos analisar um exemplo de avalia√ß√£o. Suponha que tenhamos a seguinte frase com entidades reais:
>
> **Frase:** "Elon Musk, CEO da Tesla, visitou Berlim."
>
> **Entidades Reais:**
>   - "Elon Musk" (PER)
>   - "Tesla" (ORG)
>   - "Berlim" (LOC)
>
> Suponha que um modelo NER produza as seguintes entidades:
>
> **Entidades Preditas:**
>   - "Elon" (PER)
>   - "Tesla" (ORG)
>   - "Berlim" (LOC)
>
>
> **C√°lculo:**
>
>   -   **Verdadeiros Positivos (TP):**  "Tesla" e "Berlim" foram preditos corretamente. 2 TPs.
>   -   **Falsos Positivos (FP):**  "Elon" foi predito como PER, mas a entidade completa √© "Elon Musk". 1 FP
>   -   **Falsos Negativos (FN):** "Elon Musk" foi parcialmente predito, mas a entidade completa ( "Elon Musk") n√£o. 1 FN
>
> **M√©tricas:**
>
>   -   **Precis√£o:** $\frac{TP}{TP+FP} = \frac{2}{2+1} = 0.67$
>   -   **Recall:** $\frac{TP}{TP+FN} = \frac{2}{2+1} = 0.67$
>   -   **F1-measure:** $2 \times \frac{\text{Precis√£o} \times \text{Recall}}{\text{Precis√£o} + \text{Recall}} = 2 \times \frac{0.67 \times 0.67}{0.67+0.67} = 0.67$
>
> Agora, suponha outro modelo que previu:
>
> **Entidades Preditas:**
>   - "Elon Musk" (PER)
>   - "Tesla" (ORG)
>   - "Berlim" (LOC)
>
> Para este modelo, temos:
>
>  -   **Verdadeiros Positivos (TP):**  "Elon Musk", "Tesla" e "Berlim" foram preditos corretamente. 3 TPs.
>   -   **Falsos Positivos (FP):** 0 FPs
>   -   **Falsos Negativos (FN):** 0 FNs
>
> **M√©tricas:**
>
>   -   **Precis√£o:** $\frac{TP}{TP+FP} = \frac{3}{3+0} = 1.0$
>   -   **Recall:** $\frac{TP}{TP+FN} = \frac{3}{3+0} = 1.0$
>   -   **F1-measure:** $2 \times \frac{\text{Precis√£o} \times \text{Recall}}{\text{Precis√£o} + \text{Recall}} = 2 \times \frac{1.0 \times 1.0}{1.0+1.0} = 1.0$
>
> Este exemplo ilustra como as m√©tricas de avalia√ß√£o s√£o calculadas em NER, mostrando que o segundo modelo tem melhor desempenho.
>
>  > üí° **Exemplo Num√©rico:**
>  > Considere um modelo que tenta classificar a frase "Apple anunciou o novo iPhone". O gold standard (refer√™ncia) e a predi√ß√£o do modelo est√£o na seguinte tabela:
>  >
>  > | Token       | Gold Tag | Predito Tag |
>  > |-------------|----------|-------------|
>  > | Apple      | B-ORG     | B-ORG       |
>  > | anunciou   | O        | O           |
>  > | o          | O        | O           |
>  > | novo       | B-PROD    | B-PROD       |
>  > | iPhone     | I-PROD   | I-PROD       |
>  >
>  > Neste caso, temos:
>  >
>  > -   **Verdadeiros Positivos (TP):**  "Apple" e "novo iPhone" foram preditos corretamente como ORG e PROD, respectivamente. 2 TPs.
>  > -   **Falsos Positivos (FP):** 0 FPs.
>  > -   **Falsos Negativos (FN):** 0 FNs.
>  >
>  > **M√©tricas:**
>  > -   **Precis√£o:** $\frac{TP}{TP+FP} = \frac{2}{2+0} = 1.0$
>  > -   **Recall:** $\frac{TP}{TP+FN} = \frac{2}{2+0} = 1.0$
>  > -   **F1-measure:** $2 \times \frac{1.0 \times 1.0}{1.0+1.0} = 1.0$
>  >
>  >  Agora, considere que o modelo tenha previsto:
>  > | Token       | Gold Tag | Predito Tag |
>  > |-------------|----------|-------------|
>  > | Apple      | B-ORG     | B-ORG      |
>  > | anunciou   | O        | O           |
>  > | o          | O        | O           |
>  > | novo       | B-PROD    | B-PROD       |
>  > | iPhone     | I-PROD   | B-PROD       |
>  >
>  > Neste caso, "iPhone" foi predito como B-PROD, mas o gold label √© I-PROD. Temos:
>  >
>  > -   **Verdadeiros Positivos (TP):** "Apple" foi corretamente predito como ORG. 1 TP
>  > -   **Falsos Positivos (FP):** "novo" foi corretamente predito como B-PROD, mas "iPhone" foi incorretamente predito como B-PROD, quando deveria ser I-PROD. 1 FP
>  > -   **Falsos Negativos (FN):** "novo iPhone" deveria ser I-PROD, mas foi interpretado como duas entidades separadas. 1 FN
>  >
>  > **M√©tricas:**
>  > -   **Precis√£o:** $\frac{1}{1+1} = 0.5$
>  > -   **Recall:** $\frac{1}{1+1} = 0.5$
>  > -   **F1-measure:** $2 \times \frac{0.5 \times 0.5}{0.5+0.5} = 0.5$
>  >
>  >Este exemplo mostra como um erro de limite (no caso, considerar "iPhone" uma entidade separada) impacta nas m√©tricas de avalia√ß√£o.

**Corol√°rio 1**
Uma an√°lise detalhada dos erros cometidos pelo modelo NER pode revelar padr√µes ou dificuldades espec√≠ficas do modelo. Erros podem ser categorizados como falsos positivos, falsos negativos, erros de tipo, erros de limite, ou combina√ß√µes desses, fornecendo insights sobre como o modelo pode ser melhorado.

**Prova:**
A an√°lise de erros √© um componente essencial do desenvolvimento de modelos.
I. Categorizar os erros por tipo (falsos positivos, falsos negativos, erros de classifica√ß√£o de tipo, erros de limite) permite que se identifiquem padr√µes no comportamento do modelo e identifique tipos de erros recorrentes.
II. Por exemplo, um modelo pode ter dificuldade em reconhecer entidades com limites amb√≠guos, ou distinguir entre tipos semelhantes de entidades (por exemplo, LOC vs. GPE).
III. Essa an√°lise detalhada permite que se tomem decis√µes mais informadas sobre como melhorar o treinamento do modelo, como aumentar a quantidade de dados espec√≠ficos, ajustar as t√©cnicas de tokeniza√ß√£o ou explorar arquiteturas de modelos mais complexas, focando em √°reas espec√≠ficas de fraqueza.
$\blacksquare$

**Corol√°rio 1.1**
A an√°lise de erros pode guiar o aumento de dados de treinamento, direcionando a cria√ß√£o de exemplos que representam os erros mais frequentes do modelo. Esse procedimento √© conhecido como *data augmentation dirigido por erro* e pode levar a uma melhoria mais eficiente do desempenho do modelo.

**Prova:**
A prova segue diretamente da an√°lise de erros.
I. Ao analisar os erros, se identificamos que o modelo tem dificuldade em reconhecer uma classe espec√≠fica de entidades, podemos criar novos exemplos de treinamento contendo essa classe espec√≠fica, para adicionar exemplos onde o modelo est√° se saindo mal.
II. Esse direcionamento da cria√ß√£o de dados para os erros mais frequentes torna o processo de aumento de dados mais eficiente, focando em √°reas onde o modelo tem mais dificuldades e precisa aprender mais.
III. Isso pode levar a melhorias significativas com menos exemplos de treinamento, quando comparado a um aumento de dados aleat√≥rio, que pode n√£o adicionar exemplos que abordem a fraqueza do modelo.
$\blacksquare$

**Corol√°rio 1.2**
A avalia√ß√£o de NER tamb√©m pode levar em conta as diferen√ßas de import√¢ncia entre os tipos de entidades. Por exemplo, pode ser dada maior import√¢ncia a erros relacionados a entidades PER, em compara√ß√£o com erros em entidades LOC, dependendo da aplica√ß√£o. Isso pode ser implementado usando m√©tricas de avalia√ß√£o ponderadas.

**Prova:**
A prova √© baseada na necessidade de adaptar a avalia√ß√£o √†s necessidades da aplica√ß√£o espec√≠fica.
I. Em algumas aplica√ß√µes, a identifica√ß√£o correta de entidades de um tipo pode ser mais cr√≠tica do que a identifica√ß√£o correta de entidades de outros tipos. Por exemplo, em aplica√ß√µesde sa√∫de, a identifica√ß√£o incorreta de um medicamento pode ter consequ√™ncias muito mais graves do que a identifica√ß√£o incorreta de uma condi√ß√£o m√©dica. Nesses casos, pode-se atribuir pesos diferentes √†s diferentes classes durante o treinamento do modelo, dando maior import√¢ncia √† identifica√ß√£o correta de entidades de tipos mais cr√≠ticos. Isso pode ser feito usando fun√ß√µes de perda ponderadas ou estrat√©gias de amostragem que d√£o mais peso √†s amostras de tipos de entidades mais cr√≠ticos.

II. Outra considera√ß√£o importante √© que nem todas as entidades do mesmo tipo t√™m a mesma import√¢ncia. Por exemplo, em um texto sobre not√≠cias financeiras, a identifica√ß√£o de uma empresa como "Apple" pode ser mais importante do que a identifica√ß√£o de uma empresa menos conhecida. Nesses casos, pode-se usar uma abordagem hier√°rquica para a tarefa de reconhecimento de entidades nomeadas. Primeiro, o modelo pode identificar os tipos de entidades, depois, dentro de cada tipo, pode-se atribuir diferentes pesos √†s diferentes entidades, dependendo de sua import√¢ncia. Isso pode ser feito usando um modelo de classifica√ß√£o em duas etapas ou uma arquitetura de rede neural hier√°rquica.

III. Al√©m disso, em muitos casos, o contexto desempenha um papel crucial na determina√ß√£o do tipo correto de uma entidade nomeada. Por exemplo, a palavra "Apple" pode se referir a uma empresa de tecnologia ou a uma fruta, dependendo do contexto. Portanto, √© importante considerar o contexto ao realizar o reconhecimento de entidades nomeadas. Isso pode ser feito usando modelos de linguagem que capturam as rela√ß√µes contextuais entre palavras, como o BERT ou o Transformer, ou usando arquiteturas de redes neurais com mecanismos de aten√ß√£o que permitem que o modelo se concentre nas partes mais relevantes do texto ao realizar o reconhecimento de entidades nomeadas.

IV. Al√©m do modelo em si, tamb√©m √© importante considerar a qualidade dos dados de treinamento. Se os dados de treinamento forem enviesados, o modelo provavelmente ter√° um desempenho ruim em dados que n√£o seguem essa mesma distribui√ß√£o. Por exemplo, se os dados de treinamento contiverem mais exemplos de um determinado tipo de entidade, o modelo poder√° ter um desempenho melhor nesse tipo de entidade do que em outros tipos. Portanto, √© importante usar um conjunto de dados de treinamento diversificado e equilibrado para garantir que o modelo tenha um bom desempenho em uma ampla gama de exemplos. Em outras palavras, √© fundamental realizar uma an√°lise explorat√≥ria dos dados para identificar potenciais vieses e, em seguida, aplicar as corre√ß√µes necess√°rias para garantir que o modelo n√£o seja afetado por esses vieses.

V. Outro fator importante a considerar √© a disponibilidade de dados rotulados. Em muitas aplica√ß√µes, a obten√ß√£o de dados rotulados para o reconhecimento de entidades nomeadas pode ser cara e demorada. Nesse caso, t√©cnicas de aprendizado semi-supervisionado podem ser usadas, onde o modelo √© treinado em uma combina√ß√£o de dados rotulados e n√£o rotulados. As t√©cnicas de aprendizado por transfer√™ncia tamb√©m podem ser √∫teis, onde um modelo pr√©-treinado em um conjunto de dados grande pode ser adaptado para uma tarefa de reconhecimento de entidades nomeadas com menos dados rotulados.

VI. Finalmente, √© importante monitorar e avaliar o desempenho do modelo ao longo do tempo. √Ä medida que os dados de entrada mudam, o desempenho do modelo pode se deteriorar. Portanto, √© importante usar um conjunto de dados de teste independente para avaliar o desempenho do modelo regularmente e, se necess√°rio, retreinar o modelo com novos dados para garantir que ele continue funcionando bem. Isso pode envolver a implanta√ß√£o de um sistema de monitoramento que avalia continuamente o modelo e dispara alertas caso haja uma deteriora√ß√£o do desempenho.

<!-- END -->
