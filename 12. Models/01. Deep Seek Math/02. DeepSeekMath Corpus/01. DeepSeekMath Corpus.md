## DeepSeekMath Corpus: Construindo um Dataset de Pré-Treinamento Matemático em Larga Escala

### Introdução
Este capítulo explora a construção do **DeepSeekMath Corpus**, um dataset de pré-treinamento em larga escala projetado para melhorar as capacidades de raciocínio matemático de *Large Language Models* (LLMs). Conforme mencionado na introdução [^1], os LLMs revolucionaram a forma como a inteligência artificial aborda o raciocínio matemático, e o desenvolvimento de datasets especializados como o DeepSeekMath Corpus é crucial para impulsionar ainda mais esse progresso. Este corpus, compreendendo 120B de tokens matemáticos, é extraído do *Common Crawl* (CC) através de um classificador baseado em *fastText* e refinado por anotação humana.

### Conceitos Fundamentais
O desenvolvimento do DeepSeekMath Corpus envolve uma série de etapas meticulosas, visando garantir a qualidade e relevância dos dados utilizados no pré-treinamento dos modelos [^4].

1.  **Seleção Inicial do Corpus Semente**: O processo começa com a escolha do **OpenWebMath** [^4], uma coleção de textos da web de alta qualidade com conteúdo matemático, como o *corpus* semente inicial. Este corpus é fundamental para treinar um classificador capaz de identificar páginas da web semelhantes com conteúdo matemático.
2.  **Treinamento do Classificador fastText**: Utilizando o *corpus* semente, um modelo *fastText* (Joulin et al., 2016) [^4] é treinado para identificar páginas da web adicionais com conteúdo matemático. O modelo *fastText* é uma biblioteca de código aberto para aprendizado de representações de palavras e classificação de texto.
    *   **Configuração do Modelo**: O modelo é configurado com uma dimensão de vetor de 256, taxa de aprendizado de 0.1, comprimento máximo de *n-gram* de palavras de 3, número mínimo de ocorrências de palavras de 3 e 3 épocas de treinamento [^5].
    *   **Dados de Treinamento**: Para treinar o classificador *fastText*, 500.000 pontos de dados do *corpus* semente são selecionados aleatoriamente como exemplos positivos, enquanto outros 500.000 são retirados do *Common Crawl* como exemplos negativos [^4].
3.  **Extração e Refinamento Iterativo**: O classificador *fastText* é então usado para buscar páginas da web matemáticas adicionais do *Common Crawl* deduplicado (40B de páginas HTML). As páginas coletadas são classificadas de acordo com suas pontuações previstas pelo modelo *fastText*, e apenas as de classificação mais alta são preservadas [^5].
    *   **Avaliação do Volume de Dados**: O volume de dados preservados é avaliado através de experimentos de pré-treinamento nas principais 40B, 80B, 120B e 160B de *tokens*. Na primeira iteração, os principais 40B de *tokens* são mantidos [^5].
4.  **Anotação Humana e Expansão do Corpus**: Para enriquecer o *corpus* semente e otimizar o modelo *fastText*, fontes da web matemáticas adicionais são identificadas. O *Common Crawl* inteiro é organizado em domínios disjuntos, onde um domínio é definido como páginas da web que compartilham o mesmo URL base [^5].
    *   **Classificação de Domínios**: Para cada domínio, a porcentagem de páginas da web coletadas na primeira iteração é calculada. Os domínios onde mais de 10% das páginas da web foram coletadas são classificados como relacionados à matemática (por exemplo, mathoverflow.net) [^5].
    *   **Anotação Manual de URLs**: Os URLs associados ao conteúdo matemático dentro desses domínios identificados são anotados manualmente (por exemplo, mathoverflow.net/questions). As páginas da web vinculadas a esses URLs, mas ainda não coletadas, são adicionadas ao *corpus* semente [^5].
    *   **Iterações de Coleta de Dados**: Após quatro iterações de coleta de dados, 35.5M de páginas da web matemáticas, totalizando 120B de *tokens*, são obtidas. Quase 98% dos dados já foram coletados na terceira iteração, levando à decisão de interromper a coleta de dados [^5].
5.  **Descontaminação de Benchmark**: Para evitar a contaminação do *benchmark*, páginas da web contendo perguntas ou respostas de *benchmarks* matemáticos em inglês, como GSM8K (Cobbe et al., 2021) e MATH (Hendrycks et al., 2021), e *benchmarks* chineses, como CMATH (Wei et al., 2023) e AGIEval (Zhong et al., 2023) são filtradas [^5].
    *   **Critérios de Filtragem**: Qualquer segmento de texto que contenha uma *string* de 10-*gram* que corresponda exatamente a qualquer sub-*string* dos *benchmarks* de avaliação é removido do *corpus* de treinamento matemático. Para textos de *benchmark* com menos de 10 *grams*, mas com pelo menos 3 *grams*, uma correspondência exata é utilizada para filtrar páginas da web contaminadas [^5].

De acordo com a validação da qualidade do DeepSeekMath Corpus [^6]:

*   **Alta Qualidade**: há uma clara vantagem de desempenho do modelo treinado no DeepSeekMath Corpus.
*   **Multilíngue**: o corpus incorpora dados em vários idiomas, apresentando predominantemente inglês e chinês como os dois idiomas mais representados.
*   **Grande Escala**: é várias vezes maior que os *corpora* matemáticos existentes.

### Conclusão
O DeepSeekMath Corpus é um recurso valioso para avançar as capacidades de raciocínio matemático em LLMs [^6]. Ao construir um *corpus* de pré-treinamento em larga escala e alta qualidade, cuidadosamente extraído e refinado, o DeepSeekMath Corpus fornece aos modelos uma base sólida para aprender e executar tarefas matemáticas complexas [^4]. O meticuloso processo de coleta de dados, combinado com a descontaminação de *benchmarks*, garante que os modelos treinados no *corpus* sejam robustos e generalizáveis [^5]. As avaliações realizadas utilizando este *corpus* demonstraram melhorias significativas no desempenho dos modelos em vários *benchmarks* matemáticos [^6], sublinhando a eficácia da abordagem e o potencial para mais exploração e refinamento no futuro.

### Referências
[^1]: Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y.K. Li, Y. Wu, Daya Guo. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^4]: Seção 2 do artigo: Math Pre-Training
[^5]: Seção 2.1 do artigo: Data Collection and Decontamination
[^6]: Seção 2.2 do artigo: Validating the Quality of the DeepSeekMath Corpus
<!-- END -->