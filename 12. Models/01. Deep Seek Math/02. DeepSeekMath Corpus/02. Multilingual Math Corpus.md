## DeepSeekMath Corpus: Construindo um Dataset de Pré-Treinamento Matemático em Larga Escala

### Introdução
Este capítulo aprofunda-se nas características do **DeepSeekMath Corpus**, um *dataset* de pré-treinamento em larga escala projetado para impulsionar as capacidades de raciocínio matemático de *Large Language Models* (LLMs). Construindo sobre a base estabelecida na introdução [^1] e detalhada no capítulo anterior, este capítulo se concentra especificamente no aspecto multilíngue do *corpus*, na sua composição de dados em inglês e chinês, e em sua escala comparativamente maior em relação a outros *corpora* matemáticos disponíveis publicamente.

### Conceitos Fundamentais

Expandindo o conceito apresentado no capítulo anterior [^4, 5], o DeepSeekMath Corpus não apenas se destaca pela sua escala e metodologia de coleta, mas também pela sua diversidade linguística. Ele é projetado para incluir dados em múltiplos idiomas, com um foco predominante em inglês e chinês [^6].

1.  **Natureza Multilíngue**: A inclusão de dados em vários idiomas é uma característica distintiva do DeepSeekMath Corpus. O *corpus* é composto predominantemente por dados em inglês e chinês, que são os dois idiomas mais representados [^6].

2.  **Raciocínio Matemático Aprimorado em Inglês e Chinês**: O treinamento no DeepSeekMath Corpus aprimora o desempenho de raciocínio matemático em modelos treinados tanto em inglês quanto em chinês [^6]. Isso é particularmente notável porque os *corpora* matemáticos existentes, que são principalmente centrados no inglês, mostram melhorias limitadas e podem até dificultar o desempenho no raciocínio matemático chinês.

3.  **Validação da Natureza Multilíngue**: A Tabela 1 no artigo [^6] (reproduzida abaixo para conveniência) demonstra o desempenho do DeepSeek-LLM 1.3B treinado em diferentes *corpora* matemáticos, avaliado usando *few-shot chain-of-thought prompting*:

    | Math Corpus          | Size    | GSM8K | MATH  | OCW  | SAT   | MMLU STEM | CMATH | Gaokao MathCloze | Gaokao MathQA |
    | :-------------------- | :------ | :---- | :---- | :--- | :---- | :-------- | :---- | :---------------- | :------------- |
    | No Math Training      | N/A     | 2.9%  | 3.0%  | 2.9% | 15.6% | 19.5%    | 12.3% | 0.8%            | 17.9%         |
    | MathPile              | 8.9B    | 2.7%  | 3.3%  | 2.2% | 12.5% | 15.7%    | 1.2%  | 0.0%            | 2.8%          |
    | OpenWebMath           | 13.6B   | 11.5% | 8.9%  | 3.7% | 31.3% | 29.6%    | 16.8% | 0.0%            | 14.2%         |
    | Proof-Pile-2          | 51.9B   | 14.3% | 11.2% | 3.7% | 43.8% | 29.2%    | 19.9% | 5.1%            | 11.7%         |
    | DeepSeekMath Corpus | 120.2B  | 23.8% | 13.6% | 4.8% | 56.3% | 33.1%    | 41.5% | 5.9%            | 23.6%         |

    Os resultados na tabela acima demonstram que, comparado a outros *corpora*, o treinamento com o DeepSeekMath Corpus melhora o raciocínio matemático tanto em *benchmarks* em inglês (GSM8K, MATH, etc.) quanto em *benchmarks* em chinês (CMATH, Gaokao MathCloze, Gaokao MathQA).

4.  **Comparação de Escala com Outros Corpora**: O DeepSeekMath Corpus é várias vezes maior que os *corpora* matemáticos existentes [^6]. Especificamente, o *corpus* é quase 7 vezes o tamanho das páginas da web matemáticas usadas por Minerva (Lewkowycz et al., 2022a) e 9 vezes o tamanho do OpenWebMath [^3].

    Este maior tamanho permite ao DeepSeekMath Corpus capturar uma gama mais ampla de conceitos matemáticos e nuances linguísticas, resultando em melhores capacidades de raciocínio para os modelos treinados nele. Conforme ilustrado na Figura 3 do artigo [^7], os modelos (DeepSeek-LLM 1.3B) treinados no DeepSeekMath Corpus exibem uma curva de aprendizado mais acentuada e melhorias mais duradouras. Os *corpora* de linha de base, sendo menores, já foram repetidos várias vezes durante o treinamento, levando a um platô no desempenho do modelo.

### Conclusão

Em continuidade ao que foi apresentado no capítulo anterior, a natureza multilíngue e a escala do DeepSeekMath Corpus o estabelecem como um recurso substancial para o avanço do raciocínio matemático em LLMs [^6]. Ao incorporar dados nos idiomas inglês e chinês, o *corpus* permite que os modelos treinados nele desenvolvam uma compreensão mais abrangente dos conceitos matemáticos e sua expressão em diferentes contextos linguísticos [^6]. Além disso, sua escala maior em comparação com outros *corpora* permite uma melhor captura e representação de nuances matemáticas complexas, conduzindo a melhorias significativas no desempenho dos modelos [^6]. Esses fatores combinados destacam o valor do DeepSeekMath Corpus no cenário em evolução do raciocínio matemático baseado em IA.

### Referências
[^1]: Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y.K. Li, Y. Wu, Daya Guo. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^3]: Seção 1.1 do artigo: Contributions
[^4]: Seção 2 do artigo: Math Pre-Training
[^5]: Seção 2.1 do artigo: Data Collection and Decontamination
[^6]: Seção 2.2 do artigo: Validating the Quality of the DeepSeekMath Corpus
[^7]: Figura 3 do artigo: Benchmark curves of DeepSeek-LLM 1.3B trained on different mathematical corpora.
<!-- END -->