## O DeepSeekMath Corpus: Construindo um Dataset Matemático de Alta Qualidade

### Introdução
A capacidade de raciocínio matemático em *large language models* (LLMs) é crucial para o avanço da inteligência artificial [^2]. No entanto, modelos de ponta como GPT-4 e Gemini-Ultra não são totalmente acessíveis ao público, o que limita a pesquisa e o desenvolvimento nessa área [^2]. O DeepSeekMath Corpus surge como uma solução para este problema, fornecendo um conjunto de dados de alta qualidade para o pré-treinamento de modelos de linguagem focados em matemática [^2]. Este capítulo explora a construção e as características do DeepSeekMath Corpus, um componente fundamental para o desempenho do DeepSeekMath 7B, que demonstra capacidades de raciocínio matemático impressionantes [^1].

### Construção do DeepSeekMath Corpus
O DeepSeekMath Corpus é um *corpus* de pré-treinamento de alta qualidade em larga escala, compreendendo 120B de tokens matemáticos [^2]. A sua construção envolve um processo meticuloso de extração de dados do Common Crawl (CC) [^2], utilizando um classificador baseado em **fastText** [^2, 4]. O processo de construção é iterativo, conforme ilustrado na Figura 2 do documento [^5].

**O processo iterativo:**
> O processo envolve uma pipeline iterativa que demonstra como coletar sistematicamente um *corpus* matemático em larga escala a partir do Common Crawl, começando com um *seed corpus*.

**Seed Corpus e Classificador:**
*Inicialmente*, utiliza-se o OpenWebMath (Paster et al., 2023), uma coleção de textos da web de alta qualidade relacionados à matemática, como o *seed corpus* inicial [^2, 4].
*Com este *corpus*, treina-se um modelo **fastText** (Joulin et al., 2016) para identificar páginas web adicionais semelhantes ao OpenWebMath [^2, 4].
*Especificamente*, são selecionados aleatoriamente 500.000 pontos de dados do *seed corpus* como exemplos de treinamento positivos e outras 500.000 páginas web do Common Crawl como exemplos negativos [^4].
*Utiliza-se uma biblioteca *open-source* para o treinamento, configurando a dimensão do vetor para 256, a taxa de aprendizado para 0,1 e o comprimento máximo do n-grama de palavras para 3 [^4]. O número mínimo de ocorrências de palavras é definido como 3, e o número de *epochs* de treinamento como 3 [^5].

**Redução de tamanho e filtragem:**
> Para reduzir o tamanho do Common Crawl original, emprega-se deduplicação baseada em URL e técnicas de quase-deduplicação, resultando em 40B de páginas HTML.

**Anotação humana e refinamento:**
Após a iteração inicial, numerosas páginas web matemáticas permanecem não coletadas, principalmente porque o modelo **fastText** é treinado em um conjunto de exemplos positivos que carece de diversidade suficiente [^5]. Para resolver este problema, fontes web matemáticas adicionais são identificadas para enriquecer o *seed corpus*, otimizando assim o modelo **fastText** [^5].
Organiza-se todo o Common Crawl em domínios disjuntos [^5];
Para cada domínio, calcula-se a porcentagem de páginas web coletadas na primeira iteração [^5];
Domínios onde mais de 10% das páginas web foram coletadas são classificados como relacionados à matemática (por exemplo, mathoverflow.net) [^5].
Posteriormente, anotam-se manualmente os URLs associados ao conteúdo matemático dentro desses domínios identificados (por exemplo, mathoverflow.net/questions) [^5].
As páginas web vinculadas a esses URLs, mas ainda não coletadas, são adicionadas ao *seed corpus*. Esta abordagem permite coletar mais exemplos positivos, treinando assim um modelo **fastText** aprimorado capaz de recuperar mais dados matemáticos na iteração subsequente [^5]. Após quatro iterações de coleta de dados, chega-se a 35,5 milhões de páginas web matemáticas, totalizando 120B de *tokens* [^5].
Na quarta iteração, percebe-se que quase 98% dos dados já foram coletados na terceira iteração, decidindo-se interromper a coleta de dados [^5].

**Decontaminação:**
Para evitar a contaminação de *benchmarks*, seguem-se as diretrizes de [^5] (Guo et al., 2024) para filtrar páginas web contendo perguntas ou respostas de *benchmarks* matemáticos em inglês, como GSM8K e MATH, e *benchmarks* chineses, como CMATH e AGIEval [^5]. Os critérios de filtragem são os seguintes: qualquer segmento de texto contendo uma *string* de 10-gramas que corresponda exatamente a qualquer *substring* dos *benchmarks* de avaliação é removido do *corpus* de treinamento matemático [^5]. Para textos de *benchmark* com menos de 10 gramas, mas com pelo menos 3 gramas, emprega-se correspondência exata para filtrar páginas web contaminadas [^5].

### Qualidade e Impacto do Corpus

A qualidade do DeepSeekMath Corpus é validada através de experimentos de pré-treinamento, comparando-o com outros *corpora* matemáticos lançados recentemente [^6]:

*   **MathPile** (Wang et al., 2023c): um *corpus* de multi-fontes (8.9B *tokens*) agregado de livros didáticos, Wikipedia, ProofWiki, CommonCrawl, StackExchange e arXiv, com a maioria (mais de 85%) proveniente do arXiv [^6].

*   **OpenWebMath** (Paster et al., 2023): dados do CommonCrawl filtrados para conteúdo matemático, totalizando 13.6B *tokens* [^6].

*   **Proof-Pile-2** (Azerbayev et al., 2023): um *corpus* matemático que consiste em OpenWebMath, AlgebraicStack (10.3B *tokens* de código matemático) e artigos arXiv (28.0B *tokens*) [^6].

A avaliação demonstra que o DeepSeekMath Corpus é de alta qualidade, cobre conteúdo matemático multilingue e é o maior em tamanho [^6]. Especificamente, o modelo DeepSeekMath-Base 7B, pré-treinado no DeepSeekMath Corpus, alcança um desempenho comparável ao Minerva 540B (Lewkowycz et al., 2022a), indicando que o número de parâmetros não é o único fator chave na capacidade de raciocínio matemático [^3, 6].

### Conclusão

A criação do DeepSeekMath Corpus representa um avanço significativo no desenvolvimento de LLMs capazes de raciocínio matemático avançado [^1, 2]. Através de uma combinação de técnicas de mineração de dados, anotação humana e filtragem cuidadosa, o *corpus* oferece um recurso valioso para a comunidade de pesquisa [^4, 5]. Ao superar as limitações de *corpora* existentes e demonstrar um desempenho competitivo com modelos maiores, o DeepSeekMath Corpus abre novas oportunidades para a criação de LLMs mais eficientes e eficazes em matemática [^1, 6].

### Referências
[^1]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^2]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^3]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^4]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^5]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^6]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
<!-- END -->