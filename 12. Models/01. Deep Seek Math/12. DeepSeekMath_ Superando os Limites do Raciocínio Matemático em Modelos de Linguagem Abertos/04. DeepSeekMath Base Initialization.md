## DeepSeekMath: Superando os Limites do Raciocínio Matemático em Modelos de Linguagem Abertos

### Inicialização do DeepSeekMath-Base com DeepSeek-Coder-Base-v1.5 7B

#### Introdução

Em continuidade à discussão sobre a construção do DeepSeekMath Corpus [^2, 4, 5], o processo de *fine-tuning* supervisionado (SFT) para instrução matemática [^10, 11] e o desempenho do DeepSeekMath-Base 7B [^8, 9], este capítulo mergulha na justificativa e nas implicações de inicializar o DeepSeekMath-Base 7B com o DeepSeek-Coder-Base-v1.5 7B (Guo et al., 2024) [^2, 8]. O documento original explicita que *começar com um modelo de treinamento de código é uma escolha melhor em comparação com um LLM geral* [^2]. Exploraremos as razões por trás desta afirmação e o impacto desta escolha de inicialização no desempenho final do modelo.

#### A Vantagem de Inicializar com um Modelo de Treinamento de Código

A decisão de inicializar o DeepSeekMath-Base 7B com o DeepSeek-Coder-Base-v1.5 7B reflete uma estratégia deliberada para otimizar o desempenho do modelo em tarefas de raciocínio matemático. Existem várias razões pelas quais um modelo treinado em código pode ser uma base mais eficaz para o DeepSeekMath em comparação com um *large language model* (LLM) de propósito geral:

1.  **Vocabulário e Sintaxe:** Modelos treinados em código, como o DeepSeek-Coder-Base-v1.5 7B, possuem um vocabulário mais adequado para lidar com expressões matemáticas, símbolos e estruturas lógicas complexas encontradas em código e matemática [^8, 9]. A familiaridade com a sintaxe de programação pode facilitar o aprendizado de padrões e relações matemáticas.

2.  **Raciocínio Lógico:** O treinamento em código requer um alto grau de raciocínio lógico e a capacidade de seguir instruções precisas [^9]. Esta base de raciocínio lógico pode ser transferida para tarefas matemáticas, onde a precisão e a correção são fundamentais.

3.  **Abstração e Generalização:** A programação envolve a abstração de conceitos complexos e a generalização de soluções para diferentes problemas [^8]. Essas habilidades são diretamente aplicáveis ao raciocínio matemático, onde a capacidade de abstrair e generalizar é essencial para resolver problemas complexos.

4.  **Manipulação de Símbolos:** Modelos treinados em código são proficientes na manipulação de símbolos e variáveis, o que é crucial para lidar com equações, expressões e outras representações matemáticas [^9].

5. **Capacidade de seguir instruções:** Modelos treinados em código possuem naturalmente uma maior capacidade de seguir instruções e comandos explícitos, dada a necessidade de traduzir instruções em código funcional. Isso facilita o treinamento em tarefas de raciocínio matemático onde a correta interpretação de instruções é fundamental.

#### Impacto no Desempenho

O documento original observa que o treinamento matemático melhora a capacidade do modelo em MMLU e *benchmarks* BBH [^2], indicando que a escolha da inicialização não apenas aprimora as habilidades matemáticas do modelo, mas também amplia suas capacidades de raciocínio geral. A Tabela 4 [^9] apresenta uma comparação do desempenho do DeepSeekMath-Base 7B com o DeepSeek-Coder-Base-v1.5 nos *benchmarks* MMLU e BBH, mostrando que o treinamento matemático adicional resulta em melhorias significativas.

#### Outras análises do paper em relação a modelos treinados em código

O documento original menciona que "Code training benefits program-aided mathematical reasoning, both under the two-stage training and one-stage training settings" [^16]. E continua "As shown in Table 6, under the two-stage training setting, code training alone already significantly enhances the ability to solve GSM8K and MATH problems using Python" [^16]. Estes trechos corroboram a tese de que inicializar o DeepSeekMath-Base 7B com um modelo treinado em código foi a decisão acertada.

#### Conclusão

A decisão de inicializar o DeepSeekMath-Base 7B com o DeepSeek-Coder-Base-v1.5 7B é uma escolha estratégica para otimizar o desempenho do modelo em tarefas de raciocínio matemático [^2, 8]. As habilidades adquiridas durante o treinamento em código, como raciocínio lógico, abstração e manipulação de símbolos, fornecem uma base sólida para o aprendizado de conceitos matemáticos complexos [^9]. Esta abordagem resulta em um modelo que não apenas supera os seus concorrentes em *benchmarks* de matemática, mas também demonstra um desempenho aprimorado em tarefas de raciocínio geral e compreensão da linguagem natural [^2, 9]. A inicialização com um modelo treinado em código demonstra ser uma estratégia eficaz para o desenvolvimento de LLMs capazes de raciocínio matemático avançado.

#### Referências
[^2]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^4]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^5]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^8]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^9]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^10]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^11]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
[^16]: Shao et al. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.
<!-- END -->