## Conjunto de Dados DeepSeekMath: Problemas Matemáticos Chineses K-12

### Introdução
Este capítulo explora a construção e validação do conjunto de dados DeepSeekMath, com foco particular na criação de um conjunto de dados de problemas matemáticos chineses K-12 [^1]. A criação de um conjunto de dados de alta qualidade é um passo fundamental para melhorar as capacidades de raciocínio matemático de *Large Language Models* (LLMs). Em continuidade com a discussão sobre a importância de dados diversificados e multilinguísticos [^2, ^6], detalhamos aqui a metodologia utilizada para compilar um conjunto de dados abrangente e bem anotado de problemas matemáticos chineses.

### Conjunto de Dados Matemáticos Chineses K-12
O conjunto de dados DeepSeekMath visa abordar a capacidade dos LLMs em raciocínio matemático, focando em conteúdo de língua chinesa [^2]. A criação deste conjunto de dados envolveu várias etapas importantes, conforme descrito a seguir:

**Seleção de Tópicos e Subtópicos**: Inicialmente, identificaram-se 76 subtópicos dentro do currículo de matemática K-12 chinês. Esses subtópicos abrangem uma ampla gama de conceitos matemáticos, incluindo, mas não se limitando a, equações lineares [^1].

**Anotação em Formato CoT e Raciocínio Integrado a Ferramentas**: Cada problema foi anotado com soluções em dois formatos distintos [^1]:
1.  *Chain-of-Thought (CoT)*: O CoT envolve a decomposição do problema em etapas intermediárias lógicas, permitindo que o modelo siga o processo de raciocínio passo a passo. [^2, ^3]
2.  *Raciocínio Integrado a Ferramentas*: Este formato combina raciocínio textual com o uso de ferramentas externas (por exemplo, calculadoras, *solvers* simbólicos) para auxiliar na resolução do problema [^1].

**Justificativa**: A escolha de anotar os problemas em ambos os formatos CoT e raciocínio integrado a ferramentas visa enriquecer o conjunto de dados e permitir que os modelos aprendam diferentes estratégias de resolução de problemas. O formato CoT ajuda o modelo a desenvolver habilidades de raciocínio passo a passo, enquanto o formato integrado a ferramentas permite que o modelo aproveite recursos externos para cálculos complexos [^3, ^8].

**Importância da Multilingualidade**: Em linha com as descobertas de que os modelos treinados em dados multilinguísticos apresentam melhor desempenho em benchmarks chineses [^6], o conjunto de dados de matemática chinês K-12 desempenha um papel crucial no aprimoramento das capacidades dos LLMs em contextos não ingleses [^2, ^6].

### Comparativo com Outros Conjuntos de Dados

Para validar a qualidade do conjunto de dados DeepSeekMath, os autores realizaram experimentos de pré-treinamento e compararam o desempenho com outros conjuntos de dados de treinamento de matemática, incluindo MathPile, OpenWebMath e Proof-Pile-2 [^6]. Os resultados demonstraram que o DeepSeekMath Corpus é de alta qualidade, cobre conteúdo matemático multilinguístico e é o maior em tamanho [^6]. Especificamente, o modelo treinado no DeepSeekMath Corpus demonstrou melhor desempenho nos *benchmarks* matemáticos, indicando a eficácia do conjunto de dados na melhoria das capacidades de raciocínio matemático [^6].

### Construção do DeepSeekMath Corpus
A construção do DeepSeekMath Corpus envolveu uma abordagem iterativa para coletar um *corpus* matemático em larga escala a partir do *Common Crawl* [^5]. O processo incluiu as seguintes etapas:

1.  **Seleção de um *Seed Corpus***: Utilização do OpenWebMath como o *corpus* inicial [^5].
2.  **Treinamento de um Modelo *fastText***: Treinamento de um modelo *fastText* para identificar páginas da *web* semelhantes ao OpenWebMath [^5, ^9].
3.  **Anotação Humana**: Anotação manual dos caminhos de URL relacionados à matemática para refinar o modelo *fastText* [^5].
4.  **Deduplicação e Filtragem**: Remoção de conteúdo de baixa qualidade e duplicações para garantir a qualidade do *corpus* [^5].
5.  **Controle de Contaminação**: Implementação de filtros para remover páginas da *web* que continham perguntas ou respostas de *benchmarks* matemáticos conhecidos, como GSM8K e MATH [^5].

A abordagem iterativa permitiu a coleta sistemática de um *corpus* matemático em larga escala, resultando em um conjunto de dados de 120B *tokens* de páginas da *web* filtradas para conteúdo matemático [^5].

### Conclusão

A criação de um conjunto de dados de problemas matemáticos chineses K-12 anotados em formatos CoT e raciocínio integrado a ferramentas contribui significativamente para o campo do raciocínio matemático em LLMs [^1]. Este conjunto de dados não apenas aborda a falta de recursos em língua chinesa, mas também fornece uma estrutura para modelos aprenderem e aplicarem diferentes estratégias de resolução de problemas. Os resultados experimentais demonstram a eficácia do conjunto de dados DeepSeekMath no aprimoramento das capacidades de raciocínio matemático dos LLMs, tornando-o um recurso valioso para pesquisa e desenvolvimento futuros [^6]. A combinação de *code training* e *math training* é também apontada como um fator importante na capacidade de resolver problemas matemáticos [^3].

### Referências
[^1]: Zhihong Shao et al. "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models." ArXiv abs/2402.03300 (2024)
[^2]: Du, Z., Qian, Y., Liu, X., Ding, M., Qiu, J., Yang, Z., & Tang, J. (2022). GLM: General language model pretraining with autoregressive blank infilling. *Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, 320–335.
[^3]: Guo, D., Zhu, Q., Yang, D., Xie, Z., Dong, K., Zhang, W., Chen, G., Bi, X., Wu, Y., Li, Y. K., Luo, F., Xiong, Y., & Liang, W. (2024). Deepseek-coder: When the large language model meets programming – the rise of code intelligence.
[^4]: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. (2020). Measuring massive multitask language understanding. *arXiv preprint arXiv:2009.03300*.
[^5]: Joulin, A., Grave, E., Bojanowski, P., Douze, M., Jégou, H., & Mikolov, T. (2016). Fasttext. zip: Compressing text classification models. *arXiv preprint arXiv:1612.03651*.
[^6]: Wang, Z., Xia, R., & Liu, P. (2023). Generative AI for math: Part I - mathpile: A billion-token-scale pretraining corpus for math. *CoRR, abs/2312.17120*.
[^7]: Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E. H., Le, Q. V., & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. *NeurIPS*.
[^8]: Chen, W., Ma, X., Wang, X., & Cohen, W. W. (2022). Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. *CoRR, abs/2211.12588*.
[^9]: Paster, K. D., Santos, M. D., Azerbayev, Z., & Ba, J. (2023). Openwebmath: An open dataset of high-quality mathematical web text. *CoRR, abs/2310.06786*.
<!-- END -->