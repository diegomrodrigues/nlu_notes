## Supervised Fine-tuning (SFT)

### Introdução
Este capítulo se aprofunda na etapa de Supervised Fine-tuning (SFT) como um componente crítico no desenvolvimento de modelos de linguagem matemática de alto desempenho, como o DeepSeekMath [^1]. O SFT é uma técnica de aprendizado de máquina que envolve o ajuste fino de modelos pré-treinados em um conjunto de dados específico para uma tarefa específica. No contexto do DeepSeekMath, o SFT envolve ajustar modelos pré-treinados em um conjunto de dados de problemas e soluções matemáticas [^1], cobrindo problemas em inglês e chinês de diferentes campos matemáticos e níveis de complexidade [^1].

### Conceitos Fundamentais

O Supervised Fine-tuning (SFT) é uma técnica essencial no desenvolvimento de modelos de linguagem matemática eficazes, como evidenciado pelo DeepSeekMath [^1]. A qualidade do conjunto de dados de SFT influencia diretamente o desempenho do modelo, particularmente na resolução de problemas matemáticos passo a passo [^8]. O principal objetivo do SFT é maximizar a seguinte função objetiva [^28]:

$$
\mathcal{J}_{SFT}(\theta) = \mathbb{E}_{(q, o) \sim P_{SFT}(Q,O)} \left[ \frac{1}{|o|} \sum_{t=1}^{|o|} \log \pi_{\theta}(o_t | q, o_{<t}) \right] \eqno{(6)}
$$

Onde:

*   $\mathcal{J}_{SFT}(\theta)$ representa o objetivo de otimização do SFT.
*   $P_{SFT}(Q,O)$ denota a distribuição do conjunto de dados de fine-tuning supervisionado [^19].
*   $q$ representa a pergunta [^11, 13].
*   $o$ representa a saída ou solução correspondente à pergunta $q$ [^11, 13].
*   $|o|$ indica o comprimento da saída [^28].
*   $\pi_{\theta}(o_t | q, o_{<t})$ representa a probabilidade do token $o_t$ dado a pergunta $q$ e os tokens anteriores $o_{<t}$ [^11].
*   $\theta$ simboliza os parâmetros do modelo de linguagem [^11].

A função objetiva essencialmente calcula a probabilidade média de gerar a solução correta para cada problema no conjunto de dados. O modelo é otimizado para maximizar essa probabilidade [^28].

O gradiente do objetivo SFT é expresso como [^28]:

$$
\nabla_{\theta} \mathcal{J}_{SFT} = \mathbb{E}_{(q, o) \sim P_{SFT}(Q,O)} \left[ \frac{1}{|o|} \sum_{t=1}^{|o|} \nabla_{\theta} \log \pi_{\theta}(o_t | q, o_{<t}) \right] \eqno{(7)}
$$

Onde $\nabla_{\theta}$ representa o gradiente em relação aos parâmetros do modelo. O gradiente é usado para atualizar os parâmetros do modelo durante o processo de treinamento [^28].

#### Criação de Dados SFT

A construção de um conjunto de dados de SFT de alta qualidade é um passo crucial no desenvolvimento de modelos de linguagem matemática eficazes [^1, 10]. De acordo com a informação extraída, o dataset de mathematical instruction-tuning cobre problemas em inglês e chinês de diferentes campos matemáticos e níveis de complexidade [^10]. Os problemas são pareados com soluções em chain-of-thought (CoT), program-of-thought (PoT) e formato de raciocínio integrado a ferramentas [^10]. O número total de exemplos de treinamento é de 776K [^10].

*   **Conjuntos de dados matemáticos em inglês**: O dataset de língua inglesa é construído pela anotação de problemas GSM8K e MATH com soluções integradas a ferramentas, e pela adoção de um subconjunto do MathInstruct (Yue et al., 2023) [^10], juntamente com o conjunto de treinamento de Lila-OOD (Mishra et al., 2022) [^10], onde os problemas são resolvidos com CoT ou PoT [^10]. A coleção em inglês abrange diversos campos da matemática, como álgebra, probabilidade, teoria dos números, cálculo e geometria [^10].

*   **Conjuntos de dados matemáticos em chinês**: Os datasets em língua chinesa coletam problemas matemáticos K-12 chineses que abrangem 76 sub-tópicos, como equações lineares, com soluções anotadas tanto no CoT quanto no formato de raciocínio integrado a ferramentas [^10].

#### Configurações de Treinamento e Avaliação
Ao treinar o DeepSeekMath-Instruct 7B, os exemplos de treinamento são concatenados aleatoriamente até atingir um comprimento máximo de contexto de 4K tokens [^10]. O modelo é treinado por 500 passos com um tamanho de lote de 256 e uma taxa de aprendizado constante de 5e-5 [^10]. Os modelos são avaliados em seu desempenho matemático tanto sem quanto com o uso de ferramentas, em 4 benchmarks de raciocínio quantitativo em inglês e chinês [^10]. Os modelos de referência incluem modelos de código aberto e fechado líderes do período [^10].

### Conclusão
Supervised Fine-tuning (SFT) desempenha um papel fundamental no desenvolvimento de modelos de linguagem matemática de alto desempenho. A construção de um dataset SFT de alta qualidade, abrangendo diversos domínios matemáticos e complexidades, é essencial para o sucesso do processo de fine-tuning [^1, 10]. A seleção cuidadosa de problemas e soluções e a aplicação de técnicas de treinamento apropriadas podem levar a melhorias significativas nas capacidades de raciocínio matemático do modelo [^10].

### Referências
[^1]: Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y.K. Li, Y. Wu, Daya Guo. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.

[^8]: Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. K. Li, F. Luo, Y. Xiong, and W. Liang. Deepseek-coder: When the large language model meets programming – the rise of code intelligence, 2024.

[^10]: DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models

[^11]: Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.

[^13]: Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. Proximal policy optimization algorithms. *arXiv preprint arXiv:1707.06347*, 2017.

[^19]: Methods Table 10 | The data source and gradient coefficient of different methods. *P*sft denotes the data distribution of supervised fine-tuning datasets. πθsft and rθ denote the supervised fine-tuned model and the real-time policy model during the online training process, respectively.

[^28]: Appendix A.1.1 Supervised Fine-tuning
<!-- END -->